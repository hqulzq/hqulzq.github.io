<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hqulzq.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="全文翻译Abstract我们利用扩散概率模型（一类受非平衡热力学启发的隐变量模型）生成了高质量的图像合成结果。通过训练基于加权变分界限的目标函数（该目标函数源自扩散模型与带朗之万动态的去噪分数匹配之间的新联系），我们的最佳结果得以实现。模型自然支持渐进式有损解压缩方案，可视为自回归解码的广义形式。在无条件CIFAR10数据集上，我们获得了9.46的Inception分数和3.17的FID分数（当前">
<meta property="og:type" content="article">
<meta property="og:title" content="DDPM论文精读">
<meta property="og:url" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/index.html">
<meta property="og:site_name" content="Lzq&#39;s blog">
<meta property="og:description" content="全文翻译Abstract我们利用扩散概率模型（一类受非平衡热力学启发的隐变量模型）生成了高质量的图像合成结果。通过训练基于加权变分界限的目标函数（该目标函数源自扩散模型与带朗之万动态的去噪分数匹配之间的新联系），我们的最佳结果得以实现。模型自然支持渐进式有损解压缩方案，可视为自回归解码的广义形式。在无条件CIFAR10数据集上，我们获得了9.46的Inception分数和3.17的FID分数（当前">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/algorithm_1.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/table_1_2.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_3_4.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/algorithm_3_4.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_5.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_6_7.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_8.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/t_3.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/t_4.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_9.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_10.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_11.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_12.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_13.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_14.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_15.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_16.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_17.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_18.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f_19.png">
<meta property="article:published_time" content="2025-02-08T05:18:58.000Z">
<meta property="article:modified_time" content="2025-03-08T01:55:33.958Z">
<meta property="article:author" content="Zongqing Li">
<meta property="article:tag" content="diffusion">
<meta property="article:tag" content="NeurIPS">
<meta property="article:tag" content="2020">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/algorithm_1.png">

<link rel="canonical" href="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>DDPM论文精读 | Lzq's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lzq's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">40</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">12</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">45</span></a>

  </li>
        <li class="menu-item menu-item-book">

    <a href="/book" rel="section"><i class="fas fa-book fa-fw"></i>Book</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/02/08/DDPM%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DDPM论文精读
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-08 13:18:58" itemprop="dateCreated datePublished" datetime="2025-02-08T13:18:58+08:00">2025-02-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-08 09:55:33" itemprop="dateModified" datetime="2025-03-08T09:55:33+08:00">2025-03-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>我们利用扩散概率模型（一类受非平衡热力学启发的隐变量模型）生成了高质量的图像合成结果。通过训练基于加权变分界限的目标函数（该目标函数源自扩散模型与带朗之万动态的去噪分数匹配之间的新联系），我们的最佳结果得以实现。模型自然支持渐进式有损解压缩方案，可视为自回归解码的广义形式。在无条件CIFAR10数据集上，我们获得了9.46的Inception分数和3.17的FID分数（当前最优）。在256×256 LSUN数据集上，样本质量与ProgressiveGAN相当。代码已开源：<a target="_blank" rel="noopener" href="https://github.com/hojonathanho/diffusion。">https://github.com/hojonathanho/diffusion。</a><br><span id="more"></span></p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>近年来，各类深度生成模型在多种数据模态中都展现出了高质量的样本生成能力。生成对抗网络（GANs）、自回归模型、流模型和变分自编码器（VAEs）已经合成了令人惊叹的图像和音频样本[14, 27, 3, 58, 38, 25, 10, 32, 44, 57, 26, 33, 45]。在基于能量的建模和得分匹配方面也取得了显著进展，生成的图像可与GANs生成的图像相媲美[11, 55]。</p>
<p>本文展示了扩散概率模型的进展[53]。扩散概率模型（为简洁起见，我们将其称为“扩散模型”）是一种参数化的马尔可夫链，通过变分推理进行训练，以在有限时间后生成与数据匹配的样本。该链的转移是通过学习来逆转扩散过程的，扩散过程是一个马尔可夫链，它以与采样相反的方向逐渐向数据中添加噪声，直到信号被破坏。当扩散由少量高斯噪声组成时，将采样链的转移也设置为条件高斯分布就足够了，这使得神经网络的参数化特别简单。</p>
<p>扩散模型定义简单且训练高效，但据我们所知，此前尚无研究证明它们能够生成高质量的样本。我们的研究表明，扩散模型实际上能够生成高质量的样本，有时甚至优于其他类型生成模型的已发表结果（第4节）。此外，我们还揭示了扩散模型的一种特定参数化方式，在训练过程中，它与多噪声水平下的去噪得分匹配等价，在采样过程中，它与退火朗之万动力学等价（第3.2节）[55, 61]。我们使用这种参数化方式获得了最佳的样本质量结果（第4.2节），因此我们认为这种等价性是我们的主要贡献之一。</p>
<p>尽管我们的模型生成的样本质量较高，但与其他基于似然的模型相比，其对数似然并不具有竞争力（不过，我们模型的对数似然比已报道的基于能量的模型和得分匹配的退火重要性采样的大估计值要好[11, 55]）。我们发现，我们模型的大部分无损编码长度都用于描述难以察觉的图像细节（第4.3节）。我们用有损压缩的语言对这一现象进行了更深入的分析，并表明扩散模型的采样过程是一种渐进式解码，类似于沿着一种位序的自回归解码，这种位序极大地扩展了自回归模型通常所能实现的范围。</p>
<h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>扩散模型[53]是一种潜在变量模型，形式为$p_{\theta}(x_{0}):=\int p_{\theta}(x_{0: T}) d x_{1: T}$，其中$x_{1}, …, x_{T}$是与数据$x_{0} \sim q(x_{0})$维度相同的潜在变量。联合分布$p_{\theta}(x_{0: T})$被称为反向过程，它被定义为一个马尔可夫链，其从$p(x_{T})=N(x_{T} ; 0, I)$开始，具有经过学习的高斯转移概率：</p>
<script type="math/tex; mode=display">p_{\theta}\left(x_{0: T}\right):=p\left(x_{T}\right) \prod_{t=1}^{T} p_{\theta}\left(x_{t-1} | x_{t}\right), p_{\theta}\left(x_{t-1} | x_{t}\right):=\mathcal{N}\left(x_{t-1} ; \mu_{\theta}\left(x_{t}, t\right), \sum_{\theta}\left(x_{t}, t\right)\right) (1)</script><p>扩散模型与其他类型的潜在变量模型的区别在于，近似后验$q(x_{1: T} | x_{0})$（称为正向过程或扩散过程）被固定为一个马尔可夫链，该链根据方差调度$\beta_{1}, …, \beta_{T}$逐渐向数据中添加高斯噪声：</p>
<script type="math/tex; mode=display">q\left(x_{1: T} | x_{0}\right):=\prod_{t=1}^{T} q\left(x_{t} | x_{t-1}\right), q\left(x_{t} | x_{t-1}\right):=\mathcal{N}\left(x_{t} ; \sqrt{1-\beta_{t}} x_{t-1}, \beta_{t} I\right) (2)</script><p>训练通过优化负对数似然的常用变分下界来进行：</p>
<script type="math/tex; mode=display">\mathbb{E}\left[-log p_{\theta}\left(x_{0}\right)\right] \leq \mathbb{E}_{q}\left[-log \frac{p_{\theta}\left(x_{0: T}\right)}{q\left(x_{1: T} | x_{0}\right)}\right]=\mathbb{E}_{q}\left[-log p\left(x_{T}\right)-\sum_{t \geq 1} log \frac{p_{\theta}\left(x_{t-1} | x_{t}\right)}{q\left(x_{t} | x_{t-1}\right)}\right]=: L (3)</script><p>正向过程的方差$\beta_{t}$可以通过重参数化[33]进行学习，也可以作为超参数固定。反向过程的表达能力部分通过在$p_{\theta}(x_{t-1} | x_{t})$中选择高斯条件分布来保证，因为当$\beta_{t}$较小时，两个过程具有相同的函数形式[53]。正向过程的一个显著特性是，它允许在任意时间步$t$以封闭形式对$x_{t}$进行采样：使用符号$\alpha_{t}:=1-\beta_{t}$和$\bar{\alpha}_{t}:=\prod_{s=1}^{t} \alpha_{s}$，我们有</p>
<script type="math/tex; mode=display">q\left(x_{t} | x_{0}\right)=\mathcal{N}\left(x_{t} ; \sqrt{\overline{\alpha}_{t}} x_{0},\left(1-\overline{\alpha}_{t}\right) I\right) (4)</script><p>因此，通过随机梯度下降优化$L$中的随机项，可以实现高效训练。通过将公式(3)中的$L$改写为以下形式，可以进一步降低方差：</p>
<script type="math/tex; mode=display">\mathbb{E}_{q}[\underbrace{D_{KL}\left(q\left(x_{T} | x_{0}\right) \| p\left(x_{T}\right)\right)}_{L_{T}}+\sum_{t>1} \underbrace{D_{KL}\left(q\left(x_{t-1} | x_{t}, x_{0}\right) \| p_{\theta}\left(x_{t-1} | x_{t}\right)\right)}_{L_{t-1}} \underbrace{-log p_{\theta}\left(x_{0} | x_{1}\right)}_{L_{0}}] (5)</script><p>（详细内容见附录A。这些项的标签在第3节中使用。）公式(5)使用KL散度直接将$p_{\theta}(x_{t-1} | x_{t})$与正向过程的后验进行比较，当以$x_{0}$为条件时，正向过程的后验是易于处理的：</p>
<script type="math/tex; mode=display">q\left(x_{t-1} | x_{t}, x_{0}\right)=\mathcal{N}\left(x_{t-1} ; \tilde{\mu}_{t}\left(x_{t}, x_{0}\right), \tilde{\beta}_{t} I\right), (6)</script><center>其中，$\tilde{\mu}_{t}\left(x_{t}, x_{0}\right):=\frac{\sqrt{\overline{\alpha}_{t-1}} \beta_{t}}{1-\overline{\alpha}_{t}} x_{0}+\frac{\sqrt{\alpha_{t}}\left(1-\overline{\alpha}_{t-1}\right)}{1-\overline{\alpha}_{t}} x_{t}$，$\tilde{\beta}_{t}:=\frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_{t}} \beta_{t} (7)$。</center>

<p>因此，公式(5)中的所有KL散度都是高斯分布之间的比较，所以它们可以用Rao-Blackwellized方法通过封闭形式的表达式来计算，而无需使用高方差的蒙特卡罗估计。</p>
<h3 id="Diffusion-models-and-denoising-autoencoders"><a href="#Diffusion-models-and-denoising-autoencoders" class="headerlink" title="Diffusion models and denoising autoencoders"></a>Diffusion models and denoising autoencoders</h3><p>扩散模型可能看似是一类受限的潜在变量模型，但它们在实现过程中允许有大量的自由度。人们必须选择正向过程的方差$\beta_t$，以及反向过程的模型架构和高斯分布参数化方式。为指导我们的选择，我们在扩散模型与去噪得分匹配（3.2节）之间建立了一种新的明确联系，这产生了一个简化的、加权的变分下界目标，用于扩散模型（3.4节）。最终，我们的模型设计通过简单性和实证结果（第4节）得以证明合理。我们的讨论在等式(5)的背景下进行组织。</p>
<h4 id="Forward-process-and-L-T"><a href="#Forward-process-and-L-T" class="headerlink" title="Forward process and $L_{T}$"></a>Forward process and $L_{T}$</h4><p>我们忽略了正向过程方差$\beta_t$可通过重参数化进行学习这一事实，而是将它们固定为常数（详见第4节）。因此，在我们的实现中，近似后验$q$没有可学习的参数，所以$L_T$在训练期间是一个常数，可以忽略不计。</p>
<h4 id="Reverse-process-and-L-1-T−1"><a href="#Reverse-process-and-L-1-T−1" class="headerlink" title="Reverse process and $L_{1:T−1}$"></a>Reverse process and $L_{1:T−1}$</h4><p>现在我们讨论在$1 &lt; t \leq T$时，对于$p_{\theta}(x_{t - 1}|x_t) = \mathcal{N}(x_{t - 1}; \mu_{\theta}(x_t, t), \Sigma_{\theta}(x_t, t))$的选择。首先，我们将$\Sigma_{\theta}(x_t, t) = \sigma_t^2 I$设为与训练无关的时间相关常数。在实验中，$\sigma_t^2 = \beta_t$和$\sigma_t^2 = \tilde{\beta}_t = \frac{1 - \overline{\alpha}_{t - 1}}{1 - \overline{\alpha}_t}\beta_t$都有相似的结果。第一种选择对于$x_0 \sim \mathcal{N}(0, I)$是最优的，第二种选择对于$x_0$被确定性地设为一个点时是最优的。这些是与具有坐标方向单位方差的数据的反向过程熵的上下界相对应的两种极端选择[53]。</p>
<p>其次，为了表示均值$\mu_{\theta}(x_t, t)$，我们基于对$L_t$的以下分析提出一种特定的参数化。在$p_{\theta}(x_{t - 1}|x_t) = \mathcal{N}(x_{t - 1}; \mu_{\theta}(x_t, t), \sigma_t^2 I)$的情况下，我们可以写出：</p>
<script type="math/tex; mode=display">L_{t - 1} = \mathbb{E}_q\left[\frac{1}{2\sigma_t^2}\left\|\tilde{\mu}_t(x_t, x_0) - \mu_{\theta}(x_t, t)\right\|^2\right] + C (8)</script><p>其中$C$是一个不依赖于$\theta$的常数。所以，我们看到对$\mu_{\theta}$最直接的参数化是一个预测$\tilde{\mu}_t$（正向过程后验均值）的模型。然而，我们可以通过将公式(4)重新参数化为$x_t(x_0, \epsilon) = \sqrt{\overline{\alpha}_t}x_0 + \sqrt{1 - \overline{\alpha}_t}\epsilon$（其中$\epsilon \sim \mathcal{N}(0, I)$），并应用正向过程后验公式(7)来进一步展开公式(8)：</p>
<script type="math/tex; mode=display">
\begin{align*}
L_{t - 1} - C &= \mathbb{E}_{x_0, \epsilon}\left[\frac{1}{2\sigma_t^2}\left\|\tilde{\mu}_t\left(x_t(x_0, \epsilon), \frac{1}{\sqrt{\overline{\alpha}_t}}(x_t(x_0, \epsilon) - \sqrt{1 - \overline{\alpha}_t}\epsilon)\right) - \mu_{\theta}(x_t(x_0, \epsilon), t)\right\|^2\right] (9)\\
&= \mathbb{E}_{x_0, \epsilon}\left[\frac{1}{2\sigma_t^2}\left\|\frac{1}{\sqrt{\alpha_t}}\left(x_t(x_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}}\epsilon\right) - \mu_{\theta}(x_t(x_0, \epsilon), t)\right\|^2\right] (10)
\end{align*}</script><p><img src="algorithm_1.png" alt="algorithm1"></p>
<p>公式(10)表明，给定$x_t$，$\mu_{\theta}$必须预测$\frac{1}{\sqrt{\alpha_t}}\left(x_t - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}}\epsilon\right)$。由于$x_t$可作为模型的输入，我们可以选择如下参数化方式：</p>
<script type="math/tex; mode=display">
\mu_{\theta}(x_t, t)=\tilde{\mu}_t\left(x_t, \frac{1}{\sqrt{\overline{\alpha}_t}}(x_t - \sqrt{1 - \overline{\alpha}_t}\epsilon_{\theta}(x_t))\right)=\frac{1}{\sqrt{\alpha_t}}\left(x_t - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}}\epsilon_{\theta}(x_t, t)\right) (11)</script><p>其中，$\epsilon_{\theta}$是一个函数近似器，旨在从$x_t$预测$\epsilon$。要从$p_{\theta}(x_{t - 1}|x_t)$中采样$x_{t - 1}$，需计算$x_{t - 1}=\frac{1}{\sqrt{\alpha_t}}\left(x_t - \frac{1 - \alpha_t}{\sqrt{1 - \overline{\alpha}_t}}\epsilon_{\theta}(x_t, t)\right)+\sigma_t z$，其中$z \sim \mathcal{N}(0, I)$。完整的采样过程（算法2）类似于朗之万动力学，其中$\epsilon_{\theta}$作为数据密度的学习梯度。此外，采用参数化(11)后，公式(10)简化为：</p>
<script type="math/tex; mode=display">
\mathbb{E}_{x_0, \epsilon}\left[\frac{\beta_t^2}{2\sigma_t^2\alpha_t(1 - \overline{\alpha}_t)}\left\|\epsilon - \epsilon_{\theta}(\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1 - \overline{\alpha}_t}\epsilon, t)\right\|^2\right] (12)</script><p>这类似于在由$t$索引的多个噪声尺度上进行去噪得分匹配[55]。由于公式(12)等于（类似于朗之万的反向过程(11)的变分下界的一项），我们发现优化一个类似于去噪得分匹配的目标，等同于使用变分推断来拟合类似于朗之万动力学的采样链的有限时间边际分布。</p>
<p>总而言之，我们可以训练反向过程均值函数近似器$\mu_{\theta}$来预测$\tilde{\mu}_t$，或者通过修改其参数化方式，训练它来预测$\epsilon$。（也有可能预测$x_0$，但在我们的实验早期发现这会导致样本质量较差。）我们已经表明，$\epsilon$ - 预测参数化既类似于朗之万动力学，又简化了扩散模型的变分下界目标，这类似于去噪得分匹配。尽管如此，它只是$p_{\theta}(x_{t - 1}|x_t)$的另一种参数化方式，所以我们在第4节的消融实验中验证了它相对于预测$\tilde{\mu}_t$的有效性。</p>
<h4 id="Data-scaling-reverse-process-decoder-and-L-0"><a href="#Data-scaling-reverse-process-decoder-and-L-0" class="headerlink" title="Data scaling, reverse process decoder, and $L_{0}$"></a>Data scaling, reverse process decoder, and $L_{0}$</h4><p>我们假设图像数据由集合$\{0, 1, \ldots, 255\}$中的整数组成，并将其线性缩放到$[-1, 1]$。这确保了神经网络反向过程从标准正态先验$p(x_T)$开始，对经过一致缩放的输入进行操作。为了得到离散对数似然，我们将反向过程的最后一项设置为一个独立的离散解码器，该解码器源自高斯分布$\mathcal{N}(x_0; \mu_{\theta}(x_1, 1), \sigma_1^2 I)$：</p>
<script type="math/tex; mode=display">
p_{\theta}(x_0|x_1) = \prod_{i = 1}^{D} \int_{\delta_{-}(x_0^i)}^{\delta_{+}(x_0^i)} \mathcal{N}(x; \mu_{\theta}^i(x_1, 1), \sigma_1^2) dx (13)</script><script type="math/tex; mode=display">
\delta_{+}(x) =
\begin{cases}
\infty & \text{if } x = 1 \\
x + \frac{1}{255} & \text{if } x < 1
\end{cases}
\quad
\delta_{-}(x) =
\begin{cases}
-\infty & \text{if } x = -1 \\
x - \frac{1}{255} & \text{if } x > -1
\end{cases} (13)</script><p>其中$D$是数据维度，上标$i$表示提取一个坐标。（直接采用更强大的解码器，比如条件自回归模型会很直接，但我们将其留作未来的工作。）与变分自编码器（VAE）解码器和自回归模型中使用的离散化连续分布类似[34, 52]，我们在此处的选择确保了变分下界是离散数据的无损编码长度，无需向数据添加噪声，也无需将缩放操作纳入对数似然。在采样时，我们无噪声地展示$\mu_{\theta}(x_1, 1)$。</p>
<h4 id="Simplified-training-objective"><a href="#Simplified-training-objective" class="headerlink" title="Simplified training objective"></a>Simplified training objective</h4><p>有了上述定义的反向过程和解码器，由公式(12)和(13)推导得出的各项所构成的变分下界，显然关于$\theta$是可微的，可用于训练。然而，我们发现对以下变分下界的变体进行训练对样本质量有益（并且实现起来更简单）：</p>
<p><img src="table_1_2.png" alt="table_1_2"></p>
<script type="math/tex; mode=display">
L_{\text{simple}}(\theta) := \mathbb{E}_{t, x_0, \epsilon}\left[\left\|\epsilon - \epsilon_{\theta}(\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1 - \overline{\alpha}_t}\epsilon, t)\right\|^2\right] (14)</script><p>其中，$t$在$1$到$T$之间均匀取值。当$t = 1$时，对应于$L_0$，此时离散解码器定义(13)中的积分由高斯概率密度函数乘以区间宽度近似，忽略$\sigma^2$和边缘效应。当$t &gt; 1$时，对应于公式(12)的无加权版本，类似于NCSN去噪得分匹配模型所使用的损失加权方式[55]。（$L_T$不出现，因为正向过程的方差$\beta_t$是固定的。）算法1展示了完整的训练过程。</p>
<p>由于我们的简化目标(14)舍弃了公式(12)中的加权，与标准变分下界相比[18, 22]，它是一个强调重建不同方面的加权变分下界。特别地，我们在第4节中的扩散过程设置导致简化目标对对应于较小$t$的损失项进行降权。这些项训练网络对噪声量极少的数据进行去噪，所以对它们降权是有益的，这样网络可以专注于在较大$t$项时更困难的去噪任务。我们将在实验中看到，这种重新加权会带来更好的样本质量。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>在所有实验中，我们将 $T$ 设置为1000，这样采样过程中所需的神经网络评估次数与之前的工作 [53, 55] 保持一致。我们将正向过程的方差设置为常数，从 $\beta_1 = 10^{-4}$ 线性增加到 $\beta_T = 0.02$ 。选择这些常数是因为相对于缩放到 $[-1, 1]$ 的数据来说它们较小，这确保了反向过程和正向过程具有大致相同的函数形式，同时使 $x_T$ 处的信噪比尽可能小（在我们的实验中，$L_T = D_{KL}(q(x_T|x_0)||N(0, I)) \approx 10^{-5}$ 比特/维度）。</p>
<p>为了表示反向过程，我们使用类似于未掩码的PixelCNN++ [52, 48] 的U - Net骨干网络，并在整个网络中使用组归一化 [66] 。网络参数在不同时间步共享，时间 $t$ 通过Transformer正弦位置嵌入 [60] 传递给网络。我们在16×16的特征图分辨率上使用自注意力机制 [63, 60] 。具体细节见附录B。</p>
<h4 id="Sample-quality"><a href="#Sample-quality" class="headerlink" title="Sample quality"></a>Sample quality</h4><p>表1展示了CIFAR10数据集上的Inception分数、FID分数和负对数似然（无损编码长度）。我们的无条件模型的FID分数为3.17，这表明其样本质量优于文献中的大多数模型，包括类条件模型。我们按照标准做法，相对于训练集计算FID分数；当我们相对于测试集计算时，分数为5.24，这仍然优于文献中许多模型在训练集上的FID分数。</p>
<p>我们发现，正如预期的那样，在真实变分下界上训练我们的模型会得到比在简化目标上训练更好的编码长度，但后者能产生最佳的样本质量。CIFAR10和256×256的CelebA - HQ样本见图1，256×256的LSUN样本见图3和图4 [71] ，更多样本见附录D。</p>
<h4 id="Reverse-process-parameterization-and-training-objective-ablatio"><a href="#Reverse-process-parameterization-and-training-objective-ablatio" class="headerlink" title="Reverse process parameterization and training objective ablatio"></a>Reverse process parameterization and training objective ablatio</h4><p>在表2中，我们展示了反向过程参数化和训练目标（第3.2节）对样本质量的影响。我们发现，预测 $\bar{\mu}$ 的基线选项只有在基于真实变分下界而非类似公式（14）的简化目标（未加权均方误差）进行训练时才表现良好。我们还发现，与固定方差相比，学习反向过程的方差（通过在变分下界中加入参数化的对角矩阵 $\sum_{\theta}(x_t)$ ）会导致训练不稳定且样本质量更差。我们提出的预测 $\epsilon$ 的方法，在基于固定方差的变分下界训练时，表现与预测 $\bar{\mu}$ 大致相同，但在使用我们的简化目标训练时，表现要比预测 $\bar{\mu}$ 好得多。</p>
<h4 id="Progressive-coding"><a href="#Progressive-coding" class="headerlink" title="Progressive coding"></a>Progressive coding</h4><p>表1还展示了我们CIFAR10模型的编码长度。训练集和测试集之间的差距最大为0.03比特/维度，这与其他基于似然的模型所报告的差距相当，表明我们的扩散模型没有过拟合（最近邻可视化见附录D）。尽管如此，虽然我们的无损编码长度比基于能量的模型和使用退火重要性采样的分数匹配所报告的大估计值要好 [11] ，但与其他类型的基于似然的生成模型相比仍不具竞争力 [7] 。</p>
<p>由于我们的样本质量仍然很高，因此我们得出结论，扩散模型具有一种归纳偏差，使其成为出色的有损压缩器。将变分下界项 $L_1+\cdots+L_T$ 视为速率，$L_0$ 视为失真，我们在CIFAR10上生成最高质量样本的模型的速率为1.78比特/维度，失真为1.97比特/维度，在0到255的尺度上，这相当于均方根误差为0.95。超过一半的无损编码长度用于描述难以察觉的失真。<br><img src="f_3_4.png" alt=""><br><img src="algorithm_3_4.png" alt=""></p>
<ul>
<li><p><strong>渐进有损压缩</strong>：我们可以通过引入一种渐进有损编码来进一步探究模型的速率 - 失真行为，该编码与公式（5）的形式相似：见算法3和算法4，这两个算法假设可以使用一种过程，如最小随机编码 [19, 20] ，该过程平均可以使用大约 $D_{KL}(q(x)||p(x))$ 比特来传输样本 $x \sim q(x)$ ，对于任何分布 $p$ 和 $q$ ，接收方事先仅知道 $p$ 。当应用于 $x_0 \sim q(x_0)$ 时，算法3和算法4按顺序传输 $x_T, \cdots, x_0$ ，总期望编码长度等于公式（5）。在任何时间 $t$ ，接收方都可以完全获取部分信息 $x_t$ ，并可以渐进地估计：</p>
<script type="math/tex; mode=display">x_0 \approx \hat{x}_0 = \frac{x_t - \sqrt{1-\bar{\alpha}_t}\epsilon_{\theta}(x_t)}{\sqrt{\bar{\alpha}_t}}</script><p>这是根据公式（4）得到的。（随机重建 $x_0 \sim p_{\theta}(x_0|x_t)$ 也是有效的，但我们在此不考虑它，因为这会使失真评估更加困难。）图5展示了在CIFAR10测试集上得到的速率 - 失真图。在每个时间 $t$ ，失真计算为均方根误差 $\sqrt{\frac{|x_0 - \hat{x}_0|^2}{D}}$ ，速率计算为到时间 $t$ 为止接收到的累积比特数。在速率 - 失真图的低速率区域，失真急剧下降，这表明大部分比特确实用于描述难以察觉的失真。<br><img src="f_5.png" alt=""></p>
</li>
<li><p><strong>渐进生成</strong>：我们还运行了一个从随机比特进行渐进解压缩的渐进无条件生成过程。换句话说，我们在使用算法2从反向过程采样时，预测反向过程的结果 $\hat{x}_0$ 。图6和图10展示了在反向过程中 $\hat{x}_0$ 的样本质量变化。大尺度图像特征首先出现，细节最后出现。图7展示了在不同 $t$ 下，固定 $x_t$ 时 $x_0 \sim p_{\theta}(x_0|x_t)$ 的随机预测结果。当 $t$ 较小时，除了精细细节外，大部分特征都被保留；当 $t$ 较大时，只有大尺度特征被保留。这可能暗示了概念压缩 [18] 。<br><img src="f_6_7.png" alt=""></p>
</li>
<li><p><strong>与自回归解码的联系</strong>：注意，变分下界（5）可以重写为：</p>
<script type="math/tex; mode=display">L = D_{KL}(q(x_T)||p(x_T)) + \mathbb{E}_q[\sum_{t \geq 1}D_{KL}(q(x_{t - 1}|x_t)||p_{\theta}(x_{t - 1}|x_t))] + H(x_0) (16)</script><p>（推导见附录A）。现在考虑将扩散过程的长度 $T$ 设置为数据的维度，定义正向过程，使得 $q(x_t|x_0)$ 将所有概率质量集中在 $x_0$ 上，但前 $t$ 个坐标被屏蔽（即 $q(x_t|x_{t - 1})$ 屏蔽第 $t$ 个坐标），将 $p(x_T)$ 设置为将所有质量集中在一张空白图像上，并且为了便于讨论，将 $p_{\theta}(x_{t - 1}|x_t)$ 视为一个完全表达性的条件分布。在这些选择下，$D_{KL}(q(x_T)||p(x_T)) = 0$ ，最小化 $D_{KL}(q(x_{t - 1}|x_t)||p_{\theta}(x_{t - 1}|x_t))$ 会训练 $p_{\theta}$ 不变地复制坐标 $t + 1, \cdots, T$ ，并根据 $t + 1, \cdots, T$ 预测第 $t$ 个坐标。因此，使用这种特定的扩散训练 $p_{\theta}$ 就是在训练一个自回归模型。<br><img src="f_8.png" alt=""><br>因此，我们可以将高斯扩散模型（2）解释为一种具有广义比特排序的自回归模型，这种排序无法通过重新排列数据坐标来表达。先前的工作表明，这种重新排序会引入影响样本质量的归纳偏差 [38] ，所以我们推测高斯扩散起到了类似的作用，可能效果更显著，因为与屏蔽噪声相比，向图像中添加高斯噪声可能更自然。此外，高斯扩散的长度不限于等于数据维度；例如，我们使用 $T = 1000$ ，这小于我们实验中32×32×3或256×256×3图像的维度。高斯扩散的长度可以缩短以实现快速采样，或者延长以提高模型的表达能力。</p>
</li>
</ul>
<h4 id="Interpolation"><a href="#Interpolation" class="headerlink" title="Interpolation"></a>Interpolation</h4><p>我们可以在潜在空间中对源图像 $x_0, x_0’ \sim q(x_0)$ 进行插值，使用 $q$ 作为随机编码器得到 $x_t, x_t’ \sim q(x_t|x_0)$ ，然后通过反向过程将线性插值后的潜在向量 $\overline{x}_t = (1 - \lambda)x_0 + \lambda x_0’$ 解码到图像空间，得到 $\overline{x}_0 \sim p(x_0|\overline{x}_t)$ 。实际上，我们使用反向过程去除源图像的损坏版本进行线性插值时产生的伪影，如图8（左）所示。我们为不同的 $\lambda$ 值固定噪声，使 $x_t$ 和 $x_t’$ 保持不变。图8（右）展示了原始256×256的CelebA - HQ图像的插值和重建结果（$t = 500$ ）。反向过程产生了高质量的重建结果，并且得到的插值结果合理，能够平滑地改变姿势、肤色、发型、表情和背景等属性，但眼镜部分的变化不太自然。$t$ 值越大，插值结果越粗糙、变化越多，在 $t = 1000$ 时会得到新颖的样本（附录图9）。</p>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><p>虽然扩散模型可能与流模型（flows）[9, 46, 10, 32, 5, 16, 23]和变分自编码器（VAEs）[33, 47, 37]相似，但扩散模型的设计特点在于，其近似后验分布q没有参数，并且顶层潜在变量$X_T$与数据$x_0$的互信息几乎为零。我们提出的预测$\epsilon$的反向过程参数化方法，在多噪声水平下建立了扩散模型与去噪得分匹配之间的联系，同时在采样过程中与退火朗之万动力学相关[55, 56]。然而，扩散模型能够直接进行对数似然评估，并且训练过程通过变分推理显式地训练朗之万动力学采样器（详见附录C）。这种联系还意味着，某种加权形式的去噪得分匹配等同于通过变分推理训练一个类似朗之万的采样器。其他学习马尔可夫链转移算子的方法包括注入训练（infusion training）[2]、变分回溯（variational walkback）[15]、生成随机网络（generative stochastic networks）[1]，以及其他方法[50, 54, 36, 42, 35, 65]。</p>
<p>鉴于得分匹配与基于能量的模型之间的已知联系，我们的工作可能会对其他近期关于基于能量模型的研究[67-69, 12, 70, 13, 11, 41, 17, 8]产生影响。我们的率失真曲线是在一次变分下界评估过程中随时间计算得到的，这让人联想到在一次退火重要性采样中，如何通过改变失真惩罚来计算率失真曲线[24]。我们的渐进解码观点在卷积DRAW及相关模型[18, 40]中也有所体现，并且可能为自回归模型的子尺度排序或采样策略带来更通用的设计思路[38, 64]。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>我们利用扩散模型生成了高质量的图像样本，并发现了扩散模型与训练马尔可夫链的变分推断、去噪分数匹配、退火朗之万动力学（进而与基于能量的模型）、自回归模型以及渐进有损压缩之间的联系。由于扩散模型在处理图像数据时似乎具有出色的归纳偏差，我们期待探索其在其他数据模态中的效用，以及作为其他类型生成模型和机器学习系统组件的潜力。</p>
<h3 id="Broader-Impact"><a href="#Broader-Impact" class="headerlink" title="Broader Impact"></a>Broader Impact</h3><p>我们在扩散模型方面的研究，与其他类型深度生成模型的现有工作有着相似的研究范畴，例如致力于提高生成对抗网络（GANs）、流模型（flows）、自回归模型等的样本质量。本文代表了将扩散模型发展成为这类技术中通用工具的一项进展，因此它可能会放大生成模型对更广泛世界已经产生（以及将会产生）的任何影响。</p>
<p>不幸的是，生成模型存在许多广为人知的恶意用途。样本生成技术可被用于出于政治目的制作知名人士的假图像和假视频。虽然在软件工具出现之前，假图像就已通过手工绘制的方式存在，但像我们这样的生成模型使这一过程变得更加容易。幸运的是，目前由卷积神经网络（CNN）生成的图像存在一些细微瑕疵，仍可被检测出来[62]，但生成模型的改进可能会加大检测难度。此外，生成模型还会反映出其训练数据集里的偏差。由于许多大型数据集是由自动化系统从互联网上收集而来，去除这些偏差往往很困难，尤其是当图像未被标注时。如果在这些数据集上训练的生成模型所产生的样本在互联网上大量传播，那么这些偏差只会进一步加剧。</p>
<p>另一方面，扩散模型在数据压缩方面可能会发挥作用。随着数据分辨率的提高和全球互联网流量的增加，数据压缩对于确保广大用户能够访问互联网至关重要。我们的研究可能有助于在未标记的原始数据上进行表征学习，从而服务于从图像分类到强化学习等一系列下游任务。扩散模型也有可能在艺术、摄影和音乐创作领域找到用武之地。</p>
<h3 id="Acknowledgments-and-Disclosure-of-Funding"><a href="#Acknowledgments-and-Disclosure-of-Funding" class="headerlink" title="Acknowledgments and Disclosure of Funding"></a>Acknowledgments and Disclosure of Funding</h3><p>这项工作得到了ONR PECASE和NSF研究生研究奖学金的支持，根据赠款编号DGE-1752814。 Google的Tensorflow研究云（TFRC）提供了云TPU</p>
<h3 id="Extra-information"><a href="#Extra-information" class="headerlink" title="Extra information"></a>Extra information</h3><p><strong>LSUN数据集的FID分数</strong>：LSUN数据集的FID分数列于表3。标记为∗的分数是StyleGAN2作为基线报告的，其他分数由各自的作者报告。<br><img src="t_3.png" alt=""><br><strong>渐进压缩</strong>：我们在4.3节中关于有损压缩的论证只是一个概念验证，因为算法3和算法4依赖于诸如最小随机编码[20]之类的过程，而这种过程对于高维数据来说并不容易处理。这些算法只是对Sohl-Dickstein等人[53]的变分下界（5）进行了压缩方面的解释，尚未成为实用的压缩系统。<br><img src="t_4.png" alt=""></p>
<h3 id="A-Extended-derivations"><a href="#A-Extended-derivations" class="headerlink" title="A Extended derivations"></a>A Extended derivations</h3><p>以下是扩散模型降低方差的变分下界公式（5）的推导过程。该内容源自Sohl-Dickstein等人的研究[53]，此处列出仅为保证内容完整性。</p>
<script type="math/tex; mode=display">
\begin{align*}
L&=\mathbb{E}_{q}\left[-log \frac{p_{\theta}\left(x_{0: T}\right)}{q\left(x_{1: T} | x_{0}\right)}\right]\\
&=\mathbb{E}_{q}\left[-log p\left(x_{T}\right)-\sum_{t \geq 1} log \frac{p_{\theta}\left(x_{t-1} | x_{t}\right)}{q\left(x_{t} | x_{t-1}\right)}\right]\\
&=\mathbb{E}_{q}\left[-log p\left(x_{T}\right)-\sum_{t>1} log \frac{p_{\theta}\left(x_{t-1} | x_{t}\right)}{q\left(x_{t} | x_{t-1}\right)}-log \frac{p_{\theta}\left(x_{0} | x_{1}\right)}{q\left(x_{1} | x_{0}\right)}\right]\\
&=\mathbb{E}_{q}\left[-log p\left(x_{T}\right)-\sum_{t>1} log \frac{p_{\theta}\left(x_{t-1} | x_{t}\right)}{q\left(x_{t} | x_{0}\right)} \cdot \frac{q\left(x_{t-1} | x_{0}\right)}{q\left(x_{t} | x_{0}\right)}-log \frac{p_{\theta}\left(x_{0} | x_{1}\right)}{q\left(x_{1} | x_{0}\right)}\right]\\
&=\mathbb{E}_{q}\left[D_{KL}\left(q\left(x_{T} | x_{0}\right) \| p\left(x_{T}\right)\right)+\sum_{t>1} D_{KL}\left(q\left(x_{t-1} | x_{t}, x_{0}\right) \| p_{\theta}\left(x_{t-1} | x_{t}\right)\right)-log p_{\theta}\left(x_{0} | x_{1}\right)\right]
\end{align*}</script><p>下面是$L$的另一种形式。该形式不易进行估计，但对我们在4.3节中的讨论很有帮助。</p>
<script type="math/tex; mode=display">
\begin{align*}
L&=\mathbb{E}_{q}\left[-log p\left(x_{T}\right)-\sum_{t \geq 1} log \frac{p_{\theta}\left(x_{t-1} | x_{t}\right)}{q\left(x_{t} | x_{t-1}\right)}\right]\\
&=\mathbb{E}_{q}\left[-log p\left(x_{T}\right)-\sum_{t \geq 1} log \frac{p_{\theta}\left(x_{t-1} | x_{t}\right)}{q\left(x_{t-1} | x_{t}\right)} \cdot \frac{q\left(x_{t-1}\right)}{q\left(x_{t}\right)}\right]\\
&=\mathbb{E}_{q}\left[-log \frac{p\left(x_{T}\right)}{q\left(x_{T}\right)}-\sum_{t \geq 1} log \frac{p_{\theta}\left(x_{t-1} | x_{t}\right)}{q\left(x_{t-1} | x_{t}\right)}-log q\left(x_{0}\right)\right]\\
&=D_{KL}\left(q\left(x_{T}\right) \| p\left(x_{T}\right)\right)+\mathbb{E}_{q}\left[\sum_{t \geq 1} D_{KL}\left(q\left(x_{t-1} | x_{t}\right) \| p_{\theta}\left(x_{t-1} | x_{t}\right)\right)\right]
\end{align*}</script><h3 id="B-Experimental-details"><a href="#B-Experimental-details" class="headerlink" title="B Experimental details"></a>B Experimental details</h3><p>我们的神经网络架构采用了PixelCNN++ [52]的骨干网络，它是一个基于Wide ResNet [72]的U - Net [48]。为简化实现过程，我们将权重归一化 [49]替换为了组归一化 [66]。我们的32×32模型使用了四个特征图分辨率（从32×32到4×4），而256×256模型则使用了六个。所有模型在每个分辨率级别都有两个卷积残差块，并且在卷积块之间的16×16分辨率处设有自注意力块 [6]。扩散时间t通过在每个残差块中添加Transformer正弦位置嵌入 [60] 来指定。我们的CIFAR10模型有3570万个参数，而LSUN和CelebA - HQ模型有1.14亿个参数。我们还通过增加滤波器数量，训练了一个更大版本的LSUN卧室模型，其参数约为2.56亿个。</p>
<p>我们在所有实验中都使用了TPU v3 - 8（类似于8个V100 GPU）。我们的CIFAR模型在批量大小为128时，每秒可训练21步（在800k步训练完成需要10.6小时），对一批256张图像进行采样需要17秒。我们的CelebA - HQ/LSUN（$256^2$）模型在批量大小为64时，每秒可训练2.2步，对一批128张图像进行采样需要300秒。我们在CelebA - HQ上训练了50万步，在LSUN卧室数据集上训练了240万步，在LSUN猫数据集上训练了180万步，在LSUN教堂数据集上训练了120万步。更大的LSUN卧室模型训练了115万步。</p>
<p>除了在早期为使网络大小符合内存限制而选择了一组超参数外，我们大部分超参数搜索工作都是为了优化CIFAR10的样本质量，然后将得到的设置应用到其他数据集上：</p>
<ul>
<li>我们从一组常数、线性和二次调度中选择$\beta_t$的调度，所有调度都被限制为使$L_T\approx0$。我们未进行扫描就将$T$设置为1000，并选择了从$\beta_1 = 10^{-4}$到$\beta_T = 0.02$的线性调度。</li>
<li>我们通过在{0.1, 0.2, 0.3, 0.4}这些值中进行扫描，将CIFAR10上的随机失活率设置为0.1。在CIFAR10上不使用随机失活时，我们得到的样本质量较差，出现了类似于未正则化的PixelCNN++ [52] 中的过拟合伪影。我们在其他数据集上未进行扫描就将随机失活率设置为了零。在训练CIFAR10时，我们使用了随机水平翻转；我们尝试了有翻转和无翻转的训练方式，发现翻转略微提高了样本质量。除了LSUN卧室数据集外，我们在所有其他数据集的训练中也都使用了随机水平翻转。在实验初期，我们尝试了Adam [31]和RMSProp优化器，最终选择了Adam，并将其超参数设置为标准值。我们未进行扫描就将学习率设置为$2×10^{-4}$，对于256×256的图像，我们将学习率降低到了$2×10^{-5}$，因为在较大学习率下训练似乎不稳定。</li>
<li>我们将CIFAR10的批量大小设置为128，将较大图像的批量大小设置为64，且未对这些值进行扫描。</li>
<li>我们对模型参数使用了指数移动平均（EMA），衰减因子为0.9999，同样未对该值进行扫描。</li>
</ul>
<p>最终实验只训练一次，并在整个训练过程中评估样本质量。样本质量得分和对数似然是根据训练过程中的最小FID值报告的。在CIFAR10上，我们使用来自OpenAI [51]和TTUR [21] 代码库的原始代码，对50000个样本计算Inception得分和FID得分。在LSUN上，我们使用来自StyleGAN2 [30] 代码库的代码，对50000个样本计算FID得分。CIFAR10和CelebA - HQ数据集通过TensorFlow Datasets（<a target="_blank" rel="noopener" href="https://www.tensorflow.org/datasets）加载，LSUN数据集则使用StyleGAN的代码进行准备。数据集的划分（或未划分的情况）遵循在生成建模背景下首次引入它们的论文中的标准。所有细节都可以在源代码发布中找到。">https://www.tensorflow.org/datasets）加载，LSUN数据集则使用StyleGAN的代码进行准备。数据集的划分（或未划分的情况）遵循在生成建模背景下首次引入它们的论文中的标准。所有细节都可以在源代码发布中找到。</a></p>
<h3 id="C-Discussion-on-related-work"><a href="#C-Discussion-on-related-work" class="headerlink" title="C Discussion on related work"></a>C Discussion on related work</h3><p>我们的模型架构、正向过程定义和先验分布与NCSN [55, 56]存在一些细微但重要的差异，这些差异提高了样本质量。值得注意的是，我们直接将采样器作为潜在变量模型进行训练，而不是在训练后再添加采样器。具体细节如下：</p>
<ol>
<li>我们使用带有自注意力机制的U - Net，而NCSN使用带有扩张卷积的RefineNet。我们通过添加Transformer正弦位置嵌入，使所有层都依赖于t，而NCSNv1仅在归一化层中依赖t，NCSNv2仅在输出层依赖t。</li>
<li>扩散模型在正向过程的每一步都会对数据进行缩放（缩放因子为$\sqrt{1 - \beta_t}$），这样在添加噪声时方差不会增大，从而为神经网络的反向过程提供尺度一致的输入。NCSN则省略了这个缩放因子。</li>
<li>与NCSN不同，我们的正向过程会破坏信号（$D_{KL}(q(x_T | x_0)||N(0, I))\approx0$），确保$x_T$的先验分布和聚合后验分布紧密匹配。同样与NCSN不同的是，我们的$\beta_t$非常小，这保证了正向过程可以通过具有条件高斯分布的马尔可夫链进行逆向。这两个因素都避免了采样过程中的分布偏移。</li>
<li>我们类似朗之万的采样器的系数（学习率、噪声尺度等）是根据正向过程中的$\beta_t$严格推导出来的。因此，我们的训练过程直接训练采样器，使其在T步后与数据分布匹配：我们使用变分推理将采样器作为潜在变量模型进行训练。相比之下，NCSN的采样器系数是在训练后手动设置的，并且其训练过程不能保证直接优化采样器的质量指标。</li>
</ol>
<h3 id="D-Samples"><a href="#D-Samples" class="headerlink" title="D Samples"></a>D Samples</h3><ul>
<li><strong>额外样本</strong>：图11、13、16、17、18和19展示了在CelebA - HQ、CIFAR10和LSUN数据集上训练的扩散模型生成的未经筛选的样本。</li>
<li><strong>潜在结构和反向过程的随机性</strong>：在采样过程中，先验$x_T\sim N(0, I)$和朗之万动力学都是随机的。为了理解第二个噪声源的重要性，我们在CelebA 256×256数据集上，基于相同的中间潜在变量对多个图像进行采样。图7展示了在$t\in\{1000, 750, 500, 250\}$时，从反向过程$x_0\sim p_{\theta}(x_0 | x_t)$中基于相同的潜在变量$x_t$进行的多次采样结果。为实现这一点，我们从先验分布中进行一次初始采样，然后运行单个反向链。在中间时间步，将该链分支以采样多个图像。当在$x_{T = 1000}$（即从先验分布采样后）对链进行分支时，样本之间差异显著。然而，当在更多步之后对链进行分支时，样本会共享一些高层次的属性，如性别、头发颜色、眼镜佩戴情况、饱和度、姿势和面部表情。这表明像$x_{750}$这样的中间潜在变量编码了这些属性，尽管这些属性并不明显。</li>
<li><strong>从粗到细的插值</strong>：图9展示了一对256×256的CelebA源图像之间的插值结果，其中我们在潜在空间插值之前改变了扩散步骤的数量。增加扩散步骤的数量会破坏源图像中的更多结构，而模型在反向过程中会对这些结构进行补充。这使得我们能够在精细粒度和粗糙粒度上进行插值。在扩散步骤为0的极限情况下，插值是在像素空间中混合源图像。另一方面，经过1000个扩散步骤后，源信息丢失，插值结果变成了新颖的样本。</li>
</ul>
<p><img src="f_9.png" alt=""><br><img src="f_10.png" alt=""><br><img src="f_11.png" alt=""><br><img src="f_12.png" alt=""><br><img src="f_13.png" alt=""><br><img src="f_14.png" alt=""><br><img src="f_15.png" alt=""><br><img src="f_16.png" alt=""><br><img src="f_17.png" alt=""><br><img src="f_18.png" alt=""><br><img src="f_19.png" alt=""></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="Abstract部分"><a href="#Abstract部分" class="headerlink" title="Abstract部分"></a>Abstract部分</h3><h4 id="非平衡热力学启发体现在哪里？与朗之万动力学的联系体现在哪里？"><a href="#非平衡热力学启发体现在哪里？与朗之万动力学的联系体现在哪里？" class="headerlink" title="非平衡热力学启发体现在哪里？与朗之万动力学的联系体现在哪里？"></a>非平衡热力学启发体现在哪里？与朗之万动力学的联系体现在哪里？</h4><p>非平衡热力学对扩散概率模型的启发主要体现在模型构建和训练机制上，它为模型设计提供了理论支撑，让模型能更好地模拟数据分布，实现高质量图像合成。</p>
<ol>
<li><strong>正向扩散过程</strong>：模拟非平衡态向平衡态演化。正向过程逐渐向数据中添加高斯噪声，直至信号被完全破坏，类似非平衡热力学中系统从有序趋向无序的过程。通过方差调度$\beta_{1}, …, \beta_{T}$控制噪声添加的程度，使得数据分布逐渐变化，这种从低噪声状态向高噪声状态的转变，类比于非平衡系统在热力学过程中的状态变化，系统熵不断增加，最终达到平衡态（高噪声状态）。</li>
<li><strong>反向采样过程</strong>：反向过程通过学习参数化的马尔可夫链来逆转扩散过程，从高噪声状态逐步恢复到低噪声状态，生成接近原始数据的样本。这类似于在非平衡热力学中，通过外界干预使系统从平衡态向有序状态转变（虽然实际热力学过程中这种自发逆向转变较为困难，但在模型中通过学习实现）。模型训练时，调整参数使反向过程尽可能准确地恢复原始数据，就像在特定条件下使非平衡系统逆向演化，体现了非平衡热力学中对系统状态转变的控制思想。</li>
<li><strong>与朗之万动力学的联系</strong>：论文发现扩散模型的训练与基于朗之万动力学的去噪得分匹配存在等价关系。朗之万动力学描述了粒子在随机力和摩擦力作用下的运动，在扩散模型中，采样过程类似朗之万动力学，通过对数据密度的学习梯度（由$\epsilon_{\theta}$表示）来引导采样。这种联系反映了非平衡热力学中粒子在复杂环境下的动力学行为，为模型的采样过程提供了理论依据，使模型在生成样本时能更好地捕捉数据的分布特征。</li>
</ol>
<h4 id="Inception-分数和FID-分数分别是什么？"><a href="#Inception-分数和FID-分数分别是什么？" class="headerlink" title="Inception 分数和FID 分数分别是什么？"></a>Inception 分数和FID 分数分别是什么？</h4><ol>
<li><p><strong>Inception分数（Inception Score，IS）</strong>：用于评估生成图像质量的指标。基于Inception网络，该网络在ImageNet数据集上进行过预训练。计算时，首先将生成的图像输入Inception网络，得到预测的类别概率分布。Inception分数通过衡量这些概率分布的两个特性来评估图像质量：一是类别预测的平均置信度，反映生成图像的清晰度和可识别性，置信度越高，说明图像越清晰，模型对其类别的判断越明确；二是这些概率分布的熵，衡量生成图像的多样性，熵越大，图像多样性越高。最终，Inception分数是这两个指标的综合体现，分数越高，表示生成的图像质量越高，既清晰又多样。</p>
</li>
<li><p><strong>FID分数（Frechet Inception Distance，FID）</strong>：也是评估生成图像质量的重要指标。通过计算生成图像集和真实图像集在Inception网络提取的特征空间中的距离来衡量。具体而言，它计算两个高斯分布之间的Frechet距离，这两个高斯分布分别由真实图像和生成图像在Inception网络某一层的特征统计得到，包括特征的均值和协方差。FID分数越低，表明生成图像的特征分布与真实图像的特征分布越接近，即生成图像在视觉内容和结构上与真实图像越相似，生成模型的性能也就越好。</p>
</li>
</ol>
<h3 id="Background部分"><a href="#Background部分" class="headerlink" title="Background部分"></a>Background部分</h3><h4 id="p-theta-x-0-T-详解"><a href="#p-theta-x-0-T-详解" class="headerlink" title="$p_{\theta}(x_{0:T})$详解"></a>$p_{\theta}(x_{0:T})$详解</h4><p>$p_{\theta}(x_{0:T})$是一个联合概率密度分布，它在扩散模型中描述了包含原始数据$x_0$以及一系列潜在变量$x_1,\cdots,x_T$的联合概率情况。在扩散模型中，$p_{\theta}(x_{0:T})$通常被定义为马尔可夫链形式：$p_{\theta}(x_{0:T}) = p(x_T)\prod_{t = 1}^{T}p_{\theta}(x_{t - 1}|x_t)$ ，其中：</p>
<ul>
<li><strong>$p(x_T)$</strong>：是先验分布，如$p(x_T) = \mathcal{N}(x_T; 0, I)$，表示$x_T$服从均值为$0$、协方差矩阵为单位矩阵$I$的高斯分布，它给出了反向过程起始状态$x_T$的概率分布情况。</li>
<li><p><strong>$\prod_{t = 1}^{T}p_{\theta}(x_{t - 1}|x_t)$</strong>：是从$x_T$到$x_0$的各步条件概率分布的乘积。$p_{\theta}(x_{t - 1}|x_t)$是在参数$\theta$下，从$x_t$到$x_{t - 1}$的条件概率分布，通常也被设定为高斯分布，如$p_{\theta}(x_{t - 1}|x_t) = \mathcal{N}(x_{t - 1}; \mu_{\theta}(x_t, t), \sum_{\theta}(x_t, t))$，由均值函数$\mu_{\theta}(x_t, t)$和协方差矩阵函数$\sum_{\theta}(x_t, t)$决定。这个乘积体现了从$x_T$逐步经过$T$个步骤转移到$x_0$的联合概率关系。</p>
</li>
<li><p><strong>链式法则</strong>：用于计算多个随机变量联合概率的重要工具。对于随机变量序列$x_0,x_1,\cdots,x_T$，其联合概率$p_{\theta}(x_{0:T})$可以根据链式法则展开。链式法则的一般形式为 $p(x_1,x_2,\cdots,x_n)=p(x_n)p(x_{n - 1}|x_n)\cdots p(x_1|x_2,x_3,\cdots,x_n)$。</p>
</li>
</ul>
<h4 id="q-x-1-T-x-0-详解"><a href="#q-x-1-T-x-0-详解" class="headerlink" title="$q(x_{1:T}|x_0)$详解"></a>$q(x_{1:T}|x_0)$详解</h4><p>这个公式描述的是在给定初始状态 $x_0$ 的条件下，状态序列 $x_1,x_2,\cdots,x_T$ 的联合条件概率，它基于马尔可夫性质和概率的链式法则得出，以下详细解释：</p>
<ul>
<li><p><strong>马尔可夫性质</strong>：指的是在已知当前状态的情况下，未来的状态只依赖于当前状态，而与过去的状态无关。在该公式所描述的情境中，假设状态序列 $x_0,x_1,\cdots,x_T$ 构成一个马尔可夫链，即对于任意的 $t$，$x_t$ 只依赖于 $x_{t - 1}$，可表示为 $q(x_t|x_{0:t - 1}) = q(x_t|x_{t - 1})$ 。这意味着在从 $x_0$ 到 $x_T$ 的状态转移过程中，每一步的状态转移只与前一步的状态相关，而不需要考虑更前面的所有状态。</p>
</li>
<li><p><strong>概率的链式法则</strong>：用于计算多个随机变量的联合概率。对于随机变量 $X_1,X_2,\cdots,X_n$，其联合概率 $P(X_1,X_2,\cdots,X_n)$ 可以按照链式法则展开为 $P(X_1,X_2,\cdots,X_n)=P(X_1)P(X_2|X_1)P(X_3|X_1,X_2)\cdots P(X_n|X_1,X_2,\cdots,X_{n - 1})$ 。</p>
</li>
</ul>
<p>结合上述马尔可夫性质，对于条件概率 $q(x_{1:T}|x_0)$（即在给定 $x_0$ 的条件下，$x_1$ 到 $x_T$ 的联合条件概率），根据链式法则原本为 $q(x_{1:T}|x_0)=q(x_1|x_0)q(x_2|x_0,x_1)q(x_3|x_0,x_1,x_2)\cdots q(x_T|x_0,x_1,\cdots,x_{T - 1})$ ，但由于马尔可夫性质，$q(x_2|x_0,x_1)=q(x_2|x_1)$，$q(x_3|x_0,x_1,x_2)=q(x_3|x_2)$ ，以此类推，最终就得到了 $q(x_{1:T}|x_0)=\prod_{t = 1}^{T}q(x_t|x_{t - 1})$ ，即将联合条件概率表示为从 $t = 1$ 到 $t = T$ 每一步相邻状态间条件概率的乘积。</p>
<h3 id="Diffusion-models-and-denoising-autoencoders部分"><a href="#Diffusion-models-and-denoising-autoencoders部分" class="headerlink" title="Diffusion models and denoising autoencoders部分"></a>Diffusion models and denoising autoencoders部分</h3><h4 id="L-0的计算"><a href="#L-0的计算" class="headerlink" title="$L_0的计算$"></a>$L_0的计算$</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u014386899/article/details/136679759">CSDN</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/diffusion/" rel="tag"># diffusion</a>
              <a href="/tags/NeurIPS/" rel="tag"># NeurIPS</a>
              <a href="/tags/2020/" rel="tag"># 2020</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/02/07/diffusion%E5%8E%9F%E7%90%86/" rel="prev" title="diffusion原理">
      <i class="fa fa-chevron-left"></i> diffusion原理
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/02/08/latex%E5%85%AC%E5%BC%8F%E5%A4%A7%E5%85%A8/" rel="next" title="latex公式大全">
      latex公式大全 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E6%96%87%E7%BF%BB%E8%AF%91"><span class="nav-number">1.</span> <span class="nav-text">全文翻译</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Abstract"><span class="nav-number">1.1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Introduction"><span class="nav-number">1.2.</span> <span class="nav-text">Introduction</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Background"><span class="nav-number">1.3.</span> <span class="nav-text">Background</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Diffusion-models-and-denoising-autoencoders"><span class="nav-number">1.4.</span> <span class="nav-text">Diffusion models and denoising autoencoders</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Forward-process-and-L-T"><span class="nav-number">1.4.1.</span> <span class="nav-text">Forward process and $L_{T}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reverse-process-and-L-1-T%E2%88%921"><span class="nav-number">1.4.2.</span> <span class="nav-text">Reverse process and $L_{1:T−1}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Data-scaling-reverse-process-decoder-and-L-0"><span class="nav-number">1.4.3.</span> <span class="nav-text">Data scaling, reverse process decoder, and $L_{0}$</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Simplified-training-objective"><span class="nav-number">1.4.4.</span> <span class="nav-text">Simplified training objective</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Experiments"><span class="nav-number">1.5.</span> <span class="nav-text">Experiments</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Sample-quality"><span class="nav-number">1.5.1.</span> <span class="nav-text">Sample quality</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reverse-process-parameterization-and-training-objective-ablatio"><span class="nav-number">1.5.2.</span> <span class="nav-text">Reverse process parameterization and training objective ablatio</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Progressive-coding"><span class="nav-number">1.5.3.</span> <span class="nav-text">Progressive coding</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Interpolation"><span class="nav-number">1.5.4.</span> <span class="nav-text">Interpolation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Related-Work"><span class="nav-number">1.6.</span> <span class="nav-text">Related Work</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conclusion"><span class="nav-number">1.7.</span> <span class="nav-text">Conclusion</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Broader-Impact"><span class="nav-number">1.8.</span> <span class="nav-text">Broader Impact</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Acknowledgments-and-Disclosure-of-Funding"><span class="nav-number">1.9.</span> <span class="nav-text">Acknowledgments and Disclosure of Funding</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Extra-information"><span class="nav-number">1.10.</span> <span class="nav-text">Extra information</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Extended-derivations"><span class="nav-number">1.11.</span> <span class="nav-text">A Extended derivations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#B-Experimental-details"><span class="nav-number">1.12.</span> <span class="nav-text">B Experimental details</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#C-Discussion-on-related-work"><span class="nav-number">1.13.</span> <span class="nav-text">C Discussion on related work</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#D-Samples"><span class="nav-number">1.14.</span> <span class="nav-text">D Samples</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98"><span class="nav-number">2.</span> <span class="nav-text">问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Abstract%E9%83%A8%E5%88%86"><span class="nav-number">2.1.</span> <span class="nav-text">Abstract部分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%9D%9E%E5%B9%B3%E8%A1%A1%E7%83%AD%E5%8A%9B%E5%AD%A6%E5%90%AF%E5%8F%91%E4%BD%93%E7%8E%B0%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F%E4%B8%8E%E6%9C%97%E4%B9%8B%E4%B8%87%E5%8A%A8%E5%8A%9B%E5%AD%A6%E7%9A%84%E8%81%94%E7%B3%BB%E4%BD%93%E7%8E%B0%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%9F"><span class="nav-number">2.1.1.</span> <span class="nav-text">非平衡热力学启发体现在哪里？与朗之万动力学的联系体现在哪里？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Inception-%E5%88%86%E6%95%B0%E5%92%8CFID-%E5%88%86%E6%95%B0%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">2.1.2.</span> <span class="nav-text">Inception 分数和FID 分数分别是什么？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Background%E9%83%A8%E5%88%86"><span class="nav-number">2.2.</span> <span class="nav-text">Background部分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#p-theta-x-0-T-%E8%AF%A6%E8%A7%A3"><span class="nav-number">2.2.1.</span> <span class="nav-text">$p_{\theta}(x_{0:T})$详解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#q-x-1-T-x-0-%E8%AF%A6%E8%A7%A3"><span class="nav-number">2.2.2.</span> <span class="nav-text">$q(x_{1:T}|x_0)$详解</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Diffusion-models-and-denoising-autoencoders%E9%83%A8%E5%88%86"><span class="nav-number">2.3.</span> <span class="nav-text">Diffusion models and denoising autoencoders部分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#L-0%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">2.3.1.</span> <span class="nav-text">$L_0的计算$</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zongqing Li"
      src="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
  <p class="site-author-name" itemprop="name">Zongqing Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">45</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">40</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/hqulzq" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hqulzq" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hqulzq@163.com" title="E-Mail → mailto:hqulzq@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

      
<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
<div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div id="myCanvasContainer" class="widget tagcloud">
        <canvas width="250" height="250" id="resCanvas" style="width=100%">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/2019/" rel="tag">2019</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2020/" rel="tag">2020</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2021/" rel="tag">2021</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2022/" rel="tag">2022</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bug%E6%80%BB%E7%BB%93/" rel="tag">Bug总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR/" rel="tag">CVPR</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR-Workshop/" rel="tag">CVPR Workshop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/" rel="tag">ICLR</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Knife4j/" rel="tag">Knife4j</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MinIO/" rel="tag">MinIO</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mybatis-Plus/" rel="tag">Mybatis-Plus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NeurIPS/" rel="tag">NeurIPS</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx/" rel="tag">Nginx</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RabbitMQ/" rel="tag">RabbitMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RocketMQ/" rel="tag">RocketMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/" rel="tag">k8s</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/latex/" rel="tag">latex</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/" rel="tag">mongodb</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/" rel="tag">代码随想录</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%B4%E5%87%BD%E6%95%B0/" rel="tag">头函数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%9A%E5%BA%AD%E5%85%AC%E5%AF%93/" rel="tag">尚庭公寓</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/" rel="tag">异常处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" rel="tag">快速入门</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/" rel="tag">技术总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B3%A8%E8%A7%A3/" rel="tag">注解</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%AB%99/" rel="tag">网站</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%8B%A5%E4%BE%9D/" rel="tag">若依</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" rel="tag">设计模式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E8%A1%A8i/" rel="tag">链表i</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/" rel="tag">项目实战</a><span class="tag-list-count">6</span></li></ul>
        </canvas>
    </div>
</div>



    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zongqing Li</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #4D4D4C;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #F7F7F7;
      background-image: linear-gradient(#F7F7F7, #F7F7F7);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>

  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('post.copy_button').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('post.copy_success')
          else $(this).text('post.copy_failure')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('post.copy_button')
        }, 300)
      }).append(e)
    })
  </script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
