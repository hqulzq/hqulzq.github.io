<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hqulzq.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="全文翻译摘要扩散概率模型（DPMs）是新兴的强大生成模型。尽管DPMs具有高质量的生成性能，但它们的采样速度仍然较慢，因为通常需要对大型神经网络进行数百或数千次的顺序函数评估（步骤）才能生成一个样本。从DPMs中采样可以看作是求解相应的扩散常微分方程（ODEs）。在这项工作中，我们提出了扩散ODEs解的精确公式。该公式通过解析计算解的线性部分，而不是像以往工作那样将所有项都留给黑箱ODE求解器处理">
<meta property="og:type" content="article">
<meta property="og:title" content="DPM-Solver-A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps论文精读">
<meta property="og:url" content="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/index.html">
<meta property="og:site_name" content="Lzq&#39;s blog">
<meta property="og:description" content="全文翻译摘要扩散概率模型（DPMs）是新兴的强大生成模型。尽管DPMs具有高质量的生成性能，但它们的采样速度仍然较慢，因为通常需要对大型神经网络进行数百或数千次的顺序函数评估（步骤）才能生成一个样本。从DPMs中采样可以看作是求解相应的扩散常微分方程（ODEs）。在这项工作中，我们提出了扩散ODEs解的精确公式。该公式通过解析计算解的线性部分，而不是像以往工作那样将所有项都留给黑箱ODE求解器处理">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/a1.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/a2.png">
<meta property="og:image" content="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/f2.png">
<meta property="article:published_time" content="2025-03-12T12:59:26.000Z">
<meta property="article:modified_time" content="2025-03-16T14:02:58.886Z">
<meta property="article:author" content="Zongqing Li">
<meta property="article:tag" content="diffusion">
<meta property="article:tag" content="2022">
<meta property="article:tag" content="NeurIPS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/a1.png">

<link rel="canonical" href="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>DPM-Solver-A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps论文精读 | Lzq's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lzq's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">44</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">12</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">59</span></a>

  </li>
        <li class="menu-item menu-item-book">

    <a href="/book" rel="section"><i class="fas fa-book fa-fw"></i>Book</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DPM-Solver-A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps论文精读
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-12 20:59:26" itemprop="dateCreated datePublished" datetime="2025-03-12T20:59:26+08:00">2025-03-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-16 22:02:58" itemprop="dateModified" datetime="2025-03-16T22:02:58+08:00">2025-03-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>扩散概率模型（DPMs）是新兴的强大生成模型。尽管DPMs具有高质量的生成性能，但它们的采样速度仍然较慢，因为通常需要对大型神经网络进行数百或数千次的顺序函数评估（步骤）才能生成一个样本。从DPMs中采样可以看作是求解相应的扩散常微分方程（ODEs）。在这项工作中，我们提出了扩散ODEs解的精确公式。该公式通过解析计算解的线性部分，而不是像以往工作那样将所有项都留给黑箱ODE求解器处理。通过变量变换，解可以等效简化为神经网络的指数加权积分。基于我们的公式，我们提出了DPM-Solver，这是一种快速的、具有收敛阶保证的专用高阶扩散ODE求解器。DPM-Solver适用于离散时间和连续时间的DPMs，且无需任何额外训练。实验结果表明，DPM-Solver在各种数据集上仅需10 - 20次函数评估就能生成高质量样本。在CIFAR10数据集上，我们在10次函数评估中达到了4.70的FID（Frechet Inception Distance），在20次函数评估中达到了2.87的FID，并且与之前最先进的无训练采样器相比，在各种数据集上实现了4 - 16倍的加速。<br><span id="more"></span></p>
<h3 id="2-扩散概率模型"><a href="#2-扩散概率模型" class="headerlink" title="2 扩散概率模型"></a>2 扩散概率模型</h3><p>在本节中，我们将回顾扩散概率模型及其相关的微分方程。</p>
<h4 id="2-1-正向过程和扩散随机微分方程"><a href="#2-1-正向过程和扩散随机微分方程" class="headerlink" title="2.1 正向过程和扩散随机微分方程"></a>2.1 正向过程和扩散随机微分方程</h4><p>假设我们有一个$D$维随机变量$x_{0} \in \mathbb{R}^{D}$，其分布$q_{0}(x_{0})$未知。扩散概率模型（DPMs）[1-3,10]定义了一个从$x_{0}$开始的正向过程$\{x_{t}\}_{t \in[0, T]}$（$T&gt;0$），使得对于任意$t \in[0, T]$，在给定$x_{0}$的条件下，$x_{t}$的分布满足：</p>
<script type="math/tex; mode=display">q_{0 t}\left(x_{t} | x_{0}\right)=\mathcal{N}\left(x_{t} | \alpha(t) x_{0}, \sigma^{2}(t) I\right), \tag{2.1}</script><p>其中$\alpha(t)$、$\sigma(t) \in \mathbb{R}^{+}$是关于$t$的可微函数，且导数有界，为简化表示，我们将它们记为$\alpha_{t}$、$\sigma_{t}$。$\alpha_{t}$和$\sigma_{t}$的选择被称为DPM的噪声调度。令$q_{t}(x_{t})$表示$x_{t}$的边际分布，DPMs通过选择噪声调度，确保对于某个$\bar{\sigma}&gt;0$，有$q_{T}(x_{T}) \approx \mathcal{N}(x_{T} | 0, \tilde{\sigma}^{2} I)$，并且信噪比（SNR）$\alpha_{t}^{2} / \sigma_{t}^{2}$随$t$严格递减[10]。此外，Kingma等人[10]证明，对于任意$t \in[0, T]$，以下随机微分方程（SDE）与公式（2.1）具有相同的转移分布$q_{0 t}(x_{t} | x_{0})$：</p>
<script type="math/tex; mode=display">d x_{t}=f(t) x_{t} d t+g(t) d w_{t}, x_{0} \sim q_{0}\left(x_{0}\right), \tag{2.2}</script><p>其中$w_{t} \in \mathbb{R}^{D}$是标准维纳过程，并且</p>
<script type="math/tex; mode=display">f(t)=\frac{d \log \alpha_{t}}{d t}, g^{2}(t)=\frac{d \sigma_{t}^{2}}{d t}-2 \frac{d \log \alpha_{t}}{d t} \sigma_{t}^{2} \tag{2.3}</script><p>在一些正则条件下，Song等人[3]表明，公式（2.2）中的正向过程存在一个从时间$T$到$0$的等效反向过程，从边际分布$q_{T}(x_{T})$开始：</p>
<script type="math/tex; mode=display">d x_{t}=\left[f(t) x_{t}-g^{2}(t) \nabla_{x} \log q_{t}\left(x_{t}\right)\right] d t+g(t) d \overline{w}_{t}, x_{T} \sim q_{T}\left(x_{T}\right), \tag{2.4}</script><p>其中$\overline{w}_{t}$是反向时间的标准维纳过程。公式（2.4）中唯一未知的项是每个时间$t$的得分函数$\nabla_{x} \log q_{t}(x_{t})$。在实践中，DPMs使用由$\theta$参数化的神经网络$\epsilon_{\theta}(x_{t}, t)$来估计缩放后的得分函数：$-\sigma_{t} \nabla_{x} \log q_{t}(x_{t})$ 。通过最小化以下目标来优化参数$\theta$[2,3]：</p>
<script type="math/tex; mode=display">\begin{aligned} \mathcal{L}(\theta ; \omega(t)) & :=\frac{1}{2} \int_{0}^{T} \omega(t) \mathbb{E}_{q_{t}\left(x_{t}\right)}\left[\left\| \epsilon_{\theta}\left(x_{t}, t\right)+\sigma_{t} \nabla_{x} \log q_{t}\left(x_{t}\right)\right\| _{2}^{2}\right] d t \\ & =\frac{1}{2} \int_{0}^{T} \omega(t) \mathbb{E}_{q_{0}\left(x_{0}\right)} \mathbb{E}_{q(\epsilon)}\left[\left\| \epsilon_{\theta}\left(x_{t}, t\right)-\epsilon\right\| _{2}^{2}\right] d t+C, \end{aligned}</script><p>其中$\omega(t)$是一个加权函数，$\epsilon \sim q(\epsilon)=\mathcal{N}(\epsilon | 0, I)$，$x_{t}=\alpha_{t} x_{0}+\sigma_{t} \epsilon$，$C$是一个与$\theta$无关的常数。由于$\epsilon_{\theta}(x_{t}, t)$也可以被视为预测添加到$x_{t}$的高斯噪声，所以它通常被称为噪声预测模型。由于$\epsilon_{\theta}(x_{t}, t)$的真实值是$-\sigma_{t} \nabla_{x} \log q_{t}(x_{t})$，DPMs用$-\epsilon_{\theta}(x_{t}, t)/\sigma_{t}$替换公式（2.4）中的得分函数，并定义了一个从时间$T$到$0$的参数化反向过程（扩散SDE），从$x_{T} \sim \mathcal{N}(0, \tilde{\sigma}^{2} I)$开始：</p>
<script type="math/tex; mode=display">d x_{t}=\left[f(t) x_{t}+\frac{g^{2}(t)}{\sigma_{t}} \epsilon_{\theta}\left(x_{t}, t\right)\right] d t+g(t) d \overline{w}_{t}, x_{T} \sim \mathcal{N}\left(0, \tilde{\sigma}^{2} I\right) .  \tag{2.5}</script><p>可以使用数值求解器求解公式（2.5）中的扩散SDE来从DPMs生成样本，该数值求解器将SDE从$T$离散到$0$ 。Song等人[3]证明，DPMs传统的祖传采样方法[2]可以看作是公式（2.5）的一阶SDE求解器。然而，这些一阶方法通常需要数百或数千次函数评估才能收敛[3]，导致采样速度极慢。</p>
<h4 id="2-2-扩散（概率流）常微分方程"><a href="#2-2-扩散（概率流）常微分方程" class="headerlink" title="2.2 扩散（概率流）常微分方程"></a>2.2 扩散（概率流）常微分方程</h4><p>在离散化SDE时，步长受到维纳过程随机性的限制[27，第11章]。较大的步长（较少的步数）通常会导致不收敛，尤其是在高维空间中。为了实现更快的采样，可以考虑相关的概率流ODE[3]，它在每个时间$t$的边际分布与SDE相同。具体来说，对于DPMs，Song等人[3]证明了公式（2.4）的概率流ODE为：</p>
<script type="math/tex; mode=display">\frac{d x_{t}}{d t}=f(t) x_{t}-\frac{1}{2} g^{2}(t) \nabla_{x} \log q_{t}\left(x_{t}\right), x_{T} \sim q_{T}\left(x_{T}\right),  \tag{2.6}</script><p>其中$x_{t}$的边际分布也是$q_{t}(x_{t})$ 。通过用噪声预测模型替换得分函数，Song等人[3]定义了以下参数化ODE（扩散ODE）：</p>
<script type="math/tex; mode=display">\frac{d x_{t}}{d t}=h_{\theta}\left(x_{t}, t\right):=f(t) x_{t}+\frac{g^{2}(t)}{2 \sigma_{t}} \epsilon_{\theta}\left(x_{t}, t\right), x_{T} \sim \mathcal{N}\left(0, \tilde{\sigma}^{2} I\right). \tag{2.7}</script><p>可以通过从$T$到$0$求解该ODE来生成样本。与SDE相比，ODE可以使用更大的步长求解，因为它们没有随机性。此外，我们可以利用高效的数值ODE求解器来加速采样。Song等人[3]使用RK45 ODE求解器[28]求解扩散ODE，在CIFAR-10数据集[29]上，该方法通过约60次函数评估生成的样本质量，可与公式（2.5）的1000步SDE求解器相媲美。然而，现有的通用ODE求解器仍然无法在少步（约10步）采样中生成令人满意的样本。据我们所知，目前仍然缺乏适用于少步采样的无训练DPM采样器，DPM的采样速度仍然是一个关键问题。</p>
<h3 id="3-扩散常微分方程的定制快速求解器"><a href="#3-扩散常微分方程的定制快速求解器" class="headerlink" title="3 扩散常微分方程的定制快速求解器"></a>3 扩散常微分方程的定制快速求解器</h3><p>如2.2节所述，在高维情况下离散化随机微分方程（SDEs）通常很困难[27，第11章]，且很难在几步内收敛。相比之下，常微分方程（ODEs）更容易求解，这为快速采样器提供了潜力。然而，正如2.2节提到的，先前工作[3]中使用的通用黑箱ODE求解器在经验上无法在几步内收敛。这促使我们设计一种专门用于扩散ODEs的求解器，以实现快速且高质量的少步采样。我们从详细研究扩散ODEs的具体结构开始。</p>
<h4 id="3-1-扩散常微分方程精确解的简化公式"><a href="#3-1-扩散常微分方程精确解的简化公式" class="headerlink" title="3.1 扩散常微分方程精确解的简化公式"></a>3.1 扩散常微分方程精确解的简化公式</h4><p>这项工作的关键见解是，给定时间$s&gt;0$时的初始值$x_{s}$，式（2.7）中扩散ODEs在每个时间$t&lt;s$的解$x_{t}$可以简化为一个非常特殊的精确公式，并且可以有效地进行近似。</p>
<p>我们的第一个关键观察结果是，考虑到扩散ODEs的特殊结构，解$x_{t}$的一部分可以精确计算。式（2.7）中扩散ODEs的右侧由两部分组成：$f(t)x_{t}$这部分是$x_{t}$的线性函数，而另一部分$\frac{g^{2}(t)}{2\sigma_{t}}\epsilon_{\theta}(x_{t},t)$由于神经网络$\epsilon_{\theta}(x_{t},t)$的存在，通常是$x_{t}$的非线性函数。这种类型的ODE被称为半线性ODE。先前工作[3]采用的黑箱ODE求解器忽略了这种半线性结构，因为它们将式（2.7）中的整个$h_{\theta}(x_{t},t)$作为输入，这导致了线性项和非线性项的离散化误差。我们注意到，对于半线性ODEs，时间$t$的解可以通过 “常数变易” 公式[30]精确表示为：</p>
<script type="math/tex; mode=display">x_{t}=e^{\int_{s}^{t} f(\tau) d \tau} x_{s}+\int_{s}^{t}\left(e^{\int_{\tau}^{t} f(r) d r} \frac{g^{2}(\tau)}{2 \sigma_{\tau}} \epsilon_{\theta}\left(x_{\tau}, \tau\right)\right) d \tau . \tag{3.1}</script><p>这个公式将线性部分和非线性部分解耦。与黑箱ODE求解器不同，现在线性部分被精确计算，消除了线性项的近似误差。然而，非线性部分的积分仍然很复杂，因为它将与噪声调度相关的系数（即$f(\tau)$、$g(\tau)$等）和复杂的神经网络$\epsilon_{\theta}$耦合在一起，仍然难以近似。</p>
<p>我们的第二个关键观察结果是，通过引入一个特殊变量，非线性部分的积分可以大大简化。令$\lambda_{t}:=\log (\alpha_{t} / \sigma_{t})$（即对数信噪比的一半），那么$\lambda_{t}$是$t$的严格递减函数（根据2.1节中对DPMs的定义）。我们可以将式（2.3）中的$g(t)$重写为：</p>
<script type="math/tex; mode=display">g^{2}(t)=\frac{d \sigma_{t}^{2}}{d t}-2 \frac{d \log \alpha_{t}}{d t} \sigma_{t}^{2}=2 \sigma_{t}^{2}\left(\frac{d \log \sigma_{t}}{d t}-\frac{d \log \alpha_{t}}{d t}\right)=-2 \sigma_{t}^{2} \frac{d \lambda_{t}}{d t} .\tag{3.2}</script><p>结合式（2.3）中的$f(t)=d \log \alpha_{t} / d t$，我们可以将式（3.1）重写为：</p>
<script type="math/tex; mode=display">x_{t}=\frac{\alpha_{t}}{\alpha_{s}} x_{s}-\alpha_{t} \int_{s}^{t}\left(\frac{d \lambda_{\tau}}{d \tau}\right) \frac{\sigma_{\tau}}{\alpha_{\tau}} \epsilon_{\theta}\left(x_{\tau}, \tau\right) d \tau .\tag{3.3}</script><p>由于$\lambda(t)=\lambda_{t}$是$t$的严格递减函数，它有一个反函数$t_{\lambda}(\cdot)$，满足$t=t_{\lambda}(\lambda(t))$。我们进一步将$x$和$\epsilon_{\theta}$的下标从$t$改为$\lambda$，并表示$\hat{x}_{\lambda}:=x_{t_{\lambda}(\lambda)}$，$\hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda):=\epsilon_{\theta}(x_{t_{\lambda}(\lambda)}, t_{\lambda}(\lambda))$。通过对$\lambda$进行 “变量变换” 重写式（3.3），我们得到：</p>
<p><strong>命题3.1（扩散ODEs的精确解）</strong>：给定时间$s&gt;0$时的初始值$x_{s}$，式（2.7）中扩散ODEs在时间$t \in[0, s]$的解$x_{t}$为：</p>
<script type="math/tex; mode=display">x_{t}=\frac{\alpha_{t}}{\alpha_{s}} x_{s}-\alpha_{t} \int_{\lambda_{s}}^{\lambda_{t}} e^{-\lambda} \hat{\epsilon}_{\theta}\left(\hat{x}_{\lambda}, \lambda\right) d \lambda . \tag{3.4}</script><p>我们将积分$\int e^{-\lambda} \hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda) d \lambda$称为$\hat{\epsilon}_{\theta}$的指数加权积分，它非常特殊，并且与ODE求解器文献中的指数积分器[25]密切相关。据我们所知，在扩散模型的先前工作中尚未揭示这种公式。</p>
<p>式（3.4）为近似扩散ODEs的解提供了新的视角。具体来说，给定时间$s$的$x_{s}$，根据式（3.4），近似时间$t$的解等同于直接近似从$\lambda_{s}$到$\lambda_{t}$的$\hat{\epsilon}_{\theta}$的指数加权积分，这避免了线性项的误差，并且在指数积分器的文献[25, 31]中已有深入研究。基于这一见解，我们提出了用于扩散ODEs的快速求解器，详见以下章节。</p>
<h4 id="3-2-扩散常微分方程的高阶求解器"><a href="#3-2-扩散常微分方程的高阶求解器" class="headerlink" title="3.2 扩散常微分方程的高阶求解器"></a>3.2 扩散常微分方程的高阶求解器</h4><p>在本节中，我们利用所提出的解公式（3.4），提出了具有收敛阶保证的扩散ODEs高阶求解器。所提出的求解器和分析受到ODE文献中指数积分器方法[25, 31]的启发。</p>
<p>具体来说，给定时间$T$的初始值$x_{T}$和从$t_{0}=T$到$t_{M}=0$递减的$M + 1$个时间步$\{t_{i}\}_{i = 0}^{M}$。令$\tilde{x}_{t_{0}} = x_{T}$为初始值。所提出的求解器使用$M$步迭代计算序列$\{\tilde{x}_{t_{i}}\}_{i = 0}^{M}$，以近似时间步$\{t_{i}\}_{i = 0}^{M}$的真实解。特别地，最后一次迭代$\tilde{x}_{t_{M}}$近似时间$0$的真实解。</p>
<p>为了减少$\tilde{x}_{t_{M}}$与时间$0$真实解之间的近似误差，我们需要在每一步减少$\tilde{x}_{t_{i}}$的近似误差[30]。从时间$t_{i - 1}$的先前值$\tilde{x}_{t_{i - 1}}$开始，根据式（3.4），时间$t_{i}$的精确解$x_{t_{i - 1} \to t_{i}}$为：</p>
<script type="math/tex; mode=display">x_{t_{i - 1} \to t_{i}}=\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \overline{x}_{t_{i - 1}}-\alpha_{t_{i}} \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_{i}}} e^{-\lambda} \hat{\epsilon}_{\theta}\left(\hat{x}_{\lambda}, \lambda\right) d \lambda .\tag{3.5}</script><p>因此，为了计算用于近似$x_{t_{i - 1} \to t_{i}}$的$\tilde{x}_{t_{i}}$值，我们需要近似从$\lambda_{t_{i - 1}}$到$\lambda_{t_{i}}$的$\hat{\epsilon}_{\theta}$的指数加权积分。记$h_{i}:=\lambda_{t_{i}}-\lambda_{t_{i - 1}}$，$\hat{\epsilon}_{\theta}^{(n)}(\hat{x}_{\lambda}, \lambda):=\frac{d^{n} \hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda)}{d \lambda^{n}}$为$\hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda)$关于$\lambda$的$n$阶全导数。对于$k \geq 1$，$\hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda)$在$\lambda_{t_{i - 1}}$处关于$\lambda$的$(k - 1)$阶泰勒展开式为：</p>
<script type="math/tex; mode=display">\hat{\epsilon}_{\theta}\left(\hat{x}_{\lambda}, \lambda\right)=\sum_{n = 0}^{k - 1} \frac{\left(\lambda-\lambda_{t_{i - 1}}\right)^{n}}{n!} \hat{\epsilon}_{\theta}^{(n)}\left(\hat{x}_{\lambda_{t_{i - 1}}}, \lambda_{t_{i - 1}}\right)+\mathcal{O}\left(\left(\lambda-\lambda_{t_{i - 1}}\right)^{k}\right) .</script><p>将上述泰勒展开式代入式（3.5），得到：</p>
<script type="math/tex; mode=display">x_{t_{i - 1} \to t_{i}}=\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \tilde{x}_{t_{i - 1}}-\alpha_{t_{i}} \sum_{n = 0}^{k - 1} \hat{\epsilon}_{\theta}^{(n)}\left(\hat{x}_{\lambda_{t_{i - 1}}}, \lambda_{t_{i - 1}}\right) \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_{i}}} e^{-\lambda} \frac{\left(\lambda-\lambda_{t_{i - 1}}\right)^{n}}{n!} d \lambda+\mathcal{O}\left(h_{i}^{k + 1}\right) .\tag{3.6}</script><p>其中积分$\int e^{-\lambda} \frac{(\lambda-\lambda_{t_{i - 1}})^{n}}{n!} d \lambda$可以通过反复应用$n$次分部积分法进行解析计算（见附录B.2）。因此，为了近似$x_{t_{i - 1} \to t_{i}}$，我们只需要近似$n \leq k - 1$时的$n$阶全导数$\hat{\epsilon}_{\theta}^{(n)}(\hat{x}_{\lambda}, \lambda)$，这在ODE文献[31, 32]中是一个研究得较为充分的问题。通过舍弃$O(h_{i}^{k + 1})$误差项，并使用 “刚性阶条件” [31, 32]近似前$(k - 1)$阶全导数，我们可以推导出用于扩散ODEs的$k$阶ODE求解器。我们将这类求解器统称为DPM-Solver，对于特定的阶数$k$，则称为DPM-Solver-$k$。这里我们以$k = 1$为例进行说明。在这种情况下，式（3.6）变为：</p>
<script type="math/tex; mode=display">\begin{aligned} x_{t_{i - 1} \to t_{i}} & =\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \overline{x}_{t_{i - 1}}-\alpha_{t_{i}} \epsilon_{\theta}\left(\tilde{x}_{t_{i - 1}}, t_{i - 1}\right) \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_{i}}} e^{-\lambda} d \lambda+\mathcal{O}\left(h_{i}^{2}\right) \\ & =\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \tilde{x}_{t_{i - 1}}-\sigma_{t_{i}}\left(e^{h_{i}} - 1\right) \epsilon_{\theta}\left(\tilde{x}_{t_{i - 1}}, t_{i - 1}\right)+\mathcal{O}\left(h_{i}^{2}\right) 。 \end{aligned}</script><p>通过舍弃高阶误差项$O(h_{i}^{2})$，我们可以得到$x_{t_{i - 1} \to t_{i}}$的近似值。由于这里$k = 1$，我们将这个求解器称为DPM-Solver-1，详细算法如下：</p>
<p><strong>DPM-Solver-1</strong>：给定初始值$x_{T}$和从$t_{0}=T$到$t_{M}=0$递减的$M + 1$个时间步$\{t_{i}\}_{i = 0}^{M}$。从$\tilde{x}_{t_{0}} = x_{T}$开始，序列$\{\tilde{x}_{t_{i}}\}_{i = 1}^{M}$通过以下方式迭代计算：</p>
<script type="math/tex; mode=display">\tilde{x}_{t_{i}}=\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \tilde{x}_{t_{i - 1}}-\sigma_{t_{i}}\left(e^{h_{i}} - 1\right) \epsilon_{\theta}\left(\tilde{x}_{t_{i - 1}}, t_{i - 1}\right), \text{其中} h_{i}=\lambda_{t_{i}}-\lambda_{t_{i - 1}} . \tag{3.7}</script><p>对于$k \geq 2$，近似泰勒展开式的前$k$项需要在$t$和$s$之间设置额外的中间点[31]。推导过程更具技术性，因此我们将其推迟到附录B。下面我们提出$k = 2, 3$的算法，并分别将它们命名为DPM-Solver-2和DPM-Solver-3。</p>
<p><img src="a1.png" alt=""><br><img src="a2.png" alt=""></p>
<p>在这里，$t_{\lambda}(\cdot)$ 是 $\lambda(t)$ 的反函数，对于文献[2, 16]中使用的实际噪声调度，它有一个解析表达式，如附录D所示。对于二阶龙格 - 库塔扩散概率模型求解器（DPM - Solver - 2），选择的中间点是 $(s_{i}, u_{i})$ ，对于三阶龙格 - 库塔扩散概率模型求解器（DPM - Solver - 3），选择的中间点是 $(s_{2i - 1}, u_{2i - 1})$ 和 $(s_{2i}, u_{2i})$ 。如算法中所示，对于 $k = 1, 2, 3$，DPM - Solver - $k$ 每一步需要 $k$ 次函数求值。尽管高阶求解器（$k = 2, 3$）的每一步计算成本更高，但由于它们的收敛阶更高，达到收敛所需的步数要少得多，所以通常效率更高。我们证明了 DPM - Solver - $k$ 是 $k$ 阶求解器，如以下定理所述。证明见附录B。</p>
<p><strong>定理3.2（DPM - Solver - $k$ 作为 $k$ 阶求解器）</strong> 假设 $\epsilon_{\theta}(x_{t}, t)$ 满足附录B.1中详细说明的正则条件，那么对于 $k = 1, 2, 3$ ，DPM - Solver - $k$ 是扩散常微分方程（ODE）的 $k$ 阶求解器，也就是说，对于由DPM - Solver - $k$ 计算得到的序列 $\{\tilde{x}_{t_{i}}\}_{i = 1}^{M}$ ，在时间 $t = 0$ 处的近似误差满足 $\tilde{x}_{t_{M}} - x_{0} = \mathcal{O}(h_{max}^{k})$ ，其中 $h_{max} = \max_{1\leq i\leq M}(\lambda_{t_{i}} - \lambda_{t_{i - 1}})$ 。</p>
<p>最后，如先前关于指数积分器的文献[31, 32]所示，$k\geq4$ 的求解器需要更多的中间点。因此，在这项工作中我们仅考虑 $k$ 从1到3 的情况，而将更高 $k$ 值的求解器留待未来研究。</p>
<h3 id="3-3-步长调度"><a href="#3-3-步长调度" class="headerlink" title="3.3 步长调度"></a>3.3 步长调度</h3><p>3.2节中提出的求解器需要预先指定时间步${t_{i}}_{i = 0}^{M}$。我们提出了两种步长调度的选择。一种是手动设定的，即均匀划分区间$[\lambda_{T}, \lambda_{0}]$，也就是$\lambda_{t_{i}} = \lambda_{T} + \frac{i}{M}(\lambda_{0} - \lambda_{T})$，其中$i = 0, \ldots, M$。需要注意的是，这与之前的工作[2, 3]不同，之前的工作是对$t_{i}$选择均匀的时间步。从经验上看，采用均匀时间步长$\lambda_{t_{i}}$的DPM-Solver已经能够在几步内生成相当不错的样本，附录E中列出了相关结果。作为另一种选择，我们提出了一种自适应步长算法，通过结合不同阶数的DPM-Solver来动态调整步长。这种自适应算法的灵感来自于[20]，我们将其实现细节放在附录C中。</p>
<p>对于少步采样，我们需要充分利用所有的函数评估次数（NFE）。当NFE不能被3整除时，我们首先尽可能多地应用DPM-Solver-3，然后根据NFE除以3的余数，添加单步的DPM-Solver-1或DPM-Solver-2（具体取决于余数），附录D中有详细说明。在后续实验中，对于NFE ≤ 20的情况，我们使用这种结合均匀步长调度的求解器组合；对于其他情况，则使用自适应步长调度。</p>
<h3 id="3-4-从离散时间扩散概率模型采样"><a href="#3-4-从离散时间扩散概率模型采样" class="headerlink" title="3.4 从离散时间扩散概率模型采样"></a>3.4 从离散时间扩散概率模型采样</h3><p>离散时间扩散概率模型（DPMs）[2]在$N$个固定时间步${t_{n}}_{n = 1}^{N}$训练噪声预测模型，噪声预测模型由$\tilde{\epsilon}_{\theta}(x_{n}, n)$参数化，其中$n = 0, \ldots, N - 1$，每个$x_{n}$对应于时间$t_{n + 1}$的值。我们可以通过令$\epsilon_{\theta}(x, t):=\tilde{\epsilon}_{\theta}(x, \frac{(N - 1)t}{T})$，将离散时间噪声预测模型转换为连续版本，其中$x \in \mathbb{R}^{d}$，$t \in [0, T]$。注意，$\tilde{\epsilon}_{\theta}$的输入时间可能不是整数，但我们发现噪声预测模型仍然能够很好地工作，我们推测这是因为平滑的时间嵌入（例如位置嵌入[2]）。通过这种重新参数化，噪声预测模型可以采用连续时间步作为输入，因此我们也可以使用DPM-Solver进行快速采样。</p>
<h3 id="4-与现有快速采样方法的比较"><a href="#4-与现有快速采样方法的比较" class="headerlink" title="4 与现有快速采样方法的比较"></a>4 与现有快速采样方法的比较</h3><p>在此，我们探讨DPM-Solver与现有的基于ODE的DPM快速采样方法之间的关系，并突出它们的差异。我们还将简要讨论无训练采样器相较于有训练采样器的优势。</p>
<h4 id="4-1-作为DPM-Solver-1的DDIM"><a href="#4-1-作为DPM-Solver-1的DDIM" class="headerlink" title="4.1 作为DPM-Solver-1的DDIM"></a>4.1 作为DPM-Solver-1的DDIM</h4><p>去噪扩散隐式模型（DDIM）[19]设计了一种用于从DPM快速采样的确定性方法。对于两个相邻的时间步$t_{i - 1}$和$t_{i}$，假设在时间$t_{i - 1}$我们有一个解$\tilde{x}_{t_{i - 1}}$，那么从时间$t_{i - 1}$到$t_{i}$的DDIM单步更新为：</p>
<script type="math/tex; mode=display">\overline{x}_{t_{i}}=\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \overline{x}_{t_{i - 1}}-\alpha_{t_{i}}\left(\frac{\sigma_{t_{i - 1}}}{\alpha_{t_{i - 1}}}-\frac{\sigma_{t_{i}}}{\alpha_{t_{i}}}\right) \epsilon_{\theta}\left(\overline{x}_{t_{i - 1}}, t_{i - 1}\right) 。</script><p>尽管动机完全不同，但我们发现DPM-Solver-1和去噪扩散隐式模型（DDIM）[19]的更新是相同的。根据$\lambda$的定义，我们有$\frac{\sigma_{t_{i - 1}}}{\alpha_{t_{i - 1}}}=e^{-\lambda_{t_{i - 1}}}$和$\frac{\sigma_{t_{i}}}{\alpha_{t_{i}}}=e^{-\lambda_{t_{i}}}$。将这些以及$h_{i}=\lambda_{t_{i}}-\lambda_{t_{i - 1}}$代入公式（4.1），得到的结果与公式（3.7）中DPM-Solver-1的一步更新完全一致。然而，DPM-Solver的半线性ODE公式允许有原则地推广到高阶求解器，并进行收敛阶分析。</p>
<p>最近的工作[13]也表明，通过对公式（4.1）两边求导，DDIM是扩散ODE的一阶离散化。然而，他们无法解释DDIM与扩散ODE的一阶欧拉离散化之间的差异。相比之下，通过证明DDIM是DPM-Solver的一个特殊情况，我们揭示了DDIM充分利用了扩散ODE的半线性，这解释了它相较于传统欧拉方法的优越性。</p>
<h4 id="4-2-与传统龙格-库塔方法的比较"><a href="#4-2-与传统龙格-库塔方法的比较" class="headerlink" title="4.2 与传统龙格 - 库塔方法的比较"></a>4.2 与传统龙格 - 库塔方法的比较</h4><p>通过将传统的显式龙格 - 库塔（RK）方法直接应用于公式（2.7）中的扩散ODE，可以得到一个高阶求解器。具体来说，RK方法将公式（2.7）的解写成以下积分形式：</p>
<script type="math/tex; mode=display">x_{t}=x_{s}+\int_{s}^{t} h_{\theta}\left(x_{\tau}, \tau\right) d \tau=x_{s}+\int_{s}^{t}\left(f(\tau) x_{\tau}+\frac{g^{2}(\tau)}{2 \sigma_{\tau}} \epsilon_{\theta}\left(x_{\tau}, \tau\right)\right) d \tau,</script><p>并在$[t, s]$之间使用一些中间时间步，结合$h_{\theta}$在这些时间步的评估值来近似整个积分。显式RK方法的近似误差取决于$h_{\theta}$，它包含了与线性项$f(\tau) x_{\tau}$和非线性噪声预测模型$\epsilon_{\theta}$相对应的误差。然而，由于线性项的精确解具有指数系数（如公式（3.1）所示），线性项的误差可能会呈指数增长。有许多经验证据[25, 31]表明，对于半线性ODEs，直接使用显式RK方法在大步长情况下可能会遇到数值不稳定问题。我们在5.1节中也展示了所提出的DPM-Solver与传统显式RK方法在经验上的差异，结果表明在相同阶数下，DPM-Solver的离散化误差比RK方法更小。</p>
<h4 id="4-3-基于训练的DPM快速采样方法"><a href="#4-3-基于训练的DPM快速采样方法" class="headerlink" title="4.3 基于训练的DPM快速采样方法"></a>4.3 基于训练的DPM快速采样方法</h4><p>需要额外训练或优化的采样器包括知识蒸馏[13, 14]、学习噪声水平或方差[15, 16, 33]以及学习噪声调度或样本轨迹[17, 18]。尽管渐进蒸馏方法[13]可以在4步内获得快速采样器，但它需要额外的训练成本，并且会丢失原始DPM中的部分信息（例如，蒸馏后，噪声预测模型无法预测$[0, T]$之间每个时间步的噪声（得分函数））。相比之下，无训练采样器可以保留原始模型的所有信息，从而可以通过将原始模型与外部分类器结合直接扩展到条件采样（例如，见附录D中带分类器引导的条件采样）。</p>
<p>除了直接为DPM设计快速采样器外，一些工作还提出了新型的DPM，以支持更快的采样。例如，为DPM定义低维潜在变量[34]；设计具有有界得分函数的特殊扩散过程[35]；将GAN与DPM的反向过程相结合[36]。所提出的DPM-Solver也可能适用于加速这些DPM的采样，我们将其留作未来的工作。</p>
<h3 id="5-实验"><a href="#5-实验" class="headerlink" title="5 实验"></a>5 实验</h3><p>在本节中，我们展示了作为一种无需训练的采样器，DPM - Solver（扩散概率模型求解器）能够显著加快现有预训练扩散概率模型（DPMs）的采样速度，这些模型既包括连续时间的，也包括离散时间的，并且涵盖了线性噪声调度[2, 19]和余弦噪声调度[16]。我们改变函数评估次数（NFE，即对噪声预测模型$\epsilon_{\theta}(x_{t}, t)$ 的调用次数），并比较DPM - Solver与其他方法生成样本的质量。在每个实验中，我们生成50000个样本，并使用广泛采用的弗雷歇初始距离（FID）分数[37]来评估样本质量，通常FID分数越低意味着样本质量越好。</p>
<p>除非另有明确说明，若函数评估次数（NFE）预算小于20，我们始终采用3.3节中结合均匀步长调度的求解器组合；否则，采用3.3节中结合自适应步长调度的三阶龙格 - 库塔扩散概率模型求解器（DPM - Solver - 3）。关于DPM - Solver的其他实现细节，请参见附录D，详细设置请参见附录E。</p>
<h4 id="5-1-与连续时间采样方法的比较"><a href="#5-1-与连续时间采样方法的比较" class="headerlink" title="5.1 与连续时间采样方法的比较"></a>5.1 与连续时间采样方法的比较</h4><p>我们首先将DPM-Solver与其他用于扩散概率模型（DPMs）的连续时间采样方法进行比较。对比的方法包括扩散随机微分方程（SDE）的欧拉-丸山离散化方法[3]、扩散SDE的自适应步长求解器[20]以及用于扩散常微分方程（ODE）的龙格-库塔（RK）方法[3, 28]（见公式(2.7)）。我们从在CIFAR-10数据集[29]上预训练的连续时间 “VP deep” 模型中进行采样，该模型采用线性噪声调度，以此来对比这些方法。</p>
<p>图2a展示了对比求解器的效率。对于使用欧拉离散化的扩散SDE，我们采用均匀时间步长，分别设置50、200、1000次函数评估（NFE）；对于自适应步长的SDE求解器[20]和RK45 ODE求解器[28]，我们通过调整容差超参数来控制NFE。DPM-Solver能够在约10次NFE内生成高质量样本，而其他求解器即使在50次NFE时仍有较大的离散化误差，这表明DPM-Solver相比之前最优的求解器实现了约5倍的加速。具体而言，我们在10次NFE时达到4.70的FID，12次NFE时为3.75，15次NFE时为3.24，20次NFE时为2.87，在CIFAR-10数据集上，这是最快的采样器。</p>
<p>作为一项消融研究，我们还对比了二阶和三阶的DPM-Solver与RK方法，结果见表1。我们对扩散ODE的RK方法分别基于时间t（公式(2.7)）和半对数信噪比λ（通过变量变换，详见附录E.1中的具体公式）进行比较。结果表明，在相同NFE的情况下，DPM-Solver生成的样本质量始终优于相同阶数的RK方法。DPM-Solver在15次NFE以下的少步采样场景中的卓越效率尤为明显，此时RK方法存在较大的离散化误差。这主要是因为DPM-Solver通过解析计算线性项，避免了相应的离散化误差。此外，更高阶的DPM-Solver-3比DPM-Solver-2收敛更快，这与定理3.2中的阶数分析相符。</p>
<h4 id="5-2-与离散时间采样方法的比较"><a href="#5-2-与离散时间采样方法的比较" class="headerlink" title="5.2 与离散时间采样方法的比较"></a>5.2 与离散时间采样方法的比较</h4><p>我们采用3.4节中的方法，将DPM-Solver应用于离散时间扩散概率模型（DPMs），随后将其与其他无需训练的离散时间采样器进行比较，这些采样器包括去噪扩散概率模型（DDPM）[2]、去噪扩散隐式模型（DDIM）[19]、解析去噪扩散概率模型（Analytic-DDPM）[21]、解析去噪扩散隐式模型（Analytic-DDIM）[21]、伪数值方法（PNDM）[22]、快速扩散概率模型采样（FastDPM）[38]以及伊藤 - 泰勒（Itô-Taylor）方法[24]。我们还与生成引导扩散模型（GGDM）[18]进行了对比，GGDM使用相同的预训练模型，但需要对采样轨迹进行进一步训练。我们通过将函数评估次数（NFE）从10变化到1000，来比较样本质量。</p>
<p>具体来说，我们使用文献[2]中通过$L_{simple }$训练的具有线性噪声调度的CIFAR-10数据集上的离散时间模型；文献[19]中具有线性噪声调度的CelebA 64x64数据集[39]上的离散时间模型；文献[16]中通过$L_{hybrid }$训练的具有余弦噪声调度的ImageNet 64x64数据集[26]上的离散时间模型；文献[4]中具有线性噪声调度和分类器引导的ImageNet 128x128数据集[26]上的离散时间模型；文献[4]中具有线性噪声调度的LSUN卧室256x256数据集[40]上的离散时间模型。对于在ImageNet上训练的模型，我们仅使用其 “均值” 模型，忽略 “方差” 模型。如图2所示，在所有数据集上，DPM-Solver能够在12步内获得质量合理的样本（CIFAR-10数据集上FID为4.65，CelebA 64x64数据集上为3.71，ImageNet 64x64数据集上为19.97，ImageNet 128x128数据集上为4.08），比之前最快的无需训练的采样器快4 - 16倍。DPM-Solver甚至优于需要额外训练的GGDM。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f2.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图2：使用不同采样方法从扩散概率模型（DPMs）中采样的样本质量，通过弗雷歇初始距离（FID）衡量。这些方法应用于CIFAR-10数据集上的连续时间和离散时间模型、CelebA 64x64数据集、ImageNet 64x64数据集、ImageNet 128x128数据集以及LSUN卧室256x256数据集的离散时间模型，并改变函数评估次数（NFE）。方法†GGDM [18] 需要额外训练以优化采样轨迹，而其他方法无需训练。为获得最强的基线结果，在CelebA数据集上对去噪扩散隐式模型（DDIM）使用二次步长，其FID比原始论文[19]中均匀步长的FID更优。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h3><p>我们解决了从扩散概率模型（DPMs）进行快速且无需训练的采样问题。我们提出了DPM-Solver，这是一种快速、专门用于求解扩散常微分方程（ODE）的无需训练的求解器，可在约10次函数评估步骤内实现对DPMs的快速采样。DPM-Solver利用了扩散ODE的半线性结构，直接逼近扩散ODE精确解的简化公式，该公式由噪声预测模型的指数加权积分构成。受指数积分器数值方法的启发，我们提出了一阶、二阶和三阶的DPM-Solver，以在理论上保证收敛的情况下逼近噪声预测模型的指数加权积分。我们提出了手动设定和自适应的步长调度，并将DPM-Solver应用于连续时间和离散时间的DPMs。我们的实验结果表明，DPM-Solver可以在各种数据集上，通过约10次函数评估生成高质量样本，与之前最先进的无需训练的采样器相比，实现了4 - 16倍的加速。</p>
<h4 id="局限性和更广泛的影响"><a href="#局限性和更广泛的影响" class="headerlink" title="局限性和更广泛的影响"></a>局限性和更广泛的影响</h4><p>尽管DPM-Solver在加速性能方面前景良好，但它是为快速采样而设计的，可能不适用于加速DPMs的似然评估。此外，与常用的生成对抗网络（GANs）相比，使用DPM-Solver的扩散模型在实时应用中仍然不够快。另外，与其他深度生成模型一样，DPMs可能被用于生成有害的虚假内容，而本文提出的求解器可能会进一步放大深度生成模型在恶意应用中的潜在不良影响。</p>
<h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><h3 id="3-扩散常微分方程的定制快速求解器-1"><a href="#3-扩散常微分方程的定制快速求解器-1" class="headerlink" title="3 扩散常微分方程的定制快速求解器"></a>3 扩散常微分方程的定制快速求解器</h3><h4 id="公式3-4的推导"><a href="#公式3-4的推导" class="headerlink" title="公式3.4的推导"></a>公式3.4的推导</h4><script type="math/tex; mode=display">
\begin{align*}
\mathbf{x}_t &= \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{s}^{t} \left( \frac{\mathrm{d}\lambda_{\tau}}{\mathrm{d}\tau} \right) \frac{\sigma_{\tau}}{\alpha_{\tau}} \epsilon_{\theta}(\mathbf{x}_{\tau}, \tau) \mathrm{d}\tau \\
&= \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} \left( \frac{\mathrm{d}\lambda_{\tau}}{\mathrm{d}\tau} \right) \frac{\sigma_{t_{\lambda}(\lambda)}}{\alpha_{t_{\lambda}(\lambda)}} \epsilon_{\theta}(\mathbf{x}_{t_{\lambda}(\lambda)}, t_{\lambda}(\lambda)) \frac{\mathrm{d}\tau}{\mathrm{d}\lambda} \mathrm{d}\lambda \\

&= \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} \frac{\sigma_{t_{\lambda}(\lambda)}}{\alpha_{t_{\lambda}(\lambda)}} \epsilon_{\theta}(\mathbf{x}_{t_{\lambda}(\lambda)}, t_{\lambda}(\lambda)) \mathrm{d}\lambda \\
&又 {\lambda_t} = \log{\frac{\alpha_t}{\sigma_t}}，得：\\
&= \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \hat{\epsilon}_{\theta}(\hat{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda
\end{align*}</script><h4 id="DPM-Solver-K"><a href="#DPM-Solver-K" class="headerlink" title="DPM-Solver-K"></a>DPM-Solver-K</h4><script type="math/tex; mode=display">x_t = \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \hat{\epsilon}_{\theta}(\hat{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda \tag{28}</script><p>由于通常的采样过程都是离散形式的，假设这个采样过程经过$M + 1$步完成，也即有$M + 1$个时间点序列$\{t_i\}_{i = 0}^M$，其中$t_0 = T$，$t_M = 0$，$t$随着$i$的增加严格单调递减。$M + 1$个时间点对应$M$个采样步骤，采样初始值$\tilde{x}_{t_0}=x_T$，采样终点$\tilde{x}_{t_M}$要尽可能的接近真实的解$x_0$。论文所有带波浪线上标的都是采样估计值，不带波浪线的都是真实值！有了上述假设，基于公式(28)就可以写出单步采样公式，形式如下：</p>
<script type="math/tex; mode=display">\mathbf{x}_{t_{i - 1} \to t_i} = \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}}\tilde{\mathbf{x}}_{t_{i - 1}} - \alpha_{t_i} \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_i}} e^{-\lambda} \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda \tag{29}</script><p>观察公式(29)，公式右边的第二部分，也即：</p>
<script type="math/tex; mode=display">\alpha_{t_i} \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_i}} e^{-\lambda} \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda \tag{30}</script><p>这是一个对神经网络输出$\hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda)$的指数加权积分，还没有很好的求解计算手段。既然没办法直接求得精确值，我们的核心目标就是得到一个对于公式(30)的近似，这个近似可以通过代码实现且误差较小。好了，到目前为止有没有思路了，毫无头绪，但一想到近似，又不得不喊出我们心中的四字法则——泰勒救我！不失一般性，同时为了和论文附录的推导过程对应，这里还是令起点时间为$s$，终点时间为$t$，有$t &lt; s$，$\lambda_t &gt; \lambda_s$。试着对公式(30)中唯一的不稳定项$\hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda)$进行泰勒展开。在哪个点展开呢？记住已知点法则，很显然起始点$s$的信息是已知的，也即$\lambda_s$的信息是已知的，那我们就在该点展开$n$阶。注意，这里视$\hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda)$为$\lambda$的函数，泰勒展开中的导数项为全导数形式：</p>
<script type="math/tex; mode=display">\hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda) = \sum_{k = 0}^{n} \frac{(\lambda - \lambda_s)^k}{k!} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) + \mathcal{O}(h^{n + 1}) \tag{31}</script><p>其中，$h := \lambda_t - \lambda_s$，$\hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda}, \lambda)$是关于$\lambda$的$k$阶全导数，也即：</p>
<script type="math/tex; mode=display">\hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda}, \lambda) = \frac{\mathrm{d}^k \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda)}{\mathrm{d}\lambda^k} \tag{32}</script><p>公式(30)对应的指数加权积分是数学中研究的比较“透”的部分，为了更好的分析这个指数加权积分，定义：</p>
<script type="math/tex; mode=display">\varphi_k(z) := \int_{0}^{1} e^{(1 - \delta)z} \frac{\delta^{k - 1}}{(k - 1)!} \mathrm{d}\delta, \quad \varphi_0(z) = e^z \tag{33}</script><p>目前来看，这个式子并没有什么用处。别急，先把公式(31)的泰勒展开代入公式(30)中，同时替换积分上下限时间为$s$和$t$，有：</p>
<script type="math/tex; mode=display">
\alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \sum_{k = 0}^{n} \frac{(\lambda - \lambda_s)^k}{k!} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) \mathrm{d}\lambda + \mathcal{O}(h^{n + 2}) \tag{34}</script><p>这个形式有一部分就和公式(33)有点像了，很明显$\lambda - \lambda_s$好像就是$\delta$，但是积分上下限不满足，指数项也不同。论文令$h := \lambda_t - \lambda_s$，积分上下限调整可用换元法。假定$\lambda = \lambda_t + (\delta - 1)h$成立，当$\delta = 0$时，$\lambda = \lambda_t - h = \lambda_s$对应积分下限，当$\delta = 1$时，$\lambda = \lambda_t$对应积分上限，$\mathrm{d}\lambda = \mathrm{d}(\lambda_t + (\delta - 1)h) = h\mathrm{d}\delta$。由此可以完成积分换元，公式(34)可以变为：</p>
<script type="math/tex; mode=display">
\begin{align*}
&\alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \sum_{k = 0}^{n} \frac{(\lambda - \lambda_s)^k}{k!} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) \mathrm{d}\lambda + \mathcal{O}(h^{n + 2})\\
=&\alpha_t \int_{0}^{1} e^{-\lambda_t - (\delta - 1)h} \sum_{k = 0}^{n} \frac{(\delta h)^k}{k!} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) h\mathrm{d}\delta + \mathcal{O}(h^{n + 2})\\
=&\sum_{k = 0}^{n} \alpha_t e^{-\lambda_t} h^{k + 1} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) \int_{0}^{1} e^{(1 - \delta)h} \frac{\delta^k}{k!} \mathrm{d}\delta + \mathcal{O}(h^{n + 2})\\
=&\sum_{k = 0}^{n} \alpha_t \frac{\sigma_t}{\alpha_t} h^{k + 1} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) \varphi_{k + 1}(h) + \mathcal{O}(h^{n + 2})\\
=&\sigma_t \sum_{k = 0}^{n} h^{k + 1} \varphi_{k + 1}(h) \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) + \mathcal{O}(h^{n + 2}) \tag{35}
\end{align*}</script><p>通过公式(35)能够发现定义(33)的巧妙用途。进一步的，$\varphi_k(h)$的解析形式是能写出来的，有：</p>
<script type="math/tex; mode=display">\varphi_1(h) = \frac{e^h - 1}{h} \tag{36}</script><script type="math/tex; mode=display">\varphi_2(h) = \frac{e^h - h - 1}{h^2} \tag{37}</script><script type="math/tex; mode=display">\varphi_3(h) = \frac{e^h - \frac{h^2}{2} - h - 1}{h^3} \tag{38}</script><p>上面三个式子如何获得？实际上就是对原始式子求积分得到，需要用到$\Gamma$函数的性质，在这里就不在赘述，大家就当已知量就好。</p>
<p>现在，将公式(35)代入公式(28)中，立即获得：</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbf{x}_t &= \frac{\alpha_t}{\alpha_s} \mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda\\
&= \frac{\alpha_t}{\alpha_s} \mathbf{x}_s - \sigma_t \sum_{k = 0}^{n} h^{k + 1} \varphi_{k + 1}(h) \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) + \mathcal{O}(h^{n + 2}) \tag{39}
\end{align*}</script><p>公式(39)就是DPM Solver基于指数积分的数学性质得到的简化的迭代公式，最明显的特点是不再存在积分项，变成了对神经网络各阶导数$\hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s)$的加权求和，同时由于采用求和近似积分，自然也有一定的精度损失，这个损失项是$h^{n + 2}$的同阶无穷小量。</p>
<h5 id="一阶DPM-Solver采样公式推导"><a href="#一阶DPM-Solver采样公式推导" class="headerlink" title="一阶DPM Solver采样公式推导"></a>一阶DPM Solver采样公式推导</h5><p>对于一阶情况，对应于公式(39)的$n = 0$。代入$n = 0$，有：</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbf{x}_t &= \frac{\alpha_t}{\alpha_s} \mathbf{x}_s - \sigma_t (e^h - 1) \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) + \mathcal{O}(h^2) \tag{40}\\
&= \frac{\alpha_t}{\alpha_s} \mathbf{x}_s - \sigma_t (e^h - 1) \epsilon_\theta(\mathbf{x}_s, s) + \mathcal{O}(h^2) \tag{41}
\end{align*}</script><p>公式(41)和公式(40)等价，是因为$\lambda$和时间是一一对应关系，后面的推导都会混合用到这两种形式，大家重点就看时间点是什么，时间确定$\lambda$就确定，千万不要被这种形式的不同干扰迷惑，二者完全等价。对应于相邻两步的情况，公式(41)自然可以写为：</p>
<script type="math/tex; mode=display">
\mathbf{x}_{t_i} = \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} \mathbf{x}_{t_{i - 1}} - \sigma_t (e^{h_i} - 1) \epsilon_\theta(\mathbf{x}_{t_{i - 1}}, t_{i - 1}) + \mathcal{O}(h_i^2) \tag{42}</script><p>公式(42)没有带波浪线，就意味着$\mathbf{x}_{t_i}$和$\mathbf{x}_{t_{i - 1}}$都是精确值。然而，实际上这两个值都应该是数值计算的估计值，我们把$\mathbf{x}_{t_i}$和$\mathbf{x}_{t_{i - 1}}$分别用$\tilde{\mathbf{x}}_{t_i}$和$\tilde{\mathbf{x}}_{t_{i - 1}}$代替，有：</p>
<script type="math/tex; mode=display">
\begin{align*}
\tilde{\mathbf{x}}_{t_i} &= \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} \tilde{\mathbf{x}}_{t_{i - 1}} - \sigma_t (e^{h_i} - 1) \epsilon_\theta(\tilde{\mathbf{x}}_{t_{i - 1}}, t_{i - 1})\\
&= \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} \tilde{\mathbf{x}}_{t_{i - 1}} - \sigma_t (e^{h_i} - 1) \underbrace{(\epsilon_\theta(\mathbf{x}_{t_{i - 1}}, t_{i - 1}) + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}}))}_{\text{Taylor Expansion/Lipschitz(利普希茨)}}\\
&= \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} (\mathbf{x}_{t_{i - 1}} + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}})) - \sigma_t (e^{h_i} - 1) \epsilon_\theta(\mathbf{x}_{t_{i - 1}}, t_{i - 1}) + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}})\\
&= \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} \mathbf{x}_{t_{i - 1}} - \sigma_t (e^{h_i} - 1) \epsilon_\theta(\mathbf{x}_{t_{i - 1}}, t_{i - 1}) + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}})\\
&= \mathbf{x}_{t_{i - 1}} + \mathcal{O}(h_i^2) + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}}) \tag{43}
\end{align*}</script><p>公式(43)表明了每一步的采样误差是$\mathcal{O}(h_{i}^{2})+\mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}}-\mathbf{x}_{t_{i - 1}})$，这个公式是可以进行反复迭代的计算累计误差的。我们还是老套路，只看前三步，通过三步找规律得到最后的达到，前三步自然就是$t_{0}=T$、$0 &lt; t_{1}&lt;T$和$t_{2}=0$，根据公式(43)有：</p>
<script type="math/tex; mode=display">
\begin{align*}
\tilde{\mathbf{x}}_{t_{2}}&=\mathbf{x}_{t_{2}}+\mathcal{O}(h_{2}^{2})+\mathcal{O}(\tilde{\mathbf{x}}_{t_{1}}-\mathbf{x}_{t_{1}})\\
&=\mathbf{x}_{t_{2}}+\mathcal{O}(h_{2}^{2})+\mathcal{O}(\mathcal{O}(h_{1}^{2})+\mathcal{O}(\tilde{\mathbf{x}}_{t_{0}}-\mathbf{x}_{t_{0}}))\\
&=\mathbf{x}_{t_{2}}+\mathcal{O}(h_{2}^{2})+\mathcal{O}(h_{1}^{2})+\underbrace{\mathcal{O}(\tilde{\mathbf{x}}_{t_{0}}-\mathbf{x}_{t_{0}})}_{\text{equals }0}\\
&=\mathbf{x}_{t_{2}}+\mathcal{O}(2h_{\text{max}}^{2})\\
&=\mathbf{x}_{0}+\mathcal{O}(2h_{\text{max}}^{2})
\end{align*}</script><p>其中$h_{\text{max}}=\max_{1\leq i\leq M}(\lambda_{i}-\lambda_{i - 1})$，至于为什么$\mathcal{O}(\tilde{\mathbf{x}}_{t_{0}}-\mathbf{x}_{t_{0}})=0$，那是因为作为开始点，是你随机采样的噪声，当然没有误差啦！</p>
<p>我们推广到从$t_{0}$到$t_{M}$的$M$步迭代，累计$M$步，总累计误差为：</p>
<script type="math/tex; mode=display">
\begin{align*}
\tilde{\mathbf{x}}_{t_{M}}&=\mathbf{x}_{0}+\mathcal{O}(Mh_{\text{max}}^{2})\\
&=\mathbf{x}_{0}+\mathcal{O}(h_{\text{max}}) \tag{44}
\end{align*}</script><p>其中作者定义$h_{\text{max}}=\mathcal{O}(\frac{1}{M})$，排除特别大步长存在的可能性，也同时因此有最后一步推导成立。公式(44)对应DPM Solver中的定理3.2，也即对一阶DPM Solver的误差进行了定义，误差水平为$\mathcal{O}(h_{\text{max}})$。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/diffusion/" rel="tag"># diffusion</a>
              <a href="/tags/2022/" rel="tag"># 2022</a>
              <a href="/tags/NeurIPS/" rel="tag"># NeurIPS</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/03/12/Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" rel="prev" title="Analytic-DPM an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models论文精读">
      <i class="fa fa-chevron-left"></i> Analytic-DPM an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models论文精读
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/03/14/diffusion%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%84%9F%E6%82%9F/" rel="next" title="diffusion论文阅读感悟">
      diffusion论文阅读感悟 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E6%96%87%E7%BF%BB%E8%AF%91"><span class="nav-number">1.</span> <span class="nav-text">全文翻译</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.1.</span> <span class="nav-text">摘要</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.</span> <span class="nav-text">2 扩散概率模型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-%E6%AD%A3%E5%90%91%E8%BF%87%E7%A8%8B%E5%92%8C%E6%89%A9%E6%95%A3%E9%9A%8F%E6%9C%BA%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 正向过程和扩散随机微分方程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-%E6%89%A9%E6%95%A3%EF%BC%88%E6%A6%82%E7%8E%87%E6%B5%81%EF%BC%89%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 扩散（概率流）常微分方程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%89%A9%E6%95%A3%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%9A%84%E5%AE%9A%E5%88%B6%E5%BF%AB%E9%80%9F%E6%B1%82%E8%A7%A3%E5%99%A8"><span class="nav-number">1.3.</span> <span class="nav-text">3 扩散常微分方程的定制快速求解器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-%E6%89%A9%E6%95%A3%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%B2%BE%E7%A1%AE%E8%A7%A3%E7%9A%84%E7%AE%80%E5%8C%96%E5%85%AC%E5%BC%8F"><span class="nav-number">1.3.1.</span> <span class="nav-text">3.1 扩散常微分方程精确解的简化公式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-%E6%89%A9%E6%95%A3%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%9A%84%E9%AB%98%E9%98%B6%E6%B1%82%E8%A7%A3%E5%99%A8"><span class="nav-number">1.3.2.</span> <span class="nav-text">3.2 扩散常微分方程的高阶求解器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-%E6%AD%A5%E9%95%BF%E8%B0%83%E5%BA%A6"><span class="nav-number">1.4.</span> <span class="nav-text">3.3 步长调度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-%E4%BB%8E%E7%A6%BB%E6%95%A3%E6%97%B6%E9%97%B4%E6%89%A9%E6%95%A3%E6%A6%82%E7%8E%87%E6%A8%A1%E5%9E%8B%E9%87%87%E6%A0%B7"><span class="nav-number">1.5.</span> <span class="nav-text">3.4 从离散时间扩散概率模型采样</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E4%B8%8E%E7%8E%B0%E6%9C%89%E5%BF%AB%E9%80%9F%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">1.6.</span> <span class="nav-text">4 与现有快速采样方法的比较</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-%E4%BD%9C%E4%B8%BADPM-Solver-1%E7%9A%84DDIM"><span class="nav-number">1.6.1.</span> <span class="nav-text">4.1 作为DPM-Solver-1的DDIM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-%E4%B8%8E%E4%BC%A0%E7%BB%9F%E9%BE%99%E6%A0%BC-%E5%BA%93%E5%A1%94%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">1.6.2.</span> <span class="nav-text">4.2 与传统龙格 - 库塔方法的比较</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-%E5%9F%BA%E4%BA%8E%E8%AE%AD%E7%BB%83%E7%9A%84DPM%E5%BF%AB%E9%80%9F%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95"><span class="nav-number">1.6.3.</span> <span class="nav-text">4.3 基于训练的DPM快速采样方法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E5%AE%9E%E9%AA%8C"><span class="nav-number">1.7.</span> <span class="nav-text">5 实验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-%E4%B8%8E%E8%BF%9E%E7%BB%AD%E6%97%B6%E9%97%B4%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">1.7.1.</span> <span class="nav-text">5.1 与连续时间采样方法的比较</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-%E4%B8%8E%E7%A6%BB%E6%95%A3%E6%97%B6%E9%97%B4%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95%E7%9A%84%E6%AF%94%E8%BE%83"><span class="nav-number">1.7.2.</span> <span class="nav-text">5.2 与离散时间采样方法的比较</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-%E7%BB%93%E8%AE%BA"><span class="nav-number">1.8.</span> <span class="nav-text">6 结论</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B1%80%E9%99%90%E6%80%A7%E5%92%8C%E6%9B%B4%E5%B9%BF%E6%B3%9B%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="nav-number">1.8.1.</span> <span class="nav-text">局限性和更广泛的影响</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%96%91%E9%97%AE"><span class="nav-number">2.</span> <span class="nav-text">疑问</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%89%A9%E6%95%A3%E5%B8%B8%E5%BE%AE%E5%88%86%E6%96%B9%E7%A8%8B%E7%9A%84%E5%AE%9A%E5%88%B6%E5%BF%AB%E9%80%9F%E6%B1%82%E8%A7%A3%E5%99%A8-1"><span class="nav-number">2.1.</span> <span class="nav-text">3 扩散常微分方程的定制快速求解器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%AC%E5%BC%8F3-4%E7%9A%84%E6%8E%A8%E5%AF%BC"><span class="nav-number">2.1.1.</span> <span class="nav-text">公式3.4的推导</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#DPM-Solver-K"><span class="nav-number">2.1.2.</span> <span class="nav-text">DPM-Solver-K</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%B8%80%E9%98%B6DPM-Solver%E9%87%87%E6%A0%B7%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">一阶DPM Solver采样公式推导</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zongqing Li"
      src="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
  <p class="site-author-name" itemprop="name">Zongqing Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">59</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/hqulzq" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hqulzq" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hqulzq@163.com" title="E-Mail → mailto:hqulzq@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

      
<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
<div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div id="myCanvasContainer" class="widget tagcloud">
        <canvas width="250" height="250" id="resCanvas" style="width=100%">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/2019/" rel="tag">2019</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2020/" rel="tag">2020</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2021/" rel="tag">2021</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2022/" rel="tag">2022</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2023/" rel="tag">2023</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2025/" rel="tag">2025</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bug%E6%80%BB%E7%BB%93/" rel="tag">Bug总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR/" rel="tag">CVPR</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR-Workshop/" rel="tag">CVPR Workshop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/" rel="tag">ICLR</a><span class="tag-list-count">8</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/" rel="tag">ICML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Knife4j/" rel="tag">Knife4j</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MinIO/" rel="tag">MinIO</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mybatis-Plus/" rel="tag">Mybatis-Plus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NeurIPS/" rel="tag">NeurIPS</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx/" rel="tag">Nginx</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RabbitMQ/" rel="tag">RabbitMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RocketMQ/" rel="tag">RocketMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a><span class="tag-list-count">26</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/" rel="tag">k8s</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/latex/" rel="tag">latex</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/" rel="tag">mongodb</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/" rel="tag">代码随想录</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%B4%E5%87%BD%E6%95%B0/" rel="tag">头函数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%9A%E5%BA%AD%E5%85%AC%E5%AF%93/" rel="tag">尚庭公寓</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/" rel="tag">异常处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" rel="tag">快速入门</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/" rel="tag">技术总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B3%A8%E8%A7%A3/" rel="tag">注解</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%AB%99/" rel="tag">网站</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%8B%A5%E4%BE%9D/" rel="tag">若依</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" rel="tag">设计模式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E8%A1%A8i/" rel="tag">链表i</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%85%E8%AF%BB/" rel="tag">阅读</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/" rel="tag">项目实战</a><span class="tag-list-count">6</span></li></ul>
        </canvas>
    </div>
</div>



    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zongqing Li</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #4D4D4C;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #F7F7F7;
      background-image: linear-gradient(#F7F7F7, #F7F7F7);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>

  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('post.copy_button').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('post.copy_success')
          else $(this).text('post.copy_failure')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('post.copy_button')
        }, 300)
      }).append(e)
    })
  </script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
