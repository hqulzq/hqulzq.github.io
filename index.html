<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hqulzq.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Lzq&#39;s blog">
<meta property="og:url" content="https://hqulzq.github.io/index.html">
<meta property="og:site_name" content="Lzq&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Zongqing Li">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://hqulzq.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Lzq's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lzq's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">44</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">12</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">57</span></a>

  </li>
        <li class="menu-item menu-item-book">

    <a href="/book" rel="section"><i class="fas fa-book fa-fw"></i>Book</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/25/FAST-SAMPLING-OF-DIFFUSION-MODELS-WITH-EXPONENTIAL-INTEGRATOR%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/25/FAST-SAMPLING-OF-DIFFUSION-MODELS-WITH-EXPONENTIAL-INTEGRATOR%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">FAST SAMPLING OF DIFFUSION MODELS WITH EXPONENTIAL INTEGRATOR论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-25 16:10:14" itemprop="dateCreated datePublished" datetime="2025-03-25T16:10:14+08:00">2025-03-25</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-26 10:24:58" itemprop="dateModified" datetime="2025-03-26T10:24:58+08:00">2025-03-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>在过去几年里，扩散模型（DMs）在生成式建模任务中取得了巨大成功，能够生成高保真样本。然而，DM的一个主要局限性是其采样过程极为缓慢，通常需要对学习到的扩散过程进行数百到数千次时间离散化步骤才能达到所需的精度。我们的目标是为DM开发一种快速采样方法，在减少步骤的同时保持高样本质量。为此，我们系统地分析了DM中的采样过程，确定了影响样本质量的关键因素，其中离散化方法最为关键。通过仔细研究学习到的扩散过程，我们提出了扩散指数积分采样器（DEIS）。它基于为离散化常微分方程（ODE）设计的指数积分器，并利用学习到的扩散过程的半线性结构来减少离散化误差。所提出的方法可以应用于任何DM，并且能够在仅10步内生成高保真样本。此外，通过直接使用预训练的DM，在得分函数评估次数（NFE）有限的情况下，我们实现了最先进的采样性能，例如在CIFAR10数据集上，10次NFE时的FID为4.17，20次NFE时的FID为2.86。项目页面和代码：<a target="_blank" rel="noopener" href="https://qsh-zh.github.io/deis">https://qsh-zh.github.io/deis</a> 。</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/25/FAST-SAMPLING-OF-DIFFUSION-MODELS-WITH-EXPONENTIAL-INTEGRATOR%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/25/DPM-Solver-Plus-Plus-Fast-Solver-for-Guided-Sampling-of-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/25/DPM-Solver-Plus-Plus-Fast-Solver-for-Guided-Sampling-of-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">DPM-Solver-Plus-Plus-Fast Solver for Guided Sampling of Diffusion Probabilistic Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-25 15:03:39 / 修改时间：19:15:54" itemprop="dateCreated datePublished" datetime="2025-03-25T15:03:39+08:00">2025-03-25</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>扩散概率模型（DPMs）在高分辨率图像合成中取得了显著成功，尤其是在近期大规模文本到图像生成应用中。一种提高DPMs样本质量的关键技术是引导采样，通常需要较大的引导尺度才能获得最佳样本质量。常用的引导采样快速采样器是DDIM，它是一种一阶扩散常微分方程（ODE）求解器，通常需要100到250步才能生成高质量样本。尽管近期有研究提出了专用的高阶求解器，并在无引导采样方面实现了进一步加速，但它们在引导采样中的有效性此前尚未得到充分测试。<font color="red" style="background: rgb(234, 238, 23)">在这项工作中，我们证明了以前的高阶快速采样器存在不稳定性问题，并且当引导尺度增大时，它们甚至比DDIM更慢。</font>为了进一步加速引导采样，我们提出了DPM-Solver++，这是一种用于DPMs引导采样的高阶求解器。DPM-Solver++使用数据预测模型求解扩散ODE，并采用阈值化方法使解与训练数据分布相匹配。我们进一步提出了DPM-Solver++的多步变体，通过减小有效步长来解决不稳定性问题。实验表明，DPM-Solver++仅需15到20步就能为像素空间和潜空间DPMs的引导采样生成高质量样本。</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h3><p>扩散概率模型（DPMs）（Sohl-Dickstein等人，2015；Ho等人，2020；Song等人，2021b）在各种任务中取得了显著成功，例如高分辨率图像合成（Dhariwal和Nichol，2021；Ho等人，2022；Rombach等人，2022）、图像编辑（Meng等人，2022；Saharia等人，2022a；Zhao等人，2022）、文本到图像生成（Nichol等人，2021；Saharia等人，2022b；Ramesh等人，2022；Rombach等人，2022；Gu等人，2022）、语音合成（Liu等人，2022a；Chen等人，2021a、b）、分子生成（Xu等人，2022；Hoogeboom等人，2022；Wu等人，2022）和数据压缩（Theis等人，2022；Kingma等人，2021）。与生成对抗网络（GANs）（Goodfellow等人，2014）和变分自编码器（VAEs）（Kingma和Welling，2014）等其他深度生成模型相比，DPMs通过利用一种称为引导采样的关键技术（Dhariwal和Nichol，2021；Ho和Salimans，2021），甚至可以实现更好的样本质量。该技术使用额外的引导模型来提高样本保真度和条件样本对齐度。通过它，DPMs在文本到图像和图像到图像任务中可以生成与给定条件高度相关的高分辨率逼真艺术图像，引领了人工智能绘画的新潮流。</p>
<p>DPMs的采样过程是从纯高斯随机变量中逐渐去除噪声以获得清晰数据，这可以看作是对由参数化噪声预测模型或数据预测模型定义的扩散随机微分方程（SDEs）（Ho等人，2020；Song等人，2021b）或扩散常微分方程（ODEs）（Song等人，2021b、a）进行离散化（Ho等人，2020；Kingma等人，2021）。DPMs的引导采样也可以通过将无条件模型与引导模型相结合，用这种离散化方法进行形式化，其中一个超参数控制引导模型的尺度（即引导尺度）。常用的引导采样方法是DDIM（Song等人，2021a），它被证明是一种一阶扩散ODE求解器（Salimans和Ho，2022；Lu等人，2022），通常需要进行100到250次大规模神经网络评估才能收敛，非常耗时。</p>
<p>专用的高阶扩散ODE求解器（Lu等人，2022；Zhang和Chen，2022）可以在10到20步内为无引导采样生成高质量样本。然而，它们在引导采样中的有效性此前尚未得到仔细研究。在这项工作中，我们证明了以前用于DPMs的高阶求解器在引导采样时生成的样本不尽人意，甚至比简单的一阶求解器DDIM还差。<font color="red" style="background: rgb(234, 238, 23)">我们确定了将高阶求解器应用于引导采样面临的两个挑战：（1）较大的引导尺度缩小了高阶求解器的收敛半径，使其不稳定；（2）收敛解与原始数据不在同一范围内（也称为 “训练 - 测试不匹配”（Saharia等人，2022b））。</font></p>
<p>基于这些观察，我们提出了DPM-Solver++，这是一种无需训练的用于引导采样的快速扩散ODE求解器。我们发现DPM的参数化对解的质量有至关重要的影响。随后，我们求解由数据预测模型定义的扩散ODE，该模型根据含噪数据预测干净数据。我们推导了一种用于求解具有数据预测参数化的ODE的高阶求解器，并采用动态阈值化方法（Saharia等人，2022b）来缓解训练 - 测试不匹配问题。此外，我们开发了一种多步求解器，使用较小的步长来解决不稳定性问题。</p>
<p>如图1所示，DPM-Solver++仅需15步就能生成高质量样本，比之前所有无需训练的引导采样采样器都要快得多。我们的额外实验结果表明，DPM-Solver++可以生成高保真样本，并且在仅15到20步内几乎就能收敛，适用于各种引导采样应用，包括像素空间DPMs和潜空间DPMs。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f1.png" width="80%" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图1：以往的高阶求解器在引导采样中不稳定：在ImageNet 256×256数据集上，使用预训练的扩散概率模型（Dhariwal和Nichol，2021），分类器引导尺度设为8.0，仅进行15次函数评估，采用不同采样器（以及不同求解器阶数）生成的样本。†：采用动态阈值化的DDIM（Saharia等人，2022b）。我们提出的DPM-Solver++（详见算法2）能够生成比一阶DDIM更好的样本，而其他高阶采样器生成的样本比DDIM更差。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-扩散概率模型"><a href="#2-扩散概率模型" class="headerlink" title="2 扩散概率模型"></a>2 扩散概率模型</h3><p>在本节中，我们回顾扩散概率模型（DPMs）及其采样方法。</p>
<h4 id="2-1-基于扩散ODE的DPMs快速采样"><a href="#2-1-基于扩散ODE的DPMs快速采样" class="headerlink" title="2.1 基于扩散ODE的DPMs快速采样"></a>2.1 基于扩散ODE的DPMs快速采样</h4><p>扩散概率模型（DPMs）（Sohl-Dickstein等人，2015；Ho等人，2020；Song等人，2021b）逐渐向一个$D$维随机变量$x_{0} \in \mathbb{R}^{D}$添加高斯噪声，从而将时间0时相应的未知数据分布$q_{0}(x_{0})$扰动为时间$T&gt;0$时的简单正态分布$q_{T}(x_{T}) \approx N(x_{T} | 0, \tilde{\sigma}^{2} I)$，其中$\tilde{\sigma}&gt;0$。在每个时间$t \in [0, T]$，转移分布$q_{t0}(x_{t} | x_{0})$满足：</p>
<script type="math/tex; mode=display">q_{t0}\left(x_{t} | x_{0}\right)=\mathcal{N}\left(x_{t} | \alpha_{t} x_{0}, \sigma_{t}^{2} I\right) \tag{1}</script><p>其中$\alpha_{t}$、$\sigma_{t}&gt;0$，且信噪比（SNR）$\alpha_{t}^{2} / \sigma_{t}^{2}$随时间$t$严格递减（Kingma等人，2021）。公式（1）可以写成$x_{t}=\alpha_{t} x_{0}+\sigma_{t} \epsilon$，其中$\epsilon \sim N(0, I)$。</p>
<ul>
<li><strong>参数化：噪声预测和数据预测</strong>：DPMs通过顺序去噪过程，基于含噪输入$x_{T}$学习恢复数据$x_{0}$。定义模型有两种可选方式。噪声预测模型$\epsilon_{\theta}(x_{t}, t)$试图从数据$x_{t}$中预测噪声$\epsilon$，它通过以下目标来优化参数$\theta$（Ho等人，2020；Song等人，2021b）：<script type="math/tex; mode=display">min _{\theta} \mathbb{E}_{x_{0}, \epsilon, t}\left[\omega(t)\left\| \epsilon_{\theta}\left(x_{t}, t\right)-\epsilon\right\|_{2}^{2}\right] \tag{2}</script>其中$x_{0} \sim q_{0}(x_{0})$，$\epsilon \sim N(0, I)$，$t \sim U([0,1])$，且$\omega(t)&gt;0$是一个加权函数。另外，数据预测模型$x_{\theta}(x_{t}, t)$基于含噪的$x_{t}$预测原始数据$x_{0}$，它与$\epsilon_{\theta}(x_{t}, t)$的关系为$x_{\theta}(x_{t}, t):=(x_{t}-\sigma_{t} \epsilon_{\theta}(x_{t}, t)) / \alpha_{t}$（Kingma等人，2021）。</li>
<li><strong>扩散ODE采样</strong>：DPMs的采样可以通过求解扩散ODE来实现（Song等人，2021b、a；Liu等人，2022b；Zhang和Chen，2022；Lu等人，2022），这通常比其他采样方法更快。具体来说，基于扩散ODE的采样需要对以下ODE进行离散化（Song等人，2021b），其中时间$t$从$T$变化到$0$：<script type="math/tex; mode=display">\frac{d x_{t}}{ d t}=f(t) x_{t}+\frac{g^{2}(t)}{2 \sigma_{t}} \epsilon_{\theta}\left(x_{t}, t\right), x_{T} \sim \mathcal{N}\left(0, \overline{\sigma}^{2} I\right) \tag{3}</script>关于数据预测模型$x_{\theta}$的等效扩散ODE为：<script type="math/tex; mode=display">\frac{d x_{t}}{ d t}=\left(f(t)+\frac{g^{2}(t)}{2 \sigma_{t}^{2}}\right) x_{t}-\frac{\alpha_{t} g^{2}(t)}{2 \sigma_{t}^{2}} x_{\theta}\left(x_{t}, t\right), x_{T} \sim \mathcal{N}\left(0, \overline{\sigma}^{2} I\right) \tag{4}</script>其中系数$f(t)=\frac{d log \alpha_{t}}{~d t}$，$g^{2}(t)=\frac{d \sigma_{t}^{2}}{~d t}-2 \frac{d log \alpha_{t}}{~d t} \sigma_{t}^{2}$（Kingma等人，2021）。</li>
</ul>
<h4 id="2-2-DPMs的引导采样"><a href="#2-2-DPMs的引导采样" class="headerlink" title="2.2 DPMs的引导采样"></a>2.2 DPMs的引导采样</h4><p>引导采样（Dhariwal和Nichol，2021；Ho和Salimans，2021）是一种广泛应用于DPMs条件采样的技术，在文本到图像、图像到图像和类别到图像的应用中非常有用（Dhariwal和Nichol，2021；Saharia等人，2022b；Rombach等人，2022；Nichol等人，2021；Ramesh等人，2022）。给定一个条件变量$c$，引导采样定义了一个条件噪声预测模型$\tilde{\epsilon}_{\theta}(x_{t}, t, c)$。引导采样方法有两种类型，取决于它们是否需要分类器模型。</p>
<ul>
<li><strong>分类器引导</strong>：分类器引导（Dhariwal和Nichol，2021）利用预训练的分类器$p_{\phi}(c | x_{t}, t)$来定义条件噪声预测模型：<script type="math/tex; mode=display">\tilde{\epsilon}_{\theta}\left(x_{t}, t, c\right):=\epsilon_{\theta}\left(x_{t}, t\right)-s \cdot \sigma_{t} \nabla_{x_{t}} log p_{\phi}\left(c | x_{t}, t\right) \tag{5}</script>其中$s&gt;0$是引导尺度。在实践中，为了提高引导采样中的条件样本对齐度，通常倾向于使用较大的$s$（Rombach等人，2022；Saharia等人，2022b）。</li>
<li><strong>无分类器引导</strong>：无分类器引导（Ho和Salimans，2021）对无条件和有条件噪声预测模型使用相同的参数化模型$\epsilon_{\theta}(x_{t}, t, c)$，其中无条件模型的输入$c$是一个特殊占位符$\infty$。相应的条件模型定义为：<script type="math/tex; mode=display">\tilde{\epsilon}_{\theta}\left(x_{t}, t, c\right):=s \cdot \epsilon_{\theta}\left(x_{t}, t, c\right)+(1-s) \cdot \epsilon_{\theta}\left(x_{t}, t, \infty\right) \tag{6}</script>然后，可以通过用$\epsilon_{\theta}(x_{t}, t, c)$代替$\epsilon_{\theta}(x_{t}, t)$来求解ODE（3），从而得到样本。DDIM（Song等人，2021a）是一种典型的引导采样求解器，它需要几百步来生成样本。</li>
</ul>
<h4 id="2-3-指数积分器和高阶ODE求解器"><a href="#2-3-指数积分器和高阶ODE求解器" class="headerlink" title="2.3 指数积分器和高阶ODE求解器"></a>2.3 指数积分器和高阶ODE求解器</h4><p>最近的研究（Lu等人，2022；Zhang和Chen，2022）表明，基于指数积分器（Hochbruck和Ostermann，2010）的ODE求解器在求解无条件扩散ODE（3）时，比传统求解器收敛速度快得多。给定时间$s&gt;0$时的初始值$x_{s}$，Lu等人（2022）推导出扩散ODE（3）在时间$t$的解$x_{t}$为：</p>
<script type="math/tex; mode=display">x_{t}=\frac{\alpha_{t}}{\alpha_{s}} x_{s}-\alpha_{t} \int_{\lambda_{s}}^{\lambda_{t}} e^{-\lambda} \hat{\epsilon}_{\theta}\left(\hat{x}_{\lambda}, \lambda\right) d \lambda \tag{7}</script><p>其中通过变量变换公式，ODE从$(t)$域转换到了对数信噪比（$\lambda$）域。这里，对数信噪比$\lambda_{t}:=log (\alpha_{t} / \sigma_{t})$是$t$的严格递减函数，其反函数为$t_{\lambda}(\cdot)$，且$\hat{x}_{\lambda}:=x_{t_{\lambda}(\lambda)}$，$\hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda):=\epsilon_{\theta}(x_{t_{\lambda}(\lambda)}, t_{\lambda}(\lambda))$是关于$\lambda$的相应变量变换形式。Lu等人（2022）表明，DDIM是公式（7）的一阶求解器。他们进一步提出了一种名为“DPM-Solver”的高阶求解器，它可以在仅10 - 20步内为无条件模型生成逼真的样本。</p>
<p>不幸的是，现有高阶求解器的出色效率在引导采样中并未体现，我们将很快对此进行讨论。</p>
<h3 id="3-高阶求解器用于引导采样面临的挑战"><a href="#3-高阶求解器用于引导采样面临的挑战" class="headerlink" title="3 高阶求解器用于引导采样面临的挑战"></a>3 高阶求解器用于引导采样面临的挑战</h3><p>在开发新的快速求解器之前，我们首先研究现有高阶扩散常微分方程（ODE）求解器的性能，并突出其中面临的挑战。</p>
<p>第一个挑战是较大的引导尺度会导致高阶求解器不稳定。如图1所示，当引导尺度$s = 8.0$且进行15次函数评估时，以往的高阶扩散ODE求解器（Lu等人，2022；Zhang和Chen，2022；Liu等人，2022b）生成的图像质量较低。它们生成的样本质量甚至比一阶的DDIM还差。此外，求解器的阶数越高，样本质量反而越差。</p>
<p>直观来看，较大的引导尺度可能会同时放大模型$\tilde{\epsilon}_{\theta}$在公式（5）中的输出和导数。模型的导数会影响ODE求解器的收敛范围，这种放大效应可能会导致高阶ODE求解器需要更小的步长才能收敛，因此高阶求解器的性能可能会比一阶求解器更差。而且，高阶求解器需要计算高阶导数，而高阶导数通常对这种放大效应更为敏感，这进一步缩小了收敛半径。</p>
<p>第二个挑战是“训练-测试不匹配”问题（Saharia等人，2022b）。数据通常位于一个有界区间内（例如，图像数据的区间为$[-1, 1]$）。然而，较大的引导尺度会使条件噪声预测模型$\tilde{\epsilon}_{\theta}(x_{t}, t, c)$偏离真实噪声，进而导致样本（即扩散ODE的收敛解$x_{0}$）超出边界。在这种情况下，生成的图像会出现饱和且不自然的现象（Saharia等人，2022b）。</p>
<h3 id="4-设计用于引导采样的免训练快速采样器"><a href="#4-设计用于引导采样的免训练快速采样器" class="headerlink" title="4 设计用于引导采样的免训练快速采样器"></a>4 设计用于引导采样的免训练快速采样器</h3><p>在本节中，我们设计了新的高阶扩散ODE求解器，以实现更快的引导采样。如第3节所述，以往的高阶求解器在大引导尺度下存在不稳定性和 “训练-测试不匹配” 问题。“训练-测试不匹配” 问题源于ODE本身，我们发现ODE的参数化对于收敛解的有界性至关重要。以往的高阶求解器是为噪声预测模型 $\tilde{\epsilon}_{\theta}$ 设计的，而我们求解数据预测模型 $x_{\theta}$ 的ODE（4），该模型本身具有一些优势，并且可以进一步采用阈值化方法来确保样本有界（Ho等人，2020；Saharia等人，2022b）。我们还提出了一种多步求解器来解决不稳定性问题。</p>
<h4 id="4-1-基于数据预测模型设计求解器"><a href="#4-1-基于数据预测模型设计求解器" class="headerlink" title="4.1 基于数据预测模型设计求解器"></a>4.1 基于数据预测模型设计求解器</h4><p>我们沿用Lu等人（2022）中的符号。给定一个从 $t_{0}=T$ 递减到 $t_{M}=0$ 的序列 $\{t_{i}\}_{i = 0}^{M}$ 以及初始值 $x_{t_{0}} \sim N(0 | \tilde{\sigma}^{2} I)$，求解器旨在迭代计算序列 $\{\tilde{x}_{t_{i}}\}_{i = 0}^{M}$，以逼近每个时间 $t_{i}$ 处的精确解，最终值 $\tilde{x}_{t_{M}}$ 即为扩散ODE的近似样本。记 $h_{i}:=\lambda_{t_{i}}-\lambda_{t_{i - 1}}$，其中 $i = 1, \cdots, M$。</p>
<p>为求解关于 $x_{\theta}$ 的扩散ODE（4），我们首先给出以下关于 $x_{\theta}$ 的扩散ODE精确解的简化形式。这种形式精确计算了公式（4）中的线性项，并且仅保留了 $x_{\theta}$ 的指数加权积分。记 $\hat{x}_{\theta}(\hat{x}_{\lambda}, \lambda):=x_{\theta}(x_{t_{\lambda}(\lambda)}, t_{\lambda}(\lambda))$ 为 $x_{\theta}$ 关于 $\lambda$ 的变量变换形式，我们有：</p>
<p><strong>命题4.1（$x_{\theta}$ 的扩散ODE精确解，证明见附录A）</strong>：给定时间 $s&gt;0$ 时的初始值 $x_{s}$，公式（4）中扩散ODE在时间 $t \in [0, s]$ 的解 $x_{t}$ 为：</p>
<script type="math/tex; mode=display">x_{t}=\frac{\sigma_{t}}{\sigma_{s}} x_{s}+\sigma_{t} \int_{\lambda_{s}}^{\lambda_{t}} e^{\lambda} \hat{x}_{\theta}\left(\hat{x}_{\lambda}, \lambda\right) d \lambda \tag{8}</script><p>由于公式（3）和公式（4）中的扩散ODE是等价的，公式（7）和公式（8）中的精确解形式也是等价的。然而，从设计ODE求解器的角度来看，这两种形式是不同的。首先，公式（7）精确计算线性项 $\frac{\alpha_{1}}{\alpha_{s}} x_{s}$，而公式（8）精确计算另一个线性项 $\frac{\sigma_{2}}{\sigma_{s}} x_{s}$。此外，为设计ODE求解器，公式（7）需要近似积分 $\int e^{-\lambda} \epsilon_{\theta} d \lambda$，而公式（8）需要近似 $\int e^{\lambda} x_{\theta} d \lambda$，这两个积分是不同的（回想一下 $x_{\theta}:=(x_{t}-\sigma_{t} \epsilon_{\theta}) / \alpha_{t}$）。因此，基于公式（7）和公式（8）的高阶求解器本质上是不同的。我们进一步给出基于公式（8）设计高阶ODE求解器的一般方法。</p>
<p>给定时间 $t_{i - 1}$ 处的先前值 $\tilde{x}_{t_{i - 1}}$，我们求解器的目标是逼近时间 $t_{i}$ 处的精确解。记 $x_{\theta}^{(n)}(\lambda):=\frac{d^{n} \hat{x}_{\theta}(x_{\lambda}, \lambda)}{d \lambda^{n}}$ 为 $x_{\theta}$ 关于对数信噪比 $\lambda$ 的 $n$ 阶总导数。</p>
<p>对于 $k \geq 1$，对 $x_{\theta}$ 在 $\lambda \in [\lambda_{t_{i - 1}}, \lambda_{t_{i}}]$ 上关于 $\lambda_{t_{i - 1}}$ <font color = "red">进行 $(k - 1)$ 阶泰勒展开</font>，并将其代入公式（8）（其中 $s = t_{i - 1}$，$t = t_{i}$），我们得到：</p>
<script type="math/tex; mode=display">\tilde{x}_{t_{i}}=\frac{\sigma_{t_{i}}}{\sigma_{t_{i - 1}}} \tilde{x}_{t_{i - 1}}+\sigma_{t_{i}} \sum_{n = 0}^{k - 1} \underbrace{x_{\theta}^{(n)}\left(\hat{x}_{\lambda_{t_{i - 1}}}, \lambda_{t_{i - 1}}\right)}_{估计值} \underbrace{\int_{\lambda_{t_{i - 1}}}^{\lambda_{t_{i}}} e^{\lambda} \frac{\left(\lambda-\lambda_{t_{i - 1}}\right)^{n}}{n!} d \lambda}_{解析计算值（附录A） }+\underbrace{\mathcal{O}\left(h_{i}^{k + 1}\right)}_{省略项 } \tag{9}</script><p>其中积分 $\int e^{\lambda} \frac{(\lambda-\lambda_{t_{i - 1}})^{n}}{n!} d \lambda$ 可以通过分部积分法进行解析计算（详见附录A）。因此，为设计一个 $k$ 阶ODE求解器，在省略 $O(h_{i}^{k + 1})$ 高阶误差项后，我们只需要估计 $n \leq k - 1$ 时的 $n$ 阶导数 $x_{\theta}^{(n)}(\lambda_{t_{i - 1}})$，这些都是经过充分研究的技术，我们将在4.2节详细讨论。$k = 1$ 是一个特殊情况，此时求解器与DDIM（Song等人，2021a）相同，我们将在6.1节讨论。</p>
<p>对于 $k = 2$，我们使用与DPM-Solver-2（Lu等人，2022）类似的技术来估计导数 $x_{\theta}^{(1)}(\hat{x}_{\lambda_{t_{i - 1}}}, \lambda_{t_{i - 1}})$。具体来说，我们在 $t_{i - 1}$ 和 $t_{i}$ 之间引入一个额外的中间时间步 $s_{i}$，并结合 $s_{i}$ 和 $t_{i - 1}$ 处的函数值来近似导数，这是单步ODE求解器的标准方法（Atkinson等人，2011）。总体而言，我们需要 $2M + 1$ 个时间步（$\{t_{i}\}_{i = 0}^{M}$ 和 $\{s_{i}\}_{i = 1}^{M}$），满足 $t_{0}&gt;s_{1}&gt;t_{1}&gt;\cdots&gt;t_{M - 1}&gt;s_{M}&gt;t_{M}$ 。详细算法见算法1，在算法1中，我们将时间 $t_{i - 1}$ 处的先前值 $\tilde{x}_{t_{i - 1}}$ 与时间 $s_{i}$ 处的中间值 $u_{i}$ 相结合，计算时间 $t_{i}$ 处的值 $\tilde{x}_{t_{i}}$ 。</p>
<p>我们将该算法命名为DPM-Solver++(2S)，这意味着所提出的求解器是一种二阶单步方法。我们在附录A中给出了收敛阶数的理论保证。对于 $k \geq 3$，如第3节所述，高阶求解器可能不适合大引导尺度，因此在这项工作中我们主要考虑 $k = 2$，将更高阶求解器留作未来研究。</p>
<p>此外，我们在附录B中对DPM-Solver-2（Lu等人，2022）和DPM-Solver++(2S) 进行了理论比较。我们发现DPM-Solver++(2S) 在高阶误差项前的常数更小，因此通常比DPM-Solver-2具有更小的离散化误差。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="a1.png" width="60%" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">**</td>
</tr>
</tbody>
</table>
</div>
<h4 id="4-2-从单步到多步"><a href="#4-2-从单步到多步" class="headerlink" title="4.2 从单步到多步"></a>4.2 从单步到多步</h4><p>在每一步（从 $t_{i - 1}$ 到 $t_{i}$），所提出的单步求解器需要对神经网络 $x_{\theta}$ 进行两次连续的函数评估。此外，中间值 $u_{i}$ 仅使用一次就被丢弃。这种方法丢失了先前的信息，可能效率不高。在本节中，我们提出另一种二阶扩散ODE求解器，它在每一步都利用先前的信息。</p>
<p>一般来说，为了近似公式（9）中 $n \geq 1$ 时的导数 $x_{\theta}^{(n)}$，还有另一种主流方法（Atkinson等人，2011）：多步方法（如Adams–Bashforth方法）。给定时间 $t_{i - 1}$ 处的先前值 $\{\tilde{x}_{t_{j}}\}_{j = 0}^{i - 1}$，多步方法通过重用先前的值来近似高阶导数。经验表明，多步方法比单步方法更高效，尤其是在函数评估次数有限的情况下（Atkinson等人，2011）。</p>
<p>我们将设计多步求解器的技术与公式（9）中的泰勒展开相结合，进一步提出了一种用于 $x_{\theta}$ 的扩散ODE的多步二阶求解器。详细算法见算法2，在算法2中，我们结合先前值 $\overline{x}_{t_{i - 1}}$ 和 $\tilde{x}_{t_{i - 2}}$ 来计算值 $\bar{x}_{t_{i}}$，无需额外的中间值。我们将该算法命名为DPM-Solver++(2M)，这意味着所提出的求解器是一种二阶多步求解器。我们也在附录A中给出了收敛阶数的详细理论保证。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="a2.png" width="60%" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">**</td>
</tr>
</tbody>
</table>
</div>
<p>对于固定的总函数评估次数预算 $N$，多步方法可以使用 $M = N$ 步，而 $k$ 阶单步方法最多只能使用不超过 $M = N / k$ 步。因此，多步方法的每一步步长 $h_{i}$ 大约是单步方法的 $1/k$，所以多步方法公式（9）中的高阶误差项 $O(h_{i}^{k})$ 也可能比单步方法的更小。我们在7.1节表明，多步方法略优于单步方法。</p>
<h4 id="4-3-DPM-Solver-与阈值化方法相结合"><a href="#4-3-DPM-Solver-与阈值化方法相结合" class="headerlink" title="4.3 DPM-Solver++与阈值化方法相结合"></a>4.3 DPM-Solver++与阈值化方法相结合</h4><p>对于有界数据的分布（如图像数据），阈值化方法（Ho等人，2020；Saharia等人，2022b）可以将超出边界的样本向内推，在一定程度上减少大引导尺度的不利影响。具体来说，阈值化方法通过在数据边界内对原始模型 $x_{\theta}:=(x_{t}-\sigma_{t} \epsilon_{\theta}) / \alpha_{t}$ 进行逐元素裁剪，定义了一个裁剪后的数据预测模型 $\hat{x}_{\theta}(x_{t}, t, c)$，这在大引导尺度下可以提高样本质量（Saharia等人，2022b）。由于我们提出的DPM-Solver++是为 $x_{\theta}$ 模型设计的，我们可以直接将阈值化方法与DPM-Solver++相结合。</p>
<h3 id="5-扩散随机微分方程（SDEs）的快速求解器"><a href="#5-扩散随机微分方程（SDEs）的快速求解器" class="headerlink" title="5 扩散随机微分方程（SDEs）的快速求解器"></a>5 扩散随机微分方程（SDEs）的快速求解器</h3><p>扩散模型的采样也可以通过求解扩散随机微分方程（Song等人，2021b）来实现：</p>
<script type="math/tex; mode=display">dx_t = \left[f(t)x_t + \frac{g^2(t)}{\sigma_t}\epsilon_{\theta}(x_t,t)\right]dt + g(t)d\overline{w}_t \tag{10}</script><p>其中，$\overline{w}_t$是从$T$到$0$的反向维纳过程。在本节中，我们考虑关于对数信噪比$\lambda$的扩散随机微分方程，并推导相应的二阶求解器。</p>
<p>记$dw_{\lambda} := \sqrt{-\frac{d\lambda_t}{dt}}d\overline{w}_{t_{\lambda}(\lambda)}$为关于$\lambda$的相应维纳过程。为简化表示，记$x_{\lambda} := x_{t(\lambda)}$，$\sigma_{\lambda} := \sigma_{t(\lambda)}$，$w_{\lambda} := w_{\lambda_t}$，$\epsilon_{\theta}(x_{\lambda},\lambda) := \epsilon_{\theta}(x_{t(\lambda)},t(\lambda))$。对于VP型扩散模型（Song等人，2021b）（即$\alpha_t^2 + \sigma_t^2 = 1$），我们有$\frac{d\log\alpha_{\lambda}}{d\lambda} = \sigma_{\lambda}^2$且$\frac{d\log\sigma_{\lambda}}{d\lambda} = -\alpha_{\lambda}^2$。由于$f(t) = \frac{d\log\alpha_t}{dt}$且$g(t) = \sigma_t\sqrt{-2\frac{d\lambda_t}{dt}}$（Kingma等人，2021），关于$\lambda$的扩散随机微分方程为：</p>
<script type="math/tex; mode=display">\begin{align}
dx_{\lambda} & = \left[\sigma_{\lambda}^2x_{\lambda} - 2\sigma_{\lambda}\epsilon_{\theta}(x_{\lambda},\lambda)\right]d\lambda + \sqrt{2}\sigma_{\lambda}dw_{\lambda} \tag{11} \\
& = \left[-(1 + \alpha_{\lambda}^2)x_{\lambda} + 2\alpha_{\lambda}x_{\theta}(x_{\lambda},\lambda)\right]d\lambda + \sqrt{2}\sigma_{\lambda}dw_{\lambda} \tag{12}
\end{align}</script><p>通过应用常数变易公式，我们给出扩散随机微分方程的精确解如下。<br><strong>命题5.1（扩散随机微分方程的精确解，证明见附录A）</strong>：给定在时间$s &gt; 0$的初始值$x_s$，方程（10）中扩散随机微分方程在时间$t \in [0, s]$的解$x_t$为：</p>
<script type="math/tex; mode=display">\begin{align}
x_t & = \frac{\alpha_t}{\alpha_s}x_s - 2\alpha_t\int_{\lambda_s}^{\lambda_t}e^{-\lambda}\epsilon_{\theta}(x_{\lambda},\lambda)d\lambda + \sqrt{2}\alpha_t\int_{\lambda_s}^{\lambda_t}e^{-\lambda}dw_{\lambda}  \tag{13}\\
& = \frac{\sigma_t}{\sigma_s}e^{-(\lambda_t - \lambda_s)}x_s + 2\alpha_t\int_{\lambda_s}^{\lambda_t}e^{-2(\lambda_t - \lambda)}x_{\theta}(x_{\lambda},\lambda)d\lambda + \sqrt{2}\sigma_t\int_{\lambda_s}^{\lambda_t}e^{-(\lambda_t - \lambda)}dw_{\lambda} \tag{14}
\end{align}</script><p>此外，我们可以通过以下方式计算伊藤积分：</p>
<script type="math/tex; mode=display">\int_{\lambda_s}^{\lambda_t}e^{-\lambda}dw_{\lambda} = \left(\sqrt{\int_{\lambda_s}^{\lambda_t}e^{-2\lambda}d\lambda}\right)z_s = \frac{e^{-\lambda_t}}{\sqrt{2}}\sqrt{e^{2(\lambda_t - \lambda_s)} - 1}z_s \tag{15}</script><script type="math/tex; mode=display">\int_{\lambda_s}^{\lambda_t}e^{\lambda}dw_{\lambda} = \left(\sqrt{\int_{\lambda_s}^{\lambda_t}e^{2\lambda}d\lambda}\right)z_s = \frac{e^{\lambda_t}}{\sqrt{2}}\sqrt{1 - e^{-2(\lambda_t - \lambda_s)}}z_s \tag{16}</script><p>其中$z_s \sim N(0, I)$。因此，我们可以对关于$\epsilon_{\theta}$或$x_{\theta}$的积分进行离散化，得到相应的扩散随机微分方程求解器，如下所示。为简化表示，记$h := \lambda_t - \lambda_s$。</p>
<ul>
<li><strong>SDE-DPM-Solver-1</strong>：令$z_s \sim N(0, I)$。假设$\epsilon_{\theta}(x_{\lambda},\lambda) \approx \epsilon_{\theta}(x_s,s)$，则有：<script type="math/tex; mode=display">x_t = \frac{\alpha_t}{\alpha_s}x_s - 2\sigma_t(e^h - 1)\epsilon_{\theta}(x_s,s) + \sigma_t\sqrt{e^{2h} - 1}z_s \tag{17}</script></li>
<li><strong>SDE-DPM-Solver++1</strong>：令$z_s \sim N(0, I)$。假设$x_{\theta}(x_{\lambda},\lambda) \approx x_{\theta}(x_s,s)$，则有：<script type="math/tex; mode=display">x_t = \frac{\sigma_t}{\sigma_s}e^{-h}x_s + \alpha_t(1 - e^{-2h})x_{\theta}(x_s,s) + \sigma_t\sqrt{1 - e^{-2h}}z_s \tag{18}</script></li>
<li><strong>SDE-DPM-Solver-2M</strong>：令$z_s \sim N(0, I)$。假设在时间$r &lt; t$有一个先前的解$x_r$及其模型输出$\epsilon_{\theta}(x_r,r)$。记$r_1 = \frac{\lambda_r - \lambda_s}{h}$。假设$\epsilon_{\theta}(x_{\lambda},\lambda) \approx \epsilon_{\theta}(x_s,s) + \frac{\lambda - \lambda_s}{r_1h}(\epsilon_{\theta}(x_r,r) - \epsilon_{\theta}(x_s,s))$，则有：<script type="math/tex; mode=display">x_t = \frac{\alpha_t}{\alpha_s}x_s - 2\sigma_t(e^h - 1)\epsilon_{\theta}(x_s,s) - \sigma_t(e^h - 1)\frac{\epsilon_{\theta}(x_r,r) - \epsilon_{\theta}(x_s,s)}{r_1} + \sigma_t\sqrt{e^{2h} - 1}z_s \tag{19}</script></li>
<li><strong>SDE-DPM-Solver++(2M)</strong>：令$z_s \sim N(0, I)$。假设在时间$r &lt; t$有一个先前的解$x_r$及其模型输出$x_{\theta}(x_r,r)$。记$r_1 = \frac{\lambda_r - \lambda_s}{h}$。假设$x_{\theta}(x_{\lambda},\lambda) \approx x_{\theta}(x_s,s) + \frac{\lambda - \lambda_s}{r_1h}(x_{\theta}(x_r,r) - x_{\theta}(x_s,s))$，则有：<script type="math/tex; mode=display">x_t = \frac{\sigma_t}{\sigma_s}e^{-h}x_s + \alpha_t(1 - e^{-2h})x_{\theta}(x_s,s) + \frac{\alpha_t(1 - e^{-2h})}{2}\left(\frac{x_{\theta}(x_r,r) - x_{\theta}(x_s,s)}{r_1}\right) + \sigma_t\sqrt{1 - e^{-2h}}z_s \tag{20}</script></li>
</ul>
<h3 id="6-与其他快速采样方法的关系"><a href="#6-与其他快速采样方法的关系" class="headerlink" title="6 与其他快速采样方法的关系"></a>6 与其他快速采样方法的关系</h3><p>本质上，所有针对扩散概率模型（DPMs）的免训练采样方法，都可理解为对扩散随机微分方程（SDEs）进行离散化（Ho等人，2020；Song等人，2021b；Jolicoeur-Martineau等人，2021；Tachibana等人，2021；Kong和Ping，2021；Bao等人，2022b；Zhang等人，2022），或者对扩散常微分方程（ODEs）进行离散化（Song等人，2021b、a；Liu等人，2022b；Zhang和Chen，2022；Lu等人，2022）。由于DPM-Solver++是为求解扩散ODEs而设计的，在本节中，我们将探讨DPM-Solver++与其他扩散ODE求解器之间的关系，并简要讨论其他针对DPMs的快速采样方法。</p>
<h4 id="6-1-与基于指数积分器的求解器的比较"><a href="#6-1-与基于指数积分器的求解器的比较" class="headerlink" title="6.1 与基于指数积分器的求解器的比较"></a>6.1 与基于指数积分器的求解器的比较</h4><p>一般版本的DDIM（$\eta \geq 0$）公式为（Song等人，2021a）：</p>
<script type="math/tex; mode=display">\overline{x}_{t_{i}}=\alpha_{t_{i}} x_{\theta}\left(\overline{x}_{t_{i-1}}, t_{i-1}\right)+\sqrt{\sigma_{t_{i}}^{2}-\eta^{2}} \epsilon_{\theta}\left(\overline{x}_{t_{i-1}}, t_{i-1}\right)+\eta z_{t_{i-1}} \tag{21}</script><p>以往最先进的快速扩散ODE求解器（Lu等人，2022；Zhang和Chen，2022）利用指数积分器，通过噪声预测模型$\epsilon_{\theta}$来求解扩散ODEs。简而言之，这些求解器对公式（7）中的精确解进行近似，并且将$\eta = 0$时的DDIM（Song等人，2021a）作为一阶情况。下面我们证明，DPM-Solver++的一阶情况同样是DDIM。</p>
<p>当$k = 1$时，公式（9）（省略$O(h_{i}^{k + 1})$项后）变为：</p>
<script type="math/tex; mode=display">\tilde{x}_{t_{i}}=\frac{\sigma_{t_{i}}}{\sigma_{t_{i-1}}} \tilde{x}_{t_{i-1}}+\sigma_{t_{i}} x_{\theta}\left(\tilde{x}_{t_{i-1}}, t_{i-1}\right) \int_{\lambda_{t_{i-1}}}^{\lambda_{t_{i}}} e^{\lambda} d \lambda=\frac{\sigma_{t_{i}}}{\sigma_{t_{i-1}}} \tilde{x}_{t_{i-1}}-\alpha_{t_{i}}\left(e^{-h_{i}} - 1\right) x_{\theta}\left(\tilde{x}_{t_{i-1}}, t_{i-1}\right)</script><p>因此，我们提出的DPM-Solver++是$\eta = 0$时DDIM在数据预测模型$x_{\theta}$方面的高阶扩展。据我们所知，此前尚未有人提出过这种扩展。我们在表1中列出了以往基于指数积分器的高阶求解器与DPM-Solver++之间的详细差异。需要强调的是，尽管这些求解器的一阶版本是等价的，但它们的高阶版本却有很大不同。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t1.png" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表1：基于指数积分器的高阶扩散常微分方程（ODE）求解器之间的比较，包括DEIS（Zhang和Chen，2022）、DPM-Solver（Lu等人，2022）以及DPM-Solver++（我们提出的方法）。</em></td>
</tr>
</tbody>
</table>
</div>
<p>此外，对于$\eta=\sigma_{t} \sqrt{1 - e^{-2h}}$的DDIM，很容易验证，这种随机DDIM与SDE-DPM-Solver++1是等价的。因此，我们提出的SDE-DPM-Solver++(2M)是一阶随机DDIM的二阶广义版本。据我们所知，此前的研究并未揭示这一发现。</p>
<h4 id="6-2-其他快速采样方法"><a href="#6-2-其他快速采样方法" class="headerlink" title="6.2 其他快速采样方法"></a>6.2 其他快速采样方法</h4><p>基于扩散SDEs的采样器（Ho等人，2020；Song等人，2021b；Jolicoeur-Martineau等人，2021；Tachibana等人，2021；Kong和Ping，2021；Bao等人，2022b；Zhang等人，2022）通常比基于扩散ODEs的采样器（Lu等人，2022）需要更多的步骤才能收敛，这是因为SDEs引入了更多的随机性，使得去噪更加困难。基于额外训练的采样器包括模型蒸馏（Salimans和Ho，2022；Luhman和Luhman，2021）、学习反向过程方差（San-Roman等人，2021；Nichol和Dhariwal，2021；Bao等人，2022a）以及学习采样步骤（Lam等人，2021；Watson等人，2022）。然而，基于训练的采样器难以扩展到预训练的大型DPMs（Saharia等人，2022b；Rombach等人，2022；Ramesh等人，2022）。还有其他快速采样方法，例如将原始DPMs修改到潜在空间（Vahdat等人，2021），或者引入动量（Dockhorn等人，2022）。此外，将DPMs与GANs相结合（Xiao等人，2022；Wang等人，2022），可以提高GANs的样本质量和DPMs的采样速度。</p>
<h3 id="7-实验"><a href="#7-实验" class="headerlink" title="7 实验"></a>7 实验</h3><p>在本节中，我们展示了DPM-Solver++能够加速像素空间和潜空间扩散概率模型（DPMs）的引导采样。我们改变函数评估次数（NFE，即对模型$\epsilon_{\theta}(x_{t}, t, c)$或$x_{\theta}(x_{t}, t, c)$的调用次数），并将DPM-Solver++与之前DPMs的前沿快速采样器进行比较，这些采样器包括DPM-Solver（Lu等人，2022）、DEIS（Zhang和Chen，2022）、PNDM（Liu等人，2022b）和DDIM（Song等人，2021a）。我们还将离散时间DPMs转换为连续时间，并使用这些连续时间求解器。具体的实现细节和实验设置请参考附录C。</p>
<p>由于之前的求解器没有测试在引导采样中的性能，我们还通过调整步长调度（即时间步$\{t_{i}\}_{i = 0}^{M}$的选择）和求解器阶数，仔细优化了基线采样器。我们发现：</p>
<ul>
<li><strong>步长调度</strong>：我们在以下几种选择中搜索时间步：均匀的$t$（这是高分辨率图像合成中广泛使用的设置）、均匀的$\lambda$（用于（Lu等人，2022））、$t$的幂函数的均匀划分（用于（Zhang和Chen，2022），详见附录C），结果发现最佳选择是均匀的$t$。因此，在我们所有实验中，对所有求解器的时间步都使用均匀的$t$。</li>
<li><strong>求解器阶数</strong>：我们发现对于较大的引导尺度，之前所有求解器的最佳选择是二阶（即DPM-Solver-2和DEIS-1）。然而，为了进行全面比较，我们运行了之前求解器的所有阶数，包括DPM-Solver-2和DPM-Solver-3、DEIS-1、DEIS-2和DEIS-3，并在每次比较中针对每个NFE选择它们的最佳结果。</li>
</ul>
<p>我们同时运行DPM-Solver++(2S)和DPM-Solver++(2M)，发现在较大引导尺度下，多步的DPM-Solver++(2M)性能更好；在稍小的引导尺度下，单步的DPM-Solver++(2S)性能更好。在后续章节中，我们报告DPM-Solver++和之前所有采样器的最佳结果，详细数值列于附录D。</p>
<h4 id="7-1-带引导的像素空间DPMs"><a href="#7-1-带引导的像素空间DPMs" class="headerlink" title="7.1 带引导的像素空间DPMs"></a>7.1 带引导的像素空间DPMs</h4><p>我们首先在ImageNet 256x256数据集上，使用预训练的DPMs（Dhariwal和Nichol，2021），将DPM-Solver++与其他采样器在分类器引导的采样任务中进行比较。我们通过绘制10000个样本并计算广泛使用的FID分数（Heusel等人，2017）来衡量样本质量，通常FID分数越低，样本质量越好。我们对DDIM和DPM-Solver++都采用动态阈值化方法（Saharia等人，2022b）。我们将引导尺度$s$设置为8.0、4.0和2.0，结果如图4（a - c）所示。我们发现，在较大引导尺度下，之前所有的高阶采样器（DEIS、PNDM、DPM-Solver）收敛速度都比一阶的DDIM慢，这表明之前的高阶采样器不稳定。相比之下，DPM-Solver++在大、小引导尺度下都实现了最佳的加速性能。特别是在大引导尺度下，DPM-Solver++仅需15次NFE就几乎可以收敛。</p>
<p>作为对比实验，我们还比较了单步的DPM-Solver-2、单步的DPM-Solver++(2S)和多步的DPM-Solver++(2M)，以证明我们方法的有效性。我们使用较大的引导尺度$s = 8.0$，并进行以下对比实验：</p>
<ul>
<li><strong>从$\epsilon_{\theta}$到$x_{\theta}$</strong>：<font color="red" >如图3a所示，通过简单地将求解器从基于$\epsilon_{\theta}$改为基于$x_{\theta}$（即从DPM-Solver-2改为DPM-Solver++(2S)）</font>，求解器可以实现稳定的加速性能，比一阶的DDIM更快。这一结果表明，对于引导采样，基于$x_{\theta}$的高阶求解器可能比基于$\epsilon_{\theta}$的更优。</li>
<li><strong>从单步到多步</strong>：如图3b所示，多步的DPM-Solver++(2M)收敛速度略快于单步的DPM-Solver++(2S)，多步的DPM-Solver++(2M)几乎在15次NFE内就可以收敛。这一结果表明，对于较大引导尺度的引导采样，多步方法可能比单步方法更快。</li>
<li><strong>有无阈值化</strong>：我们在图3c中比较了DDIM和DPM-Solver++在有无阈值化方法下的性能。需要注意的是，阈值化方法会改变模型$x_{\theta}$，从而也会改变扩散ODE的收敛解。首先，我们发现使用阈值化方法后，扩散ODE可以生成更高质量的样本，这与（Saharia等人，2022b）中的结论一致。其次，在相同的NFE下，使用阈值化的DPM-Solver++的样本质量优于不使用阈值化的DPM-Solver++。此外，当结合阈值化方法时，DPM-Solver++比一阶的DDIM更快，这表明DPM-Solver++结合阈值化方法也可以加速DPMs的引导采样。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f3.png"/></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图3：DPM-Solver++的消融研究。在ImageNet 256×256数据集上，使用引导尺度为8.0的扩散概率模型（DPMs），采用不同采样方法并改变函数评估次数（NFE），通过FID来衡量样本质量。</em></td>
</tr>
</tbody>
</table>
</div>
<h4 id="7-2-带引导的潜空间DPMs"><a href="#7-2-带引导的潜空间DPMs" class="headerlink" title="7.2 带引导的潜空间DPMs"></a>7.2 带引导的潜空间DPMs</h4><p>我们还在潜空间DPMs（Rombach等人，2022）上评估了DPM-Solver++，由于其官方代码“stable-diffusion”，潜空间DPMs最近在社区中很受欢迎。我们使用其官方代码中默认的引导尺度$s = 7.5$。潜空间DPMs通过训练一对编码器和解码器将图像数据映射为潜码，然后为潜码训练一个DPM。由于潜码是无界的，我们不应用阈值化方法。</p>
<p>具体来说，我们从MS-COCO2014验证数据集中随机采样10000个字幕-图像对，并使用字幕作为条件，从预训练的“stable-diffusion”模型中绘制10000张图像，并且按照（Nichol等人，2021；Rombach等人，2022）中的标准评估程序，对每个字幕仅绘制一个图像样本。我们发现，即使仅用10步，所有求解器的FID都能达到15.0至16.0左右，这与“stable-diffusion”官方页面上报告的收敛样本计算出的FID非常接近。我们认为这得益于强大的预训练解码器，它可以将未收敛的潜码映射为高质量的图像样本。对于潜空间DPMs，不同的扩散ODE求解器直接影响潜空间上的收敛速度。为了进一步比较不同的潜空间DPMs采样器，我们根据采样得到的$x_{0}$与真实解<script type="math/tex">x_{0}^{*}</script>之间的L2范数（它们之间的误差为<script type="math/tex">\left\|x_{0}-x_{0}^{*}\right\|_{2} / \sqrt{D}</script>），直接比较不同求解器在潜空间上的收敛误差。具体来说，我们首先从标准正态分布中采样10000个噪声变量并固定它们。然后，使用不同的DPM采样器，从这10000个固定的噪声变量开始采样10000个潜码。由于所有这些求解器都可以理解为对扩散ODE进行离散化，我们将不同采样器在不同NFE下得到的采样潜码$x_{0}$，与999步DDIM得到的真实解$x_{0}^{*}$进行比较，结果如图4（d）所示。我们发现，“stable-diffusion”中支持的快速采样器（DDIM和PNDM）的收敛速度比DPM-Solver++和DEIS慢得多，并且我们发现二阶多步的DPM-Solver++和DEIS在潜空间上实现了相当接近的加速效果。此外，由于“stable-diffusion”默认使用50步的PNDM，我们发现DPM-Solver++仅需15至20步就能达到类似的收敛误差。我们在附录D中还给出了不同求解器采样图像的实证比较，发现DPM-Solver++确实可以在仅15至20步内生成质量相当好的图像样本。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f4.png" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图4：（a - c）在ImageNet 256x256数据集上，针对不同引导尺度s的扩散概率模型（DPMs），使用不同采样方法，通过FID衡量样本质量，同时改变函数评估次数（NFE）。†：求解器结合动态阈值化方法（Saharia等人，2022b）的结果。（d）在MS - COCO2014验证集上，针对潜空间DPM “stable - diffusion”（Rombach等人，2022），改变函数评估次数（NFE），通过L2范数（除以维度）衡量不同采样方法与1000步DDIM之间的收敛误差，其官方代码中默认引导尺度s = 7.5。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="8-结论"><a href="#8-结论" class="headerlink" title="8 结论"></a>8 结论</h3><p>我们研究了加速扩散概率模型（DPMs）引导采样的问题。研究表明，以往基于噪声预测模型的高阶求解器在大引导尺度的引导采样中异常不稳定，生成的样本质量比一阶求解器DDIM更差。为解决这一问题并加快引导采样速度，我们提出了DPM-Solver++，这是一种无需训练的快速扩散常微分方程（ODE）求解器，用于引导采样。DPM-Solver++基于使用数据预测模型的扩散ODE，可直接采用阈值化方法，进一步稳定采样过程。我们提出了DPM-Solver++的单步和多步变体。实验结果显示，DPM-Solver++能够生成高保真样本，并且仅需15至20步就几乎可以收敛，适用于像素空间和潜空间的DPMs。</p>
<h4 id="伦理声明"><a href="#伦理声明" class="headerlink" title="伦理声明"></a>伦理声明</h4><p>与生成对抗网络（GANs）等其他深度生成模型一样，DPMs也可能被用于生成有害的虚假内容（图像）。本文提出的求解器可以加速DPMs的引导采样，这可能会进一步用于图像编辑并生成逼真的虚假图像。这种影响可能会放大DPMs在恶意应用中的潜在不良后果。</p>
<h4 id="可重复性声明"><a href="#可重复性声明" class="headerlink" title="可重复性声明"></a>可重复性声明</h4><p>我们的代码基于DPM-Solver（Lu等人，2022）的官方代码，以及Dhariwal和Nichol（2021）与Stable-Diffusion（Rombach等人，2022）中的预训练检查点。我们将在盲审结束后发布代码。此外，实验中使用的数据集均可公开获取。我们在附录C中列出了详细的实验设置和实现方式，在附录A中给出了求解器收敛性的证明。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/24/Scalable-Diffusion-Models-with-Transformers%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/24/Scalable-Diffusion-Models-with-Transformers%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Scalable Diffusion Models with Transformers论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-24 18:47:26" itemprop="dateCreated datePublished" datetime="2025-03-24T18:47:26+08:00">2025-03-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-25 10:24:46" itemprop="dateModified" datetime="2025-03-25T10:24:46+08:00">2025-03-25</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>我们探索了一类基于Transformer架构的新型扩散模型。我们训练图像的潜在扩散模型，用在潜在图像块上操作的Transformer替换常用的U-Net骨干网络。我们通过以每秒千兆次浮点运算（Gflops）衡量的前向传递复杂度，分析了我们的扩散Transformer（DiT）的可扩展性。我们发现，具有更高Gflops的DiT模型——通过增加Transformer的深度、宽度或增加输入令牌的数量——始终具有更低的FID（弗雷歇初始距离，Frechet Inception Distance）。除了具有良好的可扩展性，我们最大的DiT-XL/2模型在类条件ImageNet 512×512和256×256基准测试中优于所有先前的扩散模型，在后者上实现了2.27的最先进FID分数。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/24/Scalable-Diffusion-Models-with-Transformers%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/21/PSEUDO-NUMERICAL-METHODS-FOR-DIFFUSION-MODELS-ON-MANIFOLDS%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/21/PSEUDO-NUMERICAL-METHODS-FOR-DIFFUSION-MODELS-ON-MANIFOLDS%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">PSEUDO NUMERICAL METHODS FOR DIFFUSION MODELS ON MANIFOLDS论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-21 15:49:39 / 修改时间：17:08:07" itemprop="dateCreated datePublished" datetime="2025-03-21T15:49:39+08:00">2025-03-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>去噪扩散概率模型（DDPMs）能够生成高质量的样本，如图像和音频样本。然而，DDPMs需要数百到数千次迭代才能生成最终样本。此前有多项研究通过调整方差调度（如改进的去噪扩散概率模型）或去噪方程（如去噪扩散隐式模型（DDIMs））成功加速了DDPMs。但是，这些加速方法无法保持样本质量，甚至在高加速比下会引入新的噪声，这限制了它们的实用性。为了在保持样本质量的同时加速推理过程，我们提出了一种全新的观点，即应将DDPMs视为在流形上求解微分方程。基于这一观点，我们提出了适用于扩散模型的伪数值方法（PNDMs）。具体而言，我们明确了如何在流形上求解微分方程，并证明了DDIMs是伪数值方法的简单情形。我们将几种经典的数值方法转换为相应的伪数值方法，发现伪线性多步法在大多数情况下表现最佳。根据实验结果，直接使用在Cifar10、CelebA和LSUN上预训练的模型时，PNDMs仅需50步就能生成比1000步DDIMs质量更高的合成图像（加速20倍），显著优于250步的DDIMs（在FID指标上提高约0.4），并且在不同的方差调度下具有良好的泛化性。</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h3><p>去噪扩散概率模型（DDPMs）（Sohl-Dickstein等人，2015；Ho等人，2020）是一类生成模型，它通过一个迭代去噪过程来对数据分布进行建模，该去噪过程与多步加噪过程相反。DDPMs已成功应用于多种领域，包括图像生成（Ho等人，2020；Song等人，2020b）、文本生成（Hoogeboom等人，2021；Austin等人，2021）、3D点云生成（Luo和Hu，2021）、文本转语音（Kong等人，2021；Chen等人，2020）以及图像超分辨率（Saharia等人，2021）。与生成对抗网络（GANs）（Goodfellow等人，2014）不同，GANs需要根据不同的模型结构和数据集仔细调整超参数，而DDPMs可以使用相似的模型结构，并通过一个简单的去噪目标进行训练，使模型适应数据中的噪声。为了生成样本，迭代去噪过程从白噪声开始，根据模型在每一步预测的噪声逐步将其去噪，使其转化到目标域。然而，DDPMs的一个关键缺点是，它需要数百到数千次迭代才能生成高质量的样本，并且每一步至少需要通过网络一次，这使得生成大量样本的过程极其缓慢，甚至不可行。相比之下，GANs仅需通过网络一次。</p>
<p>最近有许多研究致力于提高去噪过程的速度。一些研究寻找更好的方差调度，包括Nichol和Dhariwal（2021）以及Watson等人（2021）。一些研究则专注于改变推理方程，包括Song等人（2020a）和Song等人（2020b）。去噪扩散隐式模型（DDIMs）（Song等人，2020a）依赖非马尔可夫过程，通过每次迭代执行多个步骤来加速去噪过程。概率流（PFs）（Song等人，2020b）在去噪过程和求解常微分方程之间建立了联系，并使用微分方程的数值方法来加速去噪过程。此外，我们在附录A.1中介绍了更多相关研究。然而，DDPMs与数值方法（例如前向欧拉法、线性多步法和龙格 - 库塔法（Timothy，2017））之间的这种直接联系在速度和效果方面都存在不足（见第3.1节）。一些数值方法，如前向欧拉法，虽然简单直接，但只能以牺牲质量为代价来提高速度。一些数值方法，如龙格 - 库塔法，可以在不损失质量的情况下加速反向过程，但它们在每一步都需要沿着神经网络向前传播更多次。此外，我们还注意到，数值方法在高加速比下会引入明显的噪声，这使得高阶数值方法（例如龙格 - 库塔法）甚至比DDIMs的效果更差。Salimans和Ho（2022）也提到了这一现象。为了找出经典数值方法性能下降的原因，我们进行了一些分析，发现经典数值方法可能会采样远离数据主要分布区域的数据，并且DDPMs的推理方程在最后几步不满足数值方法的一个必要条件（见第3.2节）。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f1.png" height = "50%" width = "50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图1：使用DDIMs、经典数值方法和PNDMs生成的5步、10步、20步、50步和100步的结果</em></td>
</tr>
</tbody>
</table>
</div>
<p>为了解决这些问题，我们设计了一种新的数值方法，称为适用于扩散模型的伪数值方法（PNDMs），用于在$\mathbb{R}^n$中的特定流形（即数据的高密度区域）上生成样本。我们首先直接且自洽地计算扩散模型的相应微分方程，这在DDPMs和数值方法之间建立了理论联系。考虑到经典数值方法不能保证在特定流形上生成样本，我们基于理论分析提出了全新的伪数值方法。我们还发现DDIMs是伪数值方法的简单情形，这意味着我们也为更好地理解DDIMs提供了一种新途径。此外，我们发现伪线性多步法在相似生成质量下是扩散模型最快的方法。</p>
<p>此外，我们对新理论进行了详细的理论分析，并给出了可视化结果以直观地支持我们的理论。根据实验，我们的方法具有以下几个优点：</p>
<ul>
<li>我们的方法成功结合了DDIMs和高阶数值方法的优点。我们从理论上证明了新方法PNDMs是二阶收敛的，而DDIMs是一阶收敛的，这使得PNDMs在Cifar10和CelebA数据集上能够在不损失质量的前提下加速20倍。</li>
<li>我们的方法可以在更短的采样时间内降低预训练模型的最佳FID（弗雷歇 inception距离）。在Cifar10和CelebA数据集上，仅需250步，我们的新去噪过程就能将最佳FID降低约0.4。我们在CelebA数据集上实现了2.71的新SOTA（最优）FID分数。</li>
<li>我们的方法在不同的方差调度下都能很好地工作，这意味着我们的方法具有良好的泛化性，可以与那些引入更好方差调度的研究一起使用，以进一步加速去噪过程。</li>
</ul>
<h3 id="2-背景"><a href="#2-背景" class="headerlink" title="2 背景"></a>2 背景</h3><p>在本节中，我们介绍一些背景知识。首先，我们阐述对DDPMs的经典理解。然后，基于Song等人（2020b）的研究，我们给出另一种理解，这启发我们使用数值方法加速扩散模型的去噪过程。之后，我们介绍本文后续用到的一些数值方法的背景知识。</p>
<h4 id="2-1-去噪扩散概率模型"><a href="#2-1-去噪扩散概率模型" class="headerlink" title="2.1 去噪扩散概率模型"></a>2.1 去噪扩散概率模型</h4><p>DDPMs通过迭代去噪过程，将数据分布从高斯分布建模为图像分布。设$x_0$为一幅图像，那么扩散过程是一个马尔可夫过程，其反向过程与扩散过程形式相似，满足：</p>
<script type="math/tex; mode=display">\begin{align*}
x_{t + 1} &\sim \mathcal{N}(\sqrt{1 - \beta_t}x_t, \beta_tI), \quad t = 0, 1, \cdots, N - 1\\
x_{t - 1} &\sim \mathcal{N}(\mu_{\theta}(x_t, t), \beta_{\theta}(x_t, t)I), \quad t = N, N - 1, \cdots, 1
\end{align*} \tag{1}</script><p>这里，$\beta_t$控制数据添加噪声的速度，称为方差调度。$N$是去噪过程的总步数。$\mu_{\theta}$和$\beta_{\theta}$是两个神经网络，$\theta$是它们的参数。</p>
<p>Ho等人（2020）对$\mu_{\theta}$和$\beta_{\theta}$进行了一些统计估计。根据条件高斯分布的性质，我们有：</p>
<script type="math/tex; mode=display">\begin{align*}
q(x_t | x_0) &= \mathcal{N}(\sqrt{\overline{\alpha}_t}x_0, (1 - \overline{\alpha}_t)I)\\
q(x_{t - 1} | x_t, x_0) &= \mathcal{N}(\overline{\mu}_t(x_t, x_0), \overline{\beta}_tI)
\end{align*} \tag{2}</script><p>这里，$\alpha_t = 1 - \beta_t$，$\overline{\alpha}_t = \prod_{i = 1}^{t}\alpha_i$，$\overline{\mu}_t = \frac{\sqrt{\alpha_{t - 1}}\beta_t}{1 - \overline{\alpha}_t}x_0 + \frac{\sqrt{\alpha_t}(1 - \overline{\alpha}_{t - 1})}{1 - \overline{\alpha}_t}x_t$，$\overline{\beta}_t = \frac{1 - \overline{\alpha}_{t - 1}}{1 - \overline{\alpha}_t}\beta_t$。然后，本文设定$\beta_{\theta} = \overline{\beta}_t$，并设计了一个目标函数来帮助神经网络表示$\mu_{\theta}$。<br><strong>目标函数</strong>：目标函数定义为：</p>
<script type="math/tex; mode=display">\begin{align*}
L_{t - 1} &= \mathbb{E}_{q}[\|\overline{\mu}_t(x_t, x_0) - \mu_{\theta}(x_t, t)\|^2]\\
&= \mathbb{E}_{x_0, \epsilon}[\|\frac{1}{\sqrt{\alpha_t}}(x_t(x_0, \epsilon) - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}}\epsilon) - \mu_{\theta}(x_t(x_0, \epsilon), t)\|^2]\\
&= \mathbb{E}_{x_0, \epsilon}[\frac{\beta_t^2}{\alpha_t(1 - \overline{\alpha}_t)}\|\epsilon - \epsilon_{\theta}(\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1 - \overline{\alpha}_t}\epsilon, t)\|^2]
\end{align*} \tag{3}</script><p>这里，$x_t(x_0, \epsilon) = \sqrt{\overline{\alpha}_t}x_0 + \sqrt{1 - \overline{\alpha}_t}\epsilon$，$\epsilon \sim N(0, 1)$，$\epsilon_{\theta}$是对噪声$\epsilon$的估计。$\mu_{\theta}$与$\epsilon_{\theta}$的关系为$\mu_{\theta} = \frac{1}{\sqrt{\alpha_t}}(x_t - \frac{\beta_t}{\sqrt{1 - \overline{\alpha}_t}}\epsilon_{\theta})$。由于$\epsilon \sim N(0, 1)$，我们假设$\epsilon_{\theta}$的均值和方差分别为0和1。</p>
<h4 id="2-2-随机微分方程"><a href="#2-2-随机微分方程" class="headerlink" title="2.2 随机微分方程"></a>2.2 随机微分方程</h4><p>根据Song等人（2020b）的研究，对DDPMs还有另一种理解。扩散过程可以看作是求解某个随机微分方程$dx = (\sqrt{1 - \beta(t)} - 1)x(t)dt + \sqrt{\beta(t)}dw$。根据Anderson（1982）的研究，去噪过程也满足一个类似的随机微分方程：</p>
<script type="math/tex; mode=display">dx = ((\sqrt{1 - \beta(t)} - 1)x(t) - \beta(t)\epsilon_{\theta}(x(t), t))dt + \sqrt{\beta(t)}d\overline{w} \tag{4}</script><p>这是方差保持随机微分方程（VP-SDEs）。这里，我们将$t$的定义域从$[1, N]$变为$[0, 1]$。当$N$趋于无穷时，$\{\beta_i\}_{i = 1}^{N}$，$\{x_i\}_{i = 1}^{N}$变为$[0, 1]$上的连续函数$\beta(t)$和$x(t)$。Song等人（2020b）还表明，该方程存在一个常微分方程（ODE）版本，其边际概率密度与方程（4）相同：</p>
<script type="math/tex; mode=display">dx = ((\sqrt{1 - \beta(t)} - 1)x(t) - \frac{1}{2}\beta(t)\epsilon_{\theta}(x(t), t))dt \tag{5}</script><p>这个没有随机项的不同去噪方程与相同的扩散方程一起构成了概率流（PFs）。这两个去噪方程为我们展示了一种新的可能性，即可以使用数值方法加速反向过程。据我们所知，DDIMs首先尝试去除这个随机项，所以PFs也可以看作是DDIMs的加速版本，而VP-SDEs是DDPMs的加速版本。</p>
<h4 id="2-3-数值方法"><a href="#2-3-数值方法" class="headerlink" title="2.3 数值方法"></a>2.3 数值方法</h4><p>许多经典的数值方法可用于求解常微分方程，包括前向欧拉法、龙格 - 库塔法和线性多步法（Timothy，2017）。</p>
<ul>
<li><strong>前向欧拉法</strong>：对于满足$\frac{dx}{dt} = f(x, t)$的某个微分方程，最基本的数值方法是前向欧拉法，满足$x_{t + \delta} = x_t + \delta f(x_t, t)$。</li>
<li><strong>龙格 - 库塔法</strong>：龙格 - 库塔法在每一步使用更多信息，因此可以达到更高的精度。龙格 - 库塔法满足：<script type="math/tex; mode=display">\begin{cases}
k_1 = f(x_t, t)\\
k_2 = f(x_t + \frac{\delta}{2}k_1, t + \frac{\delta}{2})\\
k_3 = f(x_t + \frac{\delta}{2}k_2, t + \frac{\delta}{2})\\
k_4 = f(x_t + \delta k_3, t + \delta)\\
x_{t + \delta} = x_t + \frac{\delta}{6}(k_1 + 2k_2 + 2k_3 + k_4)
\end{cases} \tag{6}</script></li>
<li><strong>线性多步法</strong>：线性多步法是另一种数值方法，满足：<script type="math/tex; mode=display">x_{t + \delta} = x_t + \frac{\delta}{24}(55f_t - 59f_{t - \delta} + 37f_{t - 2\delta} - 9f_{t - 3\delta}), \quad f_t = f(x_t, t) \tag{7}</script></li>
</ul>
<h3 id="3-用于DDPM的伪数值方法"><a href="#3-用于DDPM的伪数值方法" class="headerlink" title="3 用于DDPM的伪数值方法"></a>3 用于DDPM的伪数值方法</h3><p>在本节中，我们首先计算扩散模型相应的微分方程，以在DDPM和数值方法之间建立直接联系。作为一个附带好处，我们可以直接使用DDPM的预训练模型。在建立了这种联系之后，我们详细分析经典数值方法的弱点。为了解决经典数值方法中存在的问题，我们深入研究数值方法的结构，将其方程分为梯度部分和转移部分，并通过引入非线性转移部分来定义伪数值方法。我们发现DDIM可以被视为简单的伪数值方法。然后，我们探讨不同数值方法的优缺点，并选择线性多步法来提高数值方法的速度。最后，我们总结研究结果和分析，并提出适用于扩散模型的新型伪数值方法（PNDM），它结合了我们提出的转移部分和线性多步法的梯度部分。此外，我们分析伪数值方法的收敛阶数，从理论上证明我们方法的有效性。</p>
<h4 id="3-1-公式转换"><a href="#3-1-公式转换" class="headerlink" title="3.1 公式转换"></a>3.1 公式转换</h4><p>根据Song等人（2020a）的研究，DDPM和DDIM的反向过程满足：</p>
<script type="math/tex; mode=display">x_{t - 1}=\sqrt{\overline{\alpha}_{t - 1}}\left(\frac{x_{t}-\sqrt{1-\overline{\alpha}_{t}}\epsilon_{\theta}(x_{t}, t)}{\sqrt{\overline{\alpha}_{t}}}\right)+\sqrt{1-\overline{\alpha}_{t - 1}-\sigma_{t}^{2}}\epsilon_{\theta}(x_{t}, t)+\sigma_{t}\epsilon_{t} \tag{8}</script><p>这里，$\sigma_{t}$控制随机噪声的比例。如果$\sigma_{t}=1$，公式（8）代表DDPM的反向过程；如果$\sigma_{t}=0$，这个公式代表DDIM的反向过程。只有当$\sigma_{t}=0$时，这个公式才会去掉随机项，成为某个常微分方程的离散形式。从理论上讲，可用于带随机项微分方程的数值方法是有限的。Song等人（2020b）在这种情况下已经做了充分的研究。从经验上看，Song等人（2020a）已经表明，当总步数相对较少时，DDIM具有更好的加速效果。因此，我们的工作集中在$\sigma_{t}=0$的情况。</p>
<p>为了找到公式（8）相应的常微分方程，我们根据Song等人（2020a）的方法，用连续版本$t - \delta$替换离散的$t - 1$，并将这个公式转化为微分形式，即从公式两边减去$x_{t}$：</p>
<script type="math/tex; mode=display">x_{t - \delta}-x_{t}=(\overline{\alpha}_{t - \delta}-\overline{\alpha}_{t})\left(\frac{x_{t}}{\sqrt{\overline{\alpha}_{t}}(\sqrt{\overline{\alpha}_{t - \delta}}+\sqrt{\overline{\alpha}_{t}})}-\frac{\epsilon_{\theta}(x_{t}, t)}{\sqrt{\overline{\alpha}_{t}}(\sqrt{(1-\overline{\alpha}_{t - \delta})\overline{\alpha}_{t}}+\sqrt{(1-\overline{\alpha}_{t})\overline{\alpha}_{t - \delta}})}\right) \tag{9}</script><p>因为$\delta$是一个从0到$t$的连续变量，我们现在可以计算生成数据$x_{t}$的导数，得到$\lim_{\delta \to 0}\frac{x_{t}-x_{t - \delta}}{\delta}=-\overline{\alpha}’(t)\left(\frac{x(t)}{2\overline{\alpha}(t)}-\frac{\epsilon_{\theta}(x(t), t)}{2\overline{\alpha}(t)\sqrt{1-\overline{\alpha}(t)}}\right)$。这里，$\overline{\alpha}(t)$是$\{\overline{\alpha}_{i}\}_{i = 1}^{N}$的连续版本，类似于$x(t)$的定义。因此，当$\delta$趋于0时，公式（9）相应的常微分方程为：</p>
<script type="math/tex; mode=display">\frac{dx}{dt}=-\overline{\alpha}'(t)\left(\frac{x(t)}{2\overline{\alpha}(t)}-\frac{\epsilon_{\theta}(x(t), t)}{2\overline{\alpha}(t)\sqrt{1-\overline{\alpha}(t)}}\right) \tag{10}</script><h4 id="3-2-经典数值方法"><a href="#3-2-经典数值方法" class="headerlink" title="3.2 经典数值方法"></a>3.2 经典数值方法</h4><p>得到目标常微分方程后，最直接的求解方法是使用经典数值方法。然而，我们注意到经典数值方法在高加速比下会引入明显的噪声，使得高阶数值方法（如Runge - Kutta法）甚至比DDIM的效果更差。Salimans和Ho（2022）也提到了这种现象。为了更好地使用数值方法，我们分析公式（10）与常见微分方程之间的差异，发现直接将数值方法应用于扩散模型时存在两个主要问题。</p>
<p>第一个问题是神经网络$\epsilon_{\theta}$和公式（10）仅在有限区域内有良好定义。公式（2）表明数据$x_{t}$是沿着一条接近弧线的曲线生成的。根据图2，大多数$x_{t}$集中在宽度约为0.1的带状区域内，即图2中的红色区域。这意味着在远离该区域的地方，神经网络$\epsilon_{\theta}$无法获得足够的样本以成功拟合噪声。因此，$\epsilon_{\theta}$和包含$\epsilon_{\theta}$的公式（10）仅在这个有限区域内有良好定义。然而，所有经典数值方法都是沿着直线生成结果，而不是弧线。生成过程可能会生成远离定义良好区域的样本，从而引入新的误差。在4.3节中，我们将给出更多可视化结果来支持这一点。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f2.png" height = "50%" width = "50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图2：数据范数的密度分布</em></td>
</tr>
</tbody>
</table>
</div>
<p>第二个问题是公式（10）在大多数情况下是无界的。我们发现，对于大多数线性方差调度$\beta_{t}$，当$t$趋于0时，公式（10）趋于无穷（见附录A.4），这不符合2.3节中提到的数值方法的条件。这是一个明显的理论缺陷，而以前的研究并未对此进行探讨。相反，在原始的DDPM和DDIM中，随着索引$t$趋于0，对样本$x_{t}$和数据中噪声$\epsilon_{\theta}$的预测越来越精确（见附录A.5）。这意味着原始的扩散模型在最后几步不会产生显著误差，而对公式（10）使用数值方法却会产生误差。这解释了为什么DDIM比高阶数值方法表现更好。</p>
<h4 id="3-3-流形上的伪数值方法"><a href="#3-3-流形上的伪数值方法" class="headerlink" title="3.3 流形上的伪数值方法"></a>3.3 流形上的伪数值方法</h4><p>上述第一个问题表明，我们应该尝试在特定的流形上解决问题。这里，目标流形是DDPM数据$x_{t}$的高密度区域，由$x_{t}(x_{0},\epsilon)=\sqrt{\overline{\alpha}_{t}}x_{0}+\sqrt{1-\overline{\alpha}_{t}}\epsilon$ 定义，其中$\epsilon \sim N(0,1)$。Ernst和Gerhard（1996）展示了几种用于求解具有解析表达式流形上微分方程的数值方法。不幸的是，很难使用上述流形表达式。因为在反向过程中我们不知道目标$x_{0}$，并且随机项$\epsilon$也很难处理。</p>
<p>在本文中，我们设计了一种不同的方法，使去噪过程的新方程更符合原始DDIM的方程，从而使它们的结果具有相似的数据分布。首先，我们将经典数值方法分为两部分：梯度部分和转移部分。梯度部分决定每一步的梯度，而转移部分生成下一步的结果。例如，线性多步法可以分为梯度部分$f’=\frac{\delta}{24}(55f_{t}-59f_{t - \delta}+37f_{t - 2\delta}-9f_{t - 3\delta})$和转移部分$x_{t + \delta}=x_{t}+\delta f’$。所有经典数值方法都具有相同的线性转移部分，而梯度部分不同。</p>
<p>我们将使用非线性转移部分的数值方法定义为伪数值方法。一个理想的转移部分应具有这样的特性：当梯度部分的结果精确时，转移部分的结果尽可能接近流形，并且该结果的误差尽可能小。我们发现公式（9）满足这一特性。</p>
<p><strong>属性3.1</strong>：如果$\epsilon$是$x_{t}$中的精确噪声，那么根据公式（9）得到的$x_{t - \delta}$的结果也是精确的。我们将此属性的证明放在附录A.5中。因此，我们使用：</p>
<script type="math/tex; mode=display">\phi(x_{t},\epsilon_{t},t,t - \delta)=\frac{\sqrt{\overline{\alpha}_{t - \delta}}}{\sqrt{\overline{\alpha}_{t}}}x_{t}-\frac{(\overline{\alpha}_{t - \delta}-\overline{\alpha}_{t})}{\sqrt{\overline{\alpha}_{t}}(\sqrt{(1-\overline{\alpha}_{t - \delta})\overline{\alpha}_{t}}+\sqrt{(1-\overline{\alpha}_{t})\overline{\alpha}_{t - \delta}})}\epsilon_{t} \tag{11}</script><p>作为转移部分，$\epsilon_{\theta}$作为梯度部分。也就是说，如果$\epsilon_{\theta}$是精确的，那么$x_{t - \delta}$的结果也是精确的，这意味着$\epsilon_{\theta}$可以确定去噪过程的方向以生成最终结果。因此，这样的选择也满足梯度部分的定义。现在，我们有了梯度部分$\epsilon_{\theta}$和转移部分$\phi$。</p>
<p>这种组合成功解决了上述两个问题。首先，我们的新转移部分不会引入新的误差。这个属性还意味着它将下一步的结果保持在目标流形上，因为生成远离流形的样本是一种误差。这表明我们解决了第一个问题。其次，在上述小节中我们知道，在反向过程中$\epsilon_{\theta}$的预测越来越精确。并且我们的新转移部分可以根据$\epsilon_{\theta}$的精确预测生成精确的结果。因此，使用伪数值方法时，我们的生成结果越来越精确，而经典数值方法在最后几步会引入明显的误差。这表明我们也解决了第二个问题。我们还发现，它们的组合$\phi(x_{t},\epsilon_{\theta}(x_{t},t),t,t - 1)$正是DDIM使用的推理方程，所以DDIM是伪数值方法的一个简单案例。在这里，我们将DDIM定义为DDIM*，强调它是一种伪数值方法。</p>
<h4 id="3-4-梯度部分"><a href="#3-4-梯度部分" class="headerlink" title="3.4 梯度部分"></a>3.4 梯度部分</h4><p>由于我们将数值方法分为两部分，所以即使我们改变了推理方程的转移部分，也可以自由地使用不同经典数值方法的相同梯度部分（例如线性多步法）。我们的理论分析和实验表明，不同经典方法的梯度部分都能与我们的新转移部分很好地配合（见3.6节、4.2节）。通过使用线性多步法的相同梯度部分，我们得到：</p>
<script type="math/tex; mode=display">\begin{cases}
e_{t}=\epsilon_{\theta}(x_{t},t)\\
e_{t}'=\frac{1}{24}(55e_{t}-59e_{t - \delta}+37e_{t - 2\delta}-9e_{t - 3\delta})\\
x_{t + \delta}=\phi(x_{t},e_{t}',t,t + \delta)
\end{cases} \tag{12}</script><p>通过使用龙格 - 库塔法的相同梯度部分，我们得到：</p>
<script type="math/tex; mode=display">\begin{cases}
e_{t}^{1}=\epsilon_{\theta}(x_{t},t)\\
x_{t}^{1}=\phi(x_{t},e_{t}^{1},t,t+\frac{\delta}{2})\\
e_{t}^{2}=\epsilon_{\theta}(x_{t}^{1},t+\frac{\delta}{2})\\
x_{t}^{2}=\phi(x_{t},e_{t}^{2},t,t+\frac{\delta}{2})\\
e_{t}^{3}=\epsilon_{\theta}(x_{t}^{2},t,t+\frac{\delta}{2})\\
x_{t}^{3}=\phi(x_{t},e_{t}^{3},t,t+\delta)\\
e_{t}^{4}=\epsilon_{\theta}(x_{t}^{4},t+\delta)\\
e_{t}'=\frac{1}{6}(e_{t}^{1}+2e_{t}^{2}+2e_{t}^{3}+e_{t}^{4})\\
x_{t - \delta}=\phi(x_{t},e_{t}',t,t+\delta)
\end{cases} \tag{13}</script><p>将公式（12）和（13）简记为$x_{t + \delta}, e_{t} = PLMS(x_{t},\{e_p\}_{p &lt; t}, t, t + \delta)$，$x_{t + \delta}, e_{t}^{1} = PRK(x_{t}, t, t + \delta)$。</p>
<p>这里，我们提供了三种伪数值方法。虽然高阶数值方法可以加速去噪过程，但有些方法可能需要在每一步多次计算梯度部分$\epsilon_{\theta}$，如龙格 - 库塔法。沿着神经网络向前传播四次会使去噪过程变慢。然而，我们发现线性多步法可以重复使用$\epsilon_{\theta}$的结果四次，并且每一步只计算一次$\epsilon_{\theta}$。理论分析表明，龙格 - 库塔法和线性多步法具有相同的收敛阶数和相似的结果。</p>
<p>因此，我们使用线性多步法的梯度部分和新的转移部分作为扩散模型的主要伪数值方法（PNDM）。在表1中，我们展示了不同数值方法之间的关系。在这里，我们可以看到PNDM结合了高阶经典数值方法（在梯度部分）和DDIM（在转移部分）的优点。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "t1.png" width = "50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表1：不同数值方法之间的关系</em></td>
</tr>
</tbody>
</table>
</div>
<h4 id="3-5-算法"><a href="#3-5-算法" class="headerlink" title="3.5 算法"></a>3.5 算法</h4><p>现在我们可以给出DDIM去噪过程的完整算法。根据Song等人（2020a）的研究，原始方法的算法如算法1所示。我们新的PNDM算法使用伪线性多步法和伪龙格 - 库塔法，如算法2所示。这里，我们最初不能使用线性多步法，因为线性多步法不能自动开始，它至少需要前三个步骤的信息才能生成结果。所以我们使用龙格 - 库塔法计算前三个步骤的结果，然后使用线性多步法计算剩余步骤的结果。</p>
<p>我们还使用两种二阶数值方法的梯度部分得到另一种伪数值方法。我们在附录A.3中介绍这种方法的详细信息。我们将其称为S - PNDM，因为它的梯度部分在每一步使用来自两个步骤的信息。类似地，当我们需要区分时，我们也将第一种PNDM称为F - PNDM，它使用来自四个步骤的数据。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "a1.png" ></th>
<th style="text-align:center"><img src = "a2.png"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>算法1</em></td>
<td style="text-align:center"><em>算法2</em></td>
</tr>
</tbody>
</table>
</div>
<h4 id="3-6-收敛阶数"><a href="#3-6-收敛阶数" class="headerlink" title="3.6 收敛阶数"></a>3.6 收敛阶数</h4><p>改变数值方法的转移部分可能会引入未知误差。为了从理论上确定新转移部分的影响，我们计算公式（10）的理论结果$x(t + \delta)$与新方法之间的局部和全局误差，发现$x(t + \delta)-x_{DDIM}(x+\delta)=O(\delta^{2})$，并且：</p>
<script type="math/tex; mode=display">x(t + \delta)-x_{S/F - PNDM}(x+\delta)=O(\delta^{3}) \tag{14}</script><p>如果目标常微分方程满足利普希茨条件，并且局部误差$e_{local}=O(\delta^{k})$，那么存在$c$和$h$，使得全局误差$e_{global}$满足$e_{global} \leq C\delta^{k}(1 + e^{h}+e^{2h}+\cdots) \leq C’\delta^{k - 1}$。并且我们知道收敛阶数等于全局误差的阶数。详细证明见附录A.6。因此，我们得到以下属性：</p>
<p><strong>属性3.2</strong>：S/F - PNDM具有三阶局部误差，是二阶收敛的。</p>
<h3 id="4-实验"><a href="#4-实验" class="headerlink" title="4 实验"></a>4 实验</h3><h4 id="4-1-实验设置"><a href="#4-1-实验设置" class="headerlink" title="4.1 实验设置"></a>4.1 实验设置</h4><p>我们在四个数据集上进行无条件图像生成实验：Cifar10（32×32）（Krizhevsky等人，2009年）、CelebA（64×64）（Liu等人，2015年）、LSUN教堂（256×256）和LSUN卧室（256×256）（Yu等人，2016年）。根据3.1节中的分析，我们在实验中可以使用先前研究中的预训练模型。Cifar10、LSUN教堂和LSUN卧室的预训练模型取自Ho等人（2020年），CelebA的预训练模型取自Song等人（2020a）。在这些模型中，总步数N为1000，方差调度采用线性方差调度。我们还使用了一个Cifar10的预训练模型，该模型采用改进的去噪扩散概率模型（iDDPMs，Nichol和Dhariwal，2021年）中的余弦方差调度。</p>
<h4 id="4-2-样本效率和质量"><a href="#4-2-样本效率和质量" class="headerlink" title="4.2 样本效率和质量"></a>4.2 样本效率和质量</h4><p>为了分析加速效果，我们在不同数据集上，针对不同步数和不同数值方法（包括DDIMs、S-PNDMs、F-PNDMs以及经典四阶数值方法（FONs），如Runge-Kutta方法和线性多步法）测试Fenchel Inception Distance（FID，Heusel等人，2018年）。在Cifar10和CelebA数据集上，我们首先给出先前研究中DDIMs的结果。然后，我们使用相同的预训练模型测试本文中提到的数值方法，并将结果列在Cifar10/CelebA（线性）中。我们还使用iDDPMs的模型测试非线性方差调度，并将结果列在Cifar10（余弦）中。Song等人（2020b）没有提供概率流（PFs）在不同步数下的详细FID结果，因此我们使用其预训练模型重新测试了这些结果。</p>
<ul>
<li><strong>效率</strong>：我们的两个基线方法是DDIM和PF。DDIM是伪数值方法的一个简单示例，而PF是经典数值方法的一种情况。然而，PF使用的模型比DDIM大得多，并且使用了一些技巧来提高样本质量。为了确保实验的公平性，我们对公式（10）使用四阶数值方法，并采用DDIM的模型。在表2中，我们发现当步数较少时，FON的性能有限。相比之下，我们的新方法，包括S-PNDM和F-PNDM，无论使用的步数是多还是少，都能改善生成的结果。根据Cifar10/CelebA（线性）的结果，F-PNDM仅用50步就能实现比1000步DDIM更低的FID，使扩散模型在不损失质量的情况下加速20倍。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "t2.png" width = "80%" height="80%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表2：Cifar10和CelebA上图像生成的FID测量结果。PFs使用黑盒ODE求解器，我们将分数函数评估的次数作为PFs的步数。DDIM</em>是对DDIM的重新测试。加粗结果表示使用相同预训练模型时的最佳结果。我们在RTX3090上使用50步、512批次大小的实验来测试计算成本，“时间”列是每步的平均计算成本（秒）。标准差结果见附录A.12。*</td>
</tr>
</tbody>
</table>
</div>
<p>我们根据上述Cifar10（线性）的结果绘制了计算成本与FID的折线图（图3）。由于F-PNDM在前三步使用伪Runge-Kutta方法生成结果，所以在最初的几步中它比其他方法慢。因此，S-PNDM最初能实现最佳的FID，随后F-PNDM成为最佳方法，并且加速效果显著。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f3.png" width = "30%" height="30%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图3：Cifar10上不同计算成本和不同数值方法下的FID结果。时间单位是1步DDIM的计算成本，即0.337秒。</em></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li><strong>质量</strong>：当步数相对较多时，FON的结果与伪数值方法的结果越来越相似。这是因为所有方法都在求解公式（10），它们的收敛结果应该是相同的。然而，从经验上看，伪数值方法在使用大量步数时仍然表现更好。F-PNDM使用预训练模型可以将最佳FID提高约0.4，并在CelebA上实现了2.71的新SOTA FID分数，这表明我们的工作不仅可以加速扩散模型，还能提高样本的顶级质量。我们还注意到，F-PNDM的FID结果在超过250步后趋于收敛，之后FID结果会在某个值附近波动。在我们对LSUN进行测试时，这种现象更加明显（见表5、6）。</li>
</ul>
<p>根据Cifar10（余弦）的结果，余弦方差调度在使用相对较多的步数时可以降低FID。关于方差调度的更多分析可以在附录A.7中找到。此外，我们在其他数据集上测试了我们的方法，并在附录A.9中提供了FID结果，在附录A.10中提供了图像结果。无论数据集和图像大小如何，我们都可以就我们方法的加速效果和采样质量得出类似的结论。</p>
<h4 id="4-3-流形上的样本"><a href="#4-3-流形上的样本" class="headerlink" title="4.3 流形上的样本"></a>4.3 流形上的样本</h4><p>在这里，我们设计了可视化实验来展示新方法的效果，并支持我们的分析。由于难以可视化高维数据，我们使用全局特征范数和局部特征像素的变化来展示不同步数下数据的变化。对于像素，我们随机选择两个位置$p^1$，$p^2$。然后，对于从反向过程得到的一系列图像$x_T$，$x_{T - k}$，…，$x_0$，我们将$x_t$在位置$p^k$的值记为$y_t^k$。接着，我们在$\mathbb{R}^2$中绘制折线$(y_t^1, y_t^2)_{t = T, \cdots}$。对于范数，我们首先统计不同步数下训练数据集范数的分布，并以此制作热图作为背景。之后，我们在这个热图上绘制使用不同方法和步数生成结果的范数。</p>
<p>在图4中，我们可以看到FON可能会远离数据的高密度区域，这解释了为什么FON可能会引入明显的噪声。然而，PNDM可以避免这个问题，并能较好地拟合目标结果。更多支持我们分析的可视化结果可以在附录A.11中找到。此外，我们设计了一个简单示例来在没有神经网络影响的情况下测试新方法，得到了与上述真实情况类似的结论。详细结果见附录A.8。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f4.png" width = "80%" height="80%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图4：上图展示了使用不同方法和不同步数时，范数随步数的变化。下图展示了使用不同方法和不同步数时，两个点的生成曲线。DDIM - n表示n步的DDIM方法。本小节的实验均使用Cifar10数据集，我们将1000步DDIM的结果作为目标结果。 </em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="5-讨论"><a href="#5-讨论" class="headerlink" title="5 讨论"></a>5 讨论</h3><p>在本文中，我们提出了PNDMs，这是一种适用于求解DDPM相应常微分方程的新数值方法。PNDMs能够在不损失质量的前提下，用更少的步骤生成高质量图像。基于这项工作的思路，未来研究可以从以下几个方面进一步探索改进：</p>
<ol>
<li><strong>为PNDMs寻找更优的方差调度</strong>：尽管在本研究中我们对线性方差调度和余弦方差调度测试了PNDMs，但可能存在更适合我们所提数值方法的其他方差调度。</li>
<li><strong>寻找更高阶收敛的伪数值方法</strong>：我们分析了S/F-PNDMs的收敛阶数，它们均为二阶收敛。然而，在大多数情况下，F-PNDMs的FID表现优于S-PNDMs。我们认为这是因为转移部分与目标常微分方程之间的结果存在更高阶的误差，限制了F-PNDMs的收敛阶数。虽然这种由转移部分变化带来的误差是理论上的，且根据公式（11）的性质，它并不影响图像质量，但使转移部分更高阶收敛并探究这种变化的影响仍然是一个有趣的研究方向，值得深入探索。</li>
<li><strong>将PNDMs扩展到更广泛的应用中</strong>：在证明PNDMs的收敛阶数时，我们发现其他类型的转移部分也可以保持收敛阶数不变，这意味着伪数值方法可以应用于更广泛的领域，比如某些神经常微分方程（Chen等人，2019；Dupont等人，2019）。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/18/Elucidating-the-Design-Space-of-Diffusion-Based-Generative-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/18/Elucidating-the-Design-Space-of-Diffusion-Based-Generative-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Elucidating the Design Space of Diffusion-Based Generative Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-18 10:50:30" itemprop="dateCreated datePublished" datetime="2025-03-18T10:50:30+08:00">2025-03-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-20 15:21:47" itemprop="dateModified" datetime="2025-03-20T15:21:47+08:00">2025-03-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>我们认为，当前基于扩散的生成模型在理论和实践上过于复杂，因此试图通过提出一个设计空间来改善这种情况。该设计空间能清晰区分具体的设计选择，有助于我们确定在采样、训练过程以及分数网络预处理方面的若干改进方向。综合这些改进，在类别条件设定下，我们的模型在CIFAR-10数据集上实现了1.79的新最先进FID（弗雷歇距离），在无条件设定下为1.97，且采样速度比先前设计快得多（每生成一张图像仅需进行35次网络评估）。为进一步展示其模块化特性，我们表明，我们的设计改进能显著提升先前工作中预训练分数网络的效率和生成质量。例如，将之前训练的64×64分辨率ImageNet模型的FID从2.07提升至接近最先进的1.55，经过我们提出的改进方法重新训练后，FID达到了新的最先进水平1.36。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/18/Elucidating-the-Design-Space-of-Diffusion-Based-Generative-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/16/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/16/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">读书笔记</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-16 22:27:03 / 修改时间：22:27:29" itemprop="dateCreated datePublished" datetime="2025-03-16T22:27:03+08:00">2025-03-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="原子习惯"><a href="#原子习惯" class="headerlink" title="原子习惯"></a>原子习惯</h2><h2 id="厚黑学"><a href="#厚黑学" class="headerlink" title="厚黑学"></a>厚黑学</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/14/diffusion%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%84%9F%E6%82%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/14/diffusion%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%84%9F%E6%82%9F/" class="post-title-link" itemprop="url">diffusion论文阅读感悟</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-14 20:56:45" itemprop="dateCreated datePublished" datetime="2025-03-14T20:56:45+08:00">2025-03-14</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-24 18:18:36" itemprop="dateModified" datetime="2025-03-24T18:18:36+08:00">2025-03-24</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="NSCN-Noise-Conditional-Score-Networks-Generative-Modeling-by-Estimating-Gradients-of-the-Data-Distribution"><a href="#NSCN-Noise-Conditional-Score-Networks-Generative-Modeling-by-Estimating-Gradients-of-the-Data-Distribution" class="headerlink" title="(NSCN Noise Conditional Score Networks) Generative Modeling by Estimating Gradients of the Data Distribution"></a>(NSCN Noise Conditional Score Networks) Generative Modeling by Estimating Gradients of the Data Distribution</h2><ul>
<li>发表于2029-NeurIPS</li>
</ul>
<p>Q: 这篇论文试图解决什么问题？<br>A: 这篇论文提出了一种新的生成模型，旨在解决现有生成模型中的一些固有局限性，特别是在处理低维流形上的数据分布时的问题。具体来说，论文试图解决以下问题：<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/14/diffusion%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%84%9F%E6%82%9F/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">DPM-Solver-A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-12 20:59:26" itemprop="dateCreated datePublished" datetime="2025-03-12T20:59:26+08:00">2025-03-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-16 22:02:58" itemprop="dateModified" datetime="2025-03-16T22:02:58+08:00">2025-03-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>扩散概率模型（DPMs）是新兴的强大生成模型。尽管DPMs具有高质量的生成性能，但它们的采样速度仍然较慢，因为通常需要对大型神经网络进行数百或数千次的顺序函数评估（步骤）才能生成一个样本。从DPMs中采样可以看作是求解相应的扩散常微分方程（ODEs）。在这项工作中，我们提出了扩散ODEs解的精确公式。该公式通过解析计算解的线性部分，而不是像以往工作那样将所有项都留给黑箱ODE求解器处理。通过变量变换，解可以等效简化为神经网络的指数加权积分。基于我们的公式，我们提出了DPM-Solver，这是一种快速的、具有收敛阶保证的专用高阶扩散ODE求解器。DPM-Solver适用于离散时间和连续时间的DPMs，且无需任何额外训练。实验结果表明，DPM-Solver在各种数据集上仅需10 - 20次函数评估就能生成高质量样本。在CIFAR10数据集上，我们在10次函数评估中达到了4.70的FID（Frechet Inception Distance），在20次函数评估中达到了2.87的FID，并且与之前最先进的无训练采样器相比，在各种数据集上实现了4 - 16倍的加速。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Analytic-DPM an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-12 19:33:01" itemprop="dateCreated datePublished" datetime="2025-03-12T19:33:01+08:00">2025-03-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-16 21:35:12" itemprop="dateModified" datetime="2025-03-16T21:35:12+08:00">2025-03-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>扩散概率模型（Diffusion Probabilistic Models, DPMs）是一类强大的生成模型。尽管它们取得了成功，但DPMs的推理成本很高，因为通常需要迭代数千个时间步。推理中的一个关键问题是估计反向过程中每个时间步的方差。在这项工作中，我们给出了一个令人惊讶的结果：DPM的最优反向方差和相应的最优KL散度都可以用其得分函数的解析形式表示。在此基础上，我们提出了Analytic-DPM，这是一个无需训练的推理框架，它使用蒙特卡罗方法和预训练的基于得分的模型来估计方差和KL散度的解析形式。此外，为了纠正基于得分的模型可能带来的偏差，我们推导了最优方差的上下界，并对估计值进行裁剪以获得更好的结果。在实验中，我们的Analytic-DPM提高了各种DPM的对数似然性，生成了高质量的样本，同时实现了20到80倍的加速。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/12/Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/Understanding-Diffusion-Models-A-Unified-Perspective%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/Understanding-Diffusion-Models-A-Unified-Perspective%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Understanding Diffusion Models: A Unified Perspective论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-12 16:44:25" itemprop="dateCreated datePublished" datetime="2025-03-12T16:44:25+08:00">2025-03-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-17 18:51:12" itemprop="dateModified" datetime="2025-03-17T18:51:12+08:00">2025-03-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="引言：生成模型"><a href="#引言：生成模型" class="headerlink" title="引言：生成模型"></a>引言：生成模型</h3><p>给定来自目标分布的观测样本$x$，生成模型的目标是学习对其真实数据分布$p(x)$进行建模。一旦完成学习，我们就可以根据需要从近似模型中生成新样本。此外，在某些公式中，我们还可以使用所学模型来评估观测数据或生成数据的似然性。</p>
<p>当前文献中有几个著名的研究方向，我们将仅在较高层次上简要介绍。生成对抗网络（GANs）对复杂分布的采样过程进行建模，这种建模是通过对抗方式学习的。另一类生成模型被称为“基于似然的”，旨在学习一个为观测数据样本分配高似然的模型。这包括自回归模型、归一化流和变分自编码器（VAEs）。另一种类似的方法是基于能量的建模，其中分布被学习为一个任意灵活的能量函数，然后进行归一化。</p>
<p>分数生成模型与之高度相关；它们不是直接学习对能量函数本身进行建模，而是通过神经网络学习基于能量模型的分数。在本文中，我们将探讨并回顾扩散模型，正如我们将展示的那样，扩散模型同时具有基于似然和基于分数的解释。我们将极其详细地展示这些模型背后的数学原理，旨在让任何人都能理解扩散模型是什么以及它们的工作原理。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/12/Understanding-Diffusion-Models-A-Unified-Perspective%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zongqing Li"
      src="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
  <p class="site-author-name" itemprop="name">Zongqing Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">57</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">44</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/hqulzq" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hqulzq" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hqulzq@163.com" title="E-Mail → mailto:hqulzq@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

      
<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
<div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div id="myCanvasContainer" class="widget tagcloud">
        <canvas width="250" height="250" id="resCanvas" style="width=100%">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/2019/" rel="tag">2019</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2020/" rel="tag">2020</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2021/" rel="tag">2021</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2022/" rel="tag">2022</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2023/" rel="tag">2023</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2025/" rel="tag">2025</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bug%E6%80%BB%E7%BB%93/" rel="tag">Bug总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR/" rel="tag">CVPR</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR-Workshop/" rel="tag">CVPR Workshop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/" rel="tag">ICLR</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/" rel="tag">ICML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Knife4j/" rel="tag">Knife4j</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MinIO/" rel="tag">MinIO</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mybatis-Plus/" rel="tag">Mybatis-Plus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NeurIPS/" rel="tag">NeurIPS</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx/" rel="tag">Nginx</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RabbitMQ/" rel="tag">RabbitMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RocketMQ/" rel="tag">RocketMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a><span class="tag-list-count">24</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/" rel="tag">k8s</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/latex/" rel="tag">latex</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/" rel="tag">mongodb</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/" rel="tag">代码随想录</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%B4%E5%87%BD%E6%95%B0/" rel="tag">头函数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%9A%E5%BA%AD%E5%85%AC%E5%AF%93/" rel="tag">尚庭公寓</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/" rel="tag">异常处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" rel="tag">快速入门</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/" rel="tag">技术总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B3%A8%E8%A7%A3/" rel="tag">注解</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%AB%99/" rel="tag">网站</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%8B%A5%E4%BE%9D/" rel="tag">若依</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" rel="tag">设计模式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E8%A1%A8i/" rel="tag">链表i</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%98%85%E8%AF%BB/" rel="tag">阅读</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/" rel="tag">项目实战</a><span class="tag-list-count">6</span></li></ul>
        </canvas>
    </div>
</div>



    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zongqing Li</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #4D4D4C;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #F7F7F7;
      background-image: linear-gradient(#F7F7F7, #F7F7F7);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>

  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('post.copy_button').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('post.copy_success')
          else $(this).text('post.copy_failure')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('post.copy_button')
        }, 300)
      }).append(e)
    })
  </script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
