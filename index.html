<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hqulzq.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Lzq&#39;s blog">
<meta property="og:url" content="https://hqulzq.github.io/index.html">
<meta property="og:site_name" content="Lzq&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Zongqing Li">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://hqulzq.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Lzq's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lzq's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">43</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">12</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">49</span></a>

  </li>
        <li class="menu-item menu-item-book">

    <a href="/book" rel="section"><i class="fas fa-book fa-fw"></i>Book</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Analytic-DPM an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-12 19:33:01 / 修改时间：19:35:30" itemprop="dateCreated datePublished" datetime="2025-03-12T19:33:01+08:00">2025-03-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/Understanding-Diffusion-Models-A-Unified-Perspective%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/Understanding-Diffusion-Models-A-Unified-Perspective%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Understanding Diffusion Models: A Unified Perspective论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-12 16:44:25 / 修改时间：19:30:02" itemprop="dateCreated datePublished" datetime="2025-03-12T16:44:25+08:00">2025-03-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/FLOW-MATCHING-FOR-GENERATIVE-MODELING%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/FLOW-MATCHING-FOR-GENERATIVE-MODELING%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">FLOW MATCHING FOR GENERATIVE MODELING论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-12 15:37:40 / 修改时间：16:22:45" itemprop="dateCreated datePublished" datetime="2025-03-12T15:37:40+08:00">2025-03-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>我们提出了一种基于连续归一化流（CNFs）的生成式建模新范式，使我们能够以前所未有的规模训练CNFs。具体来说，我们提出了流匹配（FM）的概念，这是一种无需模拟的训练CNFs的方法，它基于对固定条件概率路径的向量场进行回归。流匹配与用于在噪声和数据样本之间进行转换的一般高斯概率路径族兼容，现有扩散路径是其中的特定实例。有趣的是，我们发现将FM与扩散路径结合使用，为训练扩散模型提供了一种更强大、更稳定的替代方法。此外，流匹配为使用其他非扩散概率路径训练CNFs开辟了道路。特别值得关注的一个实例是使用最优传输（OT）位移插值来定义条件概率路径。这些路径比扩散路径更高效，训练和采样速度更快，泛化性能也更好。在ImageNet数据集上使用流匹配训练CNFs，在似然性和样本质量方面均优于基于扩散的替代方法，并且使用现成的数值常微分方程（ODE）求解器就能快速可靠地生成样本。</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h3><p>深度生成模型是一类深度学习算法，旨在从未知数据分布中进行估计和采样。近年来，生成式建模取得了惊人的进展，例如在图像生成领域（Ramesh等人，2022；Rombach等人，2022），这主要得益于基于扩散的模型（Ho等人，2020；Song等人，2020b）可扩展且相对稳定的训练。然而，由于局限于简单的扩散过程，采样概率路径的空间相当有限，导致训练时间极长，并且需要采用专门的方法（例如Song等人，2020a；Zhang和Chen，2022）来进行高效采样。</p>
<p>在这项工作中，我们考虑连续归一化流（CNFs；Chen等人，2018）这一通用且确定性的框架。CNFs能够对任意概率路径进行建模，尤其值得注意的是，它涵盖了扩散过程所建模的概率路径（Song等人，2021）。然而，除了可以通过例如去噪得分匹配（Vincent，2011）进行有效训练的扩散模型外，目前还没有可扩展的CNF训练算法。实际上，最大似然训练（例如Grathwohl等人，2018）需要进行昂贵的数值ODE模拟，而现有的无模拟方法要么涉及难以处理的积分（Rozen等人，2021），要么存在有偏差的梯度（Ben-Hamu等人，2022）。</p>
<p>这项工作的目标是提出流匹配（FM），这是一种高效的无模拟方法，用于训练CNF模型，使得可以采用通用概率路径来指导CNF训练。重要的是，FM打破了除扩散之外可扩展CNF训练的障碍，并且无需考虑扩散过程，直接处理概率路径。</p>
<p>特别是，我们提出了流匹配目标（第3节），这是一个简单直观的训练目标，用于回归到生成所需概率路径的目标向量场。我们首先展示了可以通过逐样本（即条件）公式来构建这样的目标向量场。然后，受去噪得分匹配的启发，我们表明一种称为条件流匹配（CFM）的逐样本训练目标能提供等效的梯度，并且不需要明确知道难以处理的目标向量场。此外，我们讨论了可用于流匹配的一般逐样本概率路径族（第4节），现有扩散路径是该族的特殊实例。即使在扩散路径上，我们发现使用FM也能提供更强大、更稳定的训练，并且与得分匹配相比，性能更优。此外，这个概率路径族还包括一个特别有趣的情况：对应于最优传输（OT）位移插值的向量场（McCann，1997）。我们发现条件OT路径比扩散路径更简单，形成直线轨迹，而扩散路径则形成曲线。这些特性在实验中似乎转化为更快的训练速度、更快的生成速度和更好的性能。</p>
<p>我们在ImageNet上通过实验验证了流匹配以及基于最优传输路径的构建，ImageNet是一个大型且多样性高的图像数据集。我们发现，在与基于扩散的竞争方法的比较中，我们能够轻松训练模型，在似然估计和样本质量方面都取得良好的性能。此外，我们发现与先前的方法相比，我们的模型在计算成本和样本质量之间实现了更好的平衡。图1展示了从我们模型中选取的无条件ImageNet 128×128样本。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f1.png" width="70%" height="70%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图1：使用基于最优传输概率路径的流匹配方法训练的连续归一化流（CNF）生成的无条件ImageNet - 128样本。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-预备知识：连续归一化流"><a href="#2-预备知识：连续归一化流" class="headerlink" title="2 预备知识：连续归一化流"></a>2 预备知识：连续归一化流</h3><p>设$\mathbb{R}^{d}$表示数据空间，数据点$x = (x^{1}, \ldots, x^{d}) \in \mathbb{R}^{d}$。本文中使用的两个重要概念是：概率密度路径$p: [0, 1] \times \mathbb{R}^{d} \to \mathbb{R}_{&gt;0}$，它是一个随时间变化的概率密度函数，即$\int p_{t}(x)dx = 1$；以及一个随时间变化的向量场$v: [0, 1] \times \mathbb{R}^{d} \to \mathbb{R}^{d}$。向量场$v_{t}$可用于构建一个随时间变化的微分同胚映射，称为流（flow）$\phi: [0, 1] \times \mathbb{R}^{d} \to \mathbb{R}^{d}$，其由常微分方程（ODE）定义：</p>
<script type="math/tex; mode=display">\frac{d}{dt} \phi_{t}(x) = v_{t}(\phi_{t}(x)) \tag{1}</script><script type="math/tex; mode=display">\phi_{0}(x) = x \tag{2}</script><p>此前，Chen等人（2018）提出用神经网络$v_{t}(x; \theta)$对向量场$v_{t}$进行建模，其中$\theta \in \mathbb{R}^{p}$是其可学习参数，这进而产生了一个关于流$\phi_{t}$的深度参数化模型，称为连续归一化流（Continuous Normalizing Flow，CNF）。CNF用于通过推送前向方程（push - forward equation）将简单的先验密度$p_{0}$（例如纯噪声）重塑为更复杂的密度$p_{1}$：</p>
<script type="math/tex; mode=display">p_{t} = [\phi_{t}]_{*}p_{0} \tag{3}</script><p>其中，推送前向（或变量变换）算子<script type="math/tex">*</script>定义为：</p>
<script type="math/tex; mode=display">[\phi_{t}]_{*}p_{0}(x) = p_{0}(\phi_{t}^{-1}(x)) \det[\frac{\partial \phi_{t}^{-1}}{\partial x}(x)] \tag{4}</script><p>如果向量场$v_{t}$的流$\phi_{t}$满足方程（3），则称$v_{t}$生成了概率密度路径$p_{t}$。一种检验向量场是否生成概率路径的实用方法是使用连续性方程，这是我们证明过程中的一个关键部分，详见附录B。我们在附录C中补充了更多关于CNF的信息，特别是如何计算$\mathbb{R}^{d}$中任意点$x$处的概率$p_{1}(x)$。</p>
<h3 id="3-流匹配"><a href="#3-流匹配" class="headerlink" title="3 流匹配"></a>3 流匹配</h3><p>令$x_1$表示一个服从某种未知数据分布$q(x_1)$的随机变量。我们假设只能从$q(x_1)$中获取数据样本，但无法得到其密度函数。此外，令$p_t$为一条概率路径，使得$p_0 = p$是一个简单分布，例如标准正态分布$p(x) = N(x|0, I)$，并且令$p_1$的分布近似等于$q$。稍后我们将讨论如何构建这样的路径。流匹配目标旨在匹配这个目标概率路径，从而使我们能够从$p_0$流向$p_1$。</p>
<p>给定目标概率密度路径$p_t(x)$以及相应的生成$p_t(x)$的向量场$u_t(x)$，我们将流匹配（FM）目标定义为：</p>
<script type="math/tex; mode=display">\mathcal{L}_{FM}(\theta)=\mathbb{E}_{t, p_{t}(x)}\left\| v_{t}(x)-u_{t}(x)\right\| ^{2} \tag{5}</script><p>其中，$\theta$表示CNF向量场$v_t$（如第2节所定义）的可学习参数，$t \sim U[0, 1]$（均匀分布），$x \sim p_t(x)$。简单来说，FM损失通过神经网络$v_t$对向量场$u_t$进行回归。当损失达到零时，学习到的CNF模型将生成$p_t(x)$。流匹配是一个简单且有吸引力的目标，但就其本身而言，在实际中直接使用是难以处理的，因为我们事先不知道合适的$p_t$和$u_t$是什么。有许多概率路径选择都可以满足$p_1(x) \approx q(x)$，更重要的是，我们通常无法得到生成所需$p_t$的封闭形式的$u_t$。在本节中，我们将展示可以使用仅在每个样本上定义的概率路径和向量场来构建$p_t$和$u_t$，并且通过适当的聚合方法可以得到所需的$p_t$和$u_t$。此外，这种构建方式为流匹配创建了一个更易于处理的目标。</p>
<h4 id="3-1-从条件概率路径和向量场构建-p-t-、-u-t"><a href="#3-1-从条件概率路径和向量场构建-p-t-、-u-t" class="headerlink" title="3.1 从条件概率路径和向量场构建$p_t$、$u_t$"></a>3.1 从条件概率路径和向量场构建$p_t$、$u_t$</h4><p>一种构建目标概率路径的简单方法是通过混合更简单的概率路径：对于一个特定的数据样本$x_1$，我们用$p_t(x|x_1)$表示条件概率路径，使得在$t = 0$时，它满足$p_0(x|x_1) = p(x)$；在$t = 1$时，我们将$p_1(x|x_1)$设计为一个集中在$x = x_1$附近的分布，例如$p_1(x|x_1) = N(x|x_1, \sigma^2 I)$，这是一个均值为$x_1$、标准差$\sigma &gt; 0$足够小的正态分布。对$q(x_1)$求条件概率路径的边缘分布，可得到边缘概率路径：</p>
<script type="math/tex; mode=display">p_{t}(x)=\int p_{t}\left(x | x_{1}\right) q\left(x_{1}\right) d x_{1} \tag{6}</script><p>特别地，在$t = 1$时，边缘概率$p_1$是一个混合分布，它非常接近数据分布$q$，即：</p>
<script type="math/tex; mode=display">p_{1}(x)=\int p_{1}\left(x | x_{1}\right) q\left(x_{1}\right) d x_{1} \approx q(x) \tag{7}</script><p>有趣的是，我们还可以通过以下方式“边缘化”条件向量场来定义边缘向量场（假设对于所有的$t$和$x$，$p_t(x) &gt; 0$）：</p>
<script type="math/tex; mode=display">u_{t}(x)=\int u_{t}\left(x | x_{1}\right) \frac{p_{t}\left(x | x_{1}\right) q\left(x_{1}\right)}{p_{t}(x)} d x_{1} \tag{8}</script><p>其中，$u_t(\cdot|x_1): \mathbb{R}^d \to \mathbb{R}^d$是生成$p_t(\cdot|x_1)$的条件向量场。可能不太明显，但这种聚合条件向量场的方式实际上得到了用于对边缘概率路径进行建模的正确向量场。</p>
<p><strong>我们的第一个关键发现是：边缘向量场（公式8）生成边缘概率路径（公式6）。</strong></p>
<p>这在条件向量场（生成条件概率路径的向量场）和边缘向量场（生成边缘概率路径的向量场）之间建立了一种令人惊讶的联系。这种联系使我们能够将未知且难以处理的边缘向量场分解为更简单的条件向量场，这些条件向量场只依赖于单个数据样本，定义起来要简单得多。我们在以下定理中对此进行形式化。</p>
<p><strong>定理1</strong>：给定生成条件概率路径$p_t(x|x_1)$的向量场$u_t(x|x_1)$，对于任何分布$q(x_1)$，公式8中的边缘向量场$u_t$生成公式6中的边缘概率路径$p_t$，即$u_t$和$p_t$满足连续性方程（公式26）。</p>
<p>我们所有定理的完整证明都在附录A中。定理1也可以从Peluchetti（2021）中的扩散混合表示定理推导得出，该定理为扩散随机微分方程中的边缘漂移和扩散系数提供了一个公式。</p>
<h4 id="3-2-条件流匹配"><a href="#3-2-条件流匹配" class="headerlink" title="3.2 条件流匹配"></a>3.2 条件流匹配</h4><p>遗憾的是，由于边缘概率路径和向量场的定义（公式6和公式8）中存在难以处理的积分，计算$u_t$仍然很困难，因此，直接计算原始流匹配目标的无偏估计量也很困难。相反，我们提出了一个更简单的目标，令人惊讶的是，它将得到与原始目标相同的最优解。具体来说，我们考虑条件流匹配（CFM）目标：</p>
<script type="math/tex; mode=display">\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t, q\left(x_{1}\right), p_{t}\left(x | x_{1}\right)}\left\| v_{t}(x)-u_{t}\left(x | x_{1}\right)\right\| ^{2} \tag{9}</script><p>其中，$t \sim U[0, 1]$，$x_1 \sim q(x_1)$，并且$x \sim p_t(x|x_1)$。与FM目标不同，CFM目标只要我们能够从$p_t(x|x_1)$中有效采样并计算$u_t(x|x_1)$，就可以轻松采样得到无偏估计，而这两者都很容易做到，因为它们是在每个样本的基础上定义的。</p>
<p><strong>因此，我们的第二个关键发现是：FM（公式5）和CFM（公式9）目标关于$\theta$的梯度相同。</strong></p>
<p>也就是说，优化CFM目标（在期望上）等同于优化FM目标。因此，这使我们能够训练一个CNF来生成边缘概率路径$p_t$（特别地，在$t = 1$时，$p_t$近似未知数据分布$q$），而无需访问边缘概率路径或边缘向量场。我们只需要设计合适的条件概率路径和向量场。我们在以下定理中对这一性质进行形式化。</p>
<p><strong>定理2</strong>：假设对于所有$x \in \mathbb{R}^d$和$t \in [0, 1]$，$p_t(x) &gt; 0$，那么，除了一个与$\theta$无关的常数外，$L_{CFM}$和$L_{FM}$相等。因此，$\nabla_{\theta} L_{FM}(\theta)=\nabla_{\theta} L_{CFM}(\theta)$</p>
<h3 id="4-条件概率路径和向量场"><a href="#4-条件概率路径和向量场" class="headerlink" title="4 条件概率路径和向量场"></a>4 条件概率路径和向量场</h3><p>条件流匹配目标适用于任何条件概率路径和条件向量场的选择。在本节中，我们将讨论一类通用的高斯条件概率路径的$p_t(x|x_1)$和$u_t(x|x_1)$的构建。具体而言，我们考虑形式如下的条件概率路径：</p>
<script type="math/tex; mode=display">p_t(x|x_1) = \mathcal{N}(x|\mu_t(x_1), \sigma_t(x_1)^2I) \tag{10}</script><p>其中，$\mu: [0, 1] \times \mathbb{R}^d \to \mathbb{R}^d$是高斯分布随时间变化的均值，而$\sigma: [0, 1] \times \mathbb{R} \to \mathbb{R}_{&gt;0}$描述了随时间变化的标量标准差。我们设定$\mu_0(x_1) = 0$且$\sigma_0(x_1) = 1$，这样所有条件概率路径在$t = 0$时都收敛到相同的标准高斯噪声分布$p(x) = N(x|0, I)$。然后我们设定$\mu_1(x_1) = x_1$且$\sigma_1(x_1) = \sigma_{min}$，$\sigma_{min}$被设置得足够小，使得$p_1(x|x_1)$是一个以$x_1$为中心的集中高斯分布。</p>
<p>对于任何特定的概率路径，都存在无数个向量场可以生成它（例如，通过在连续性方程中添加一个散度为零的分量，见公式26），但其中绝大多数是由于存在使基础分布保持不变的分量，例如当分布具有旋转不变性时的旋转分量，这会导致不必要的额外计算。我们决定使用与高斯分布的规范变换相对应的最简单向量场。具体来说，考虑（基于$x_1$的）变换：</p>
<script type="math/tex; mode=display">\psi_t(x) = \sigma_t(x_1)x + \mu_t(x_1) \tag{11}</script><p>当$x$服从标准高斯分布时，$\psi_t(x)$是一个仿射变换，它将$x$映射到一个均值为$\mu_t(x_1)$、标准差为$\sigma_t(x_1)$的正态分布随机变量。也就是说，根据公式4，$\psi_t$将噪声分布$p_0(x|x_1) = p(x)$推前到$p_t(x|x_1)$，即：</p>
<script type="math/tex; mode=display">[\psi_t]_*p(x) = p_t(x|x_1) \tag{12}</script><p>这个流进而提供了一个生成条件概率路径的向量场：</p>
<script type="math/tex; mode=display">\frac{d}{dt}\psi_t(x) = u_t(\psi_t(x)|x_1) \tag{13}</script><p>用$x_0$重新参数化$p_t(x|x_1)$，并将公式13代入CFM损失中，我们得到：</p>
<script type="math/tex; mode=display">\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t, q\left(x_{1}\right), p\left(x_{0}\right)}\left\| v_{t}\left(\psi_{t}\left(x_{0}\right)\right)-\frac{d}{d t} \psi_{t}\left(x_{0}\right)\right\| ^{2} \tag{14}</script><p>由于$\psi_t$是一个简单的（可逆）仿射映射，我们可以使用公式13以封闭形式求解$u_t$。对于一个随时间变化的函数$f$，令$f’$表示其对时间的导数，即$f’=\frac{d}{dt}f$。<br><strong>定理3</strong>：设$p_t(x|x_1)$是如公式10所示的高斯概率路径，$\psi_t$是其如公式11所示的相应流映射。那么，定义$\psi_t$的唯一向量场具有以下形式：</p>
<script type="math/tex; mode=display">u_{t}\left(x | x_{1}\right)=\frac{\sigma_{t}'\left(x_{1}\right)}{\sigma_{t}\left(x_{1}\right)}\left(x-\mu_{t}\left(x_{1}\right)\right)+\mu_{t}'\left(x_{1}\right) \tag{15}</script><p>因此，$u_t(x|x_1)$生成了高斯路径$p_t(x|x_1)$。</p>
<h4 id="4-1-高斯条件概率路径的特殊实例"><a href="#4-1-高斯条件概率路径的特殊实例" class="headerlink" title="4.1 高斯条件概率路径的特殊实例"></a>4.1 高斯条件概率路径的特殊实例</h4><p>我们的公式对于任意函数$\mu_t(x_1)$和$\sigma_t(x_1)$都是完全通用的，并且我们可以将它们设置为满足所需边界条件的任何可微函数。我们首先讨论那些能够恢复与先前使用的扩散过程相对应的概率路径的特殊情况。由于我们直接处理概率路径，因此可以完全抛开对扩散过程的推理。因此，在下面的第二个例子中，我们直接基于Wasserstein - 2最优传输解来构建概率路径，这是一个有趣的实例。</p>
<p><strong>示例一：扩散条件向量场</strong>。扩散模型从数据点开始，逐渐添加噪声，直到它近似于纯噪声。这些可以被表述为随机过程，为了在任意时刻$t$获得封闭形式的表示，需要满足严格的条件，这导致了具有特定均值$\mu_t(x_1)$和标准差$\sigma_t(x_1)$选择的高斯条件概率路径$p_t(x|x_1)$（Sohl - Dickstein等人，2015；Ho等人，2020；Song等人，2020b）。例如，反向（从噪声到数据）方差爆炸（VE）路径具有以下形式：</p>
<script type="math/tex; mode=display">p_{t}(x)=\mathcal{N}\left(x | x_{1}, \sigma_{1 - t}^{2}I\right)  \tag{16}</script><p>其中，$\sigma_t$是一个递增函数，$\sigma_0 = 0$，且$\sigma_1 \gg 1$。根据公式16，我们得到$\mu_t(x_1) = x_1$和$\sigma_t(x_1) = \sigma_{1 - t}$。将这些代入定理3的公式15中，我们得到：</p>
<script type="math/tex; mode=display">u_{t}\left(x | x_{1}\right)=-\frac{\sigma_{1 - t}'}{\sigma_{1 - t}}\left(x - x_{1}\right) \tag{17}</script><p>反向（从噪声到数据）方差保持（VP）扩散路径具有以下形式：</p>
<script type="math/tex; mode=display">p_{t}\left(x | x_{1}\right)=\mathcal{N}\left(x | \alpha_{1 - t}x_{1},(1 - \alpha_{1 - t}^{2})I\right) \tag{18}</script><p>其中$\alpha_{t}=e^{-\frac{1}{2}T(t)}$，$T(t)=\int_{0}^{t} \beta(s)ds$，$\beta$是噪声尺度函数。根据公式18，我们得到$\mu_t(x_1) = \alpha_{1 - t}x_1$和$\sigma_t(x_1)=\sqrt{1 - \alpha_{1 - t}^{2}}$。将这些代入定理3的公式15中，我们得到：</p>
<script type="math/tex; mode=display">u_{t}\left(x | x_{1}\right)=\frac{\alpha_{1 - t}'}{1 - \alpha_{1 - t}^{2}}\left(\alpha_{1 - t}x - x_{1}\right)=-\frac{T'(1 - t)}{2}\left[\frac{e^{-T(1 - t)}x - e^{-\frac{1}{2}T(1 - t)}x_{1}}{1 - e^{-T(1 - t)}}\right] \tag{19}</script><p>当限制在这些条件扩散过程时，我们构建的条件向量场$u_t(x|x_1)$实际上与之前在确定性概率流中使用的向量场（Song等人，2020b，公式13）一致；详见附录D。尽管如此，将扩散条件向量场与流匹配目标相结合，为现有的得分匹配方法提供了一种有吸引力的训练替代方案，在我们的实验中，我们发现这种方法更稳定、更强大。</p>
<p>另一个重要的观察结果是，由于这些概率路径以前是作为扩散过程的解推导出来的，它们实际上在有限时间内并不能达到真正的噪声分布。在实践中，$p_0(x)$只是通过一个合适的高斯分布来近似，以进行采样和似然评估。相反，我们的构建方法可以完全控制概率路径，我们可以直接设置$\mu_t$和$\sigma_t$，就像我们接下来要做的那样。</p>
<p><strong>示例二：最优传输条件向量场</strong>。一种更自然的条件概率路径选择是将均值和标准差定义为随时间线性变化，即：</p>
<script type="math/tex; mode=display">\mu_{t}(x)=tx_{1}，\sigma_{t}(x)=1 - (1 - \sigma_{min})t \tag{20}</script><p>根据定理3，这条路径由向量场生成：</p>
<script type="math/tex; mode=display">u_{t}\left(x | x_{1}\right)=\frac{x_{1}-(1 - \sigma_{min})x}{1 - (1 - \sigma_{min})t} \tag{21}</script><p>与扩散条件向量场（公式19）相比，它在所有$t \in [0, 1]$上都有定义。与$u_t(x|x_1)$对应的条件流为：</p>
<script type="math/tex; mode=display">\psi_{t}(x)=(1 - (1 - \sigma_{min})t)x + tx_{1} \tag{22}</script><p>在这种情况下，CFM损失（见公式9、14）的形式为：</p>
<script type="math/tex; mode=display">\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t, q\left(x_{1}\right), p\left(x_{0}\right)}\left\| v_{t}\left(\psi_{t}\left(x_{0}\right)\right)-\left(x_{1}-(1 - \sigma_{min})x_{0}\right)\right\| ^{2} \tag{23}</script><p>允许均值和标准差线性变化不仅会产生简单直观的路径，而且实际上在以下意义上也是最优的。条件流$\psi_t(x)$实际上是两个高斯分布$p_0(x|x_1)$和$p_1(x|x_1)$之间的最优传输（OT）位移映射。OT插值（一种概率路径）定义为（见McCann，1997中的定义1.1）：</p>
<script type="math/tex; mode=display">p_{t}=[(1 - t)\text{id}+t\psi]_*p_{0} \tag{24}</script><p>其中$\psi: \mathbb{R}^d \to \mathbb{R}^d$是将$p_0$推前到$p_1$的OT映射，$\text{id}$表示恒等映射，即$\text{id}(x) = x$，$(1 - t)\text{id}+t\psi$被称为OT位移映射。McCann（1997）中的示例1.7表明，在我们的两个高斯分布的情况下，其中第一个是标准高斯分布，OT位移映射具有公式22的形式。</p>
<p>直观地说，在OT位移映射下，粒子总是沿直线轨迹以恒定速度移动。图3描绘了扩散和OT条件向量场的采样路径。有趣的是，我们发现从扩散路径采样的轨迹可能会“超过”最终样本，导致不必要的回溯，而OT路径则保证保持直线。图2比较了扩散条件得分函数（典型扩散方法中的回归目标），即$\nabla \log p_t(x|x_1)$（其中$p_t$如公式18所定义）与OT条件向量场（公式21）。在两个示例中，起始（$p_0$）和结束（$p_1$）的高斯分布是相同的。一个有趣的观察结果是，OT向量场在时间上具有恒定的方向，这可以说导致了一个更简单的回归任务。从公式21也可以直接验证这一性质，因为该向量场可以写成$u_t(x|x_1) = g(t)h(x|x_1)$的形式。附录中的图8展示了扩散向量场的可视化。最后，我们注意到，虽然条件流是最优的，但这绝不是说边缘向量场是最优传输解。尽管如此，我们预计边缘向量场仍然相对简单。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f2.png" width="70%" height="70%"></th>
<th style="text-align:center"><img src="f3.png" width="100%" height="100%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图2：与扩散路径的条件得分函数相比，最优传输（OT）路径的条件向量场在时间上具有恒定的方向，并且可以说更容易用参数模型进行拟合。请注意，蓝色表示幅度较大，而红色表示幅度较小。</em></td>
<td style="text-align:center"><em>图3：扩散和最优传输（OT）轨迹。扩散轨迹可能会“超调”最终样本，导致不必要的回溯，而OT轨迹始终保持直线。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5 相关工作"></a>5 相关工作</h3><p>连续归一化流（Continuous Normalizing Flows，CNFs）由Chen等人于2018年提出，是归一化流（Normalizing Flows）的连续时间版本（相关综述可参考Kobyzev等人，2020；Papamakarios等人，2021）。最初，CNFs是通过最大似然目标进行训练的，但这需要对正向和反向传播进行代价高昂的ODE模拟。由于ODE模拟的顺序性，导致时间复杂度较高。尽管一些研究展示了CNF生成模型在图像合成方面的能力（Grathwohl等人，2018），但要扩展到高维图像本质上仍然困难。许多研究试图对ODE进行正则化以使其更易于求解，例如使用增强技术（Dupont等人，2019）、添加正则化项（Yang和Karniadakis，2019；Finlay等人，2020；Onken等人，2021；Tong等人，2020；Kelly等人，2020），或者对积分区间进行随机采样（Du等人，2022）。这些研究仅仅旨在对ODE进行正则化，并没有改变基本的训练算法。</p>
<p>为了加速CNF训练，一些研究通过显式设计目标概率路径和动力学，开发了无需模拟的CNF训练框架。例如，Rozen等人（2021）考虑了先验和目标密度之间的线性插值，但涉及到在高维中难以估计的积分。Ben - Hamu等人（2022）考虑了与本研究类似的通用概率路径，但在随机小批量训练中存在梯度偏差问题。相比之下，流匹配框架允许进行无偏梯度的无模拟训练，并且可以轻松扩展到高维。</p>
<p>另一种无模拟训练方法依赖于构建扩散过程来间接定义目标概率路径（Sohl - Dickstein等人，2015；Ho等人，2020；Song和Ermon，2019）。Song等人（2020b）表明，扩散模型可以通过去噪得分匹配（Vincent，2011）进行训练，这是一种条件目标，能够为得分匹配目标提供无偏梯度。条件流匹配从该结果中获得启发，但将其推广到直接匹配向量场。由于易于扩展，扩散模型受到了越来越多的关注，并产生了多种改进方法，如损失重缩放（Song等人，2021）、添加分类器指导以及架构改进（Dhariwal和Nichol，2021），还有学习噪声调度（Nichol和Dhariwal，2021；Kingma等人，2021）。然而，Nichol和Dhariwal（2021）以及Kingma等人（2021）仅考虑了由简单扩散过程定义的具有单个参数的受限高斯条件路径设置，特别地，其中不包括我们的条件OT路径。在另一系列研究中，De Bortoli等人（2021）、Wang等人（2021）和Peluchetti（2021）通过扩散桥理论提出了有限时间扩散构建方法，解决了无限时间去噪构建所产生的近似误差问题。虽然现有研究利用了扩散过程和具有相同概率路径的连续归一化流之间的联系（Maoutsa等人，2020b；Song等人，2020b；2021），但我们的工作使我们能够超越简单扩散所建模的概率路径类别。通过我们的工作，可以完全避开扩散过程的构建，直接对概率路径进行推理，同时仍然保持高效的训练和对数似然评估。最后，与我们的工作同期，Liu等人（2022）和Albergo与Vanden - Eijnden（2022）得出了类似的用于CNFs无模拟训练的条件目标，而Neklyudov等人（2023）在假设$u_t$为梯度场的情况下推导出了一个隐式目标。</p>
<h3 id="6-实验"><a href="#6-实验" class="headerlink" title="6 实验"></a>6 实验</h3><p>我们在CIFAR10（Krizhevsky等人，2009）以及分辨率为32、64和128的ImageNet（Chrabaszcz等人，2017；Deng等人，2009）图像数据集上探究使用流匹配的实证优势。我们还对比了流匹配中不同扩散路径的选择，特别是标准方差保持扩散路径和最优传输路径。我们讨论了通过直接参数化生成向量场并使用流匹配目标，样本生成是如何得到改进的。最后，我们展示了流匹配也可用于条件生成场景。除非另有说明，我们使用dopri5（Dormand和Prince，1980）在绝对和相对容差为1e - 5的情况下评估模型的似然性和样本。生成的样本见附录，所有实现细节见附录E。</p>
<h4 id="6-1-ImageNet上的密度建模和样本质量"><a href="#6-1-ImageNet上的密度建模和样本质量" class="headerlink" title="6.1 ImageNet上的密度建模和样本质量"></a>6.1 ImageNet上的密度建模和样本质量</h4><p>我们首先比较相同的模型架构（即来自Dhariwal和Nichol，2021的U - Net架构，仅做了微小改动）在CIFAR - 10和不同分辨率（32×32、64×64）的ImageNet上，使用不同流行的基于扩散的损失函数进行训练的情况：来自Ho等人（2020）的DDPM、得分匹配（SM，Song等人，2020b）和得分流（SF，Song等人，2021）。具体细节见附录E.1。表1（左）总结了我们的结果以及这些基线方法，报告了以每维比特数（BPD）为单位的负对数似然（NLL）、通过弗雷歇初始距离（FID，Heusel等人，2017）衡量的样本质量，以及自适应求解器达到预定数值容差所需的平均函数评估次数（NFE），对50,000个样本求平均。所有模型都使用相同的架构、超参数值和训练迭代次数进行训练，为了更好地收敛，基线方法允许更多的迭代次数。请注意，这些都是无条件模型。在CIFAR - 10和ImageNet上，与竞争方法相比，基于最优传输的流匹配（FM - OT）在所有定量指标上始终获得最佳结果。我们注意到，与之前的工作（Ho等人，2020；Song等人，2020b；2021）相比，我们在CIFAR - 10上的FID性能更高，这可能是因为我们使用的架构并非针对CIFAR - 10进行优化。其次，表1（右）比较了在分辨率为128×128的ImageNet上使用基于最优传输路径的流匹配训练的模型。除了使用自监督ResNet50模型进行条件设定的IC - GAN（Casanova等人，2021）外，我们的FID达到了当前最优水平，因此IC - GAN未列入此表。附录中的图11、12、13展示了这些模型生成的未经筛选的样本。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t1.png" width="100%" height="100%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表1：使用不同方法训练的同一模型的似然性（以比特每维度，即BPD为单位）、生成样本的质量（以弗雷歇初始距离，即FID衡量）以及评估时间（以函数评估次数，即NFE表示）。</em></td>
</tr>
</tbody>
</table>
</div>
<p><strong>更快的训练速度</strong>：虽然现有工作在训练扩散模型时需要大量的迭代次数（例如，得分流和VDM分别报告了130万次和1000万次迭代），但我们发现流匹配通常收敛得更快。图5展示了在ImageNet 64×64上训练流匹配和所有基线模型时的FID曲线；FM - OT能够比其他方法更快地降低FID，且降幅更大。对于ImageNet - 128，Dhariwal和Nichol（2021）使用批量大小为256训练了436万次迭代，而FM（模型大小比前者大25%）使用批量大小为1500训练了50万次迭代，即图像吞吐量减少了33%；具体细节见表3。此外，在使用得分匹配训练时，模型采样的成本在训练过程中可能会大幅变化，而使用流匹配训练时，采样成本保持恒定（见附录图10）。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f5.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图5：ImageNet 64×64图像训练过程中的图像质量变化。图中展示了流匹配（Flow Matching）和所有基线模型在训练过程中的FID曲线。基于最优传输的流匹配（FM - OT）能够比其他方法更快地降低FID，且降幅更大。</em></td>
</tr>
</tbody>
</table>
</div>
<h4 id="6-2-采样效率"><a href="#6-2-采样效率" class="headerlink" title="6.2 采样效率"></a>6.2 采样效率</h4><p>在采样时，我们首先从标准正态分布$x_0 \sim N(0, I)$中随机抽取一个噪声样本，然后使用训练好的向量场$v_t$，在区间$t \in [0, 1]$上通过求解方程1，利用ODE求解器计算$\phi_1(x_0)$。虽然扩散模型也可以通过随机微分方程（SDE）进行采样，但这可能效率极低，许多提出快速采样器的方法（例如Song等人，2020a；Zhang和Chen，2022）直接采用ODE视角（见附录D）。部分原因是ODE求解器效率更高，在相似计算成本下误差更低（Kloeden等人，2012），并且有多种可用的ODE求解器方案。与我们的对比模型相比，我们发现使用基于最优传输路径的流匹配训练的模型，无论使用何种ODE求解器，总是能得到最高效的采样器，具体如下。<br><strong>采样路径</strong>：我们首先定性地可视化扩散路径和OT路径在采样路径上的差异。图6展示了使用相同随机种子，从ImageNet - 64模型生成的样本，我们发现基于OT路径的模型比基于扩散路径的模型更早开始生成图像，在扩散路径模型中，直到最后一个时间点图像中都主要是噪声。我们还在生成棋盘图案的2D实验中描绘了概率密度路径（图4左），也观察到了类似的趋势。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f6.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图6：使用在ImageNet 64×64上训练的模型，从相同初始噪声生成的采样路径。OT路径大致呈线性地降低噪声，而扩散路径明显仅在路径接近结束时才去除噪声。同时注意生成图像之间的差异。</em></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f4.png" width="70%" height="70%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图4：（左）在二维棋盘数据上使用不同目标训练的连续归一化流（CNF）的轨迹。最优传输（OT）路径能更早地呈现出棋盘图案，而流匹配（FM）则使训练更加稳定。（右）使用OT路径的流匹配在采用中点法求解时，采样效率更高。</em></td>
</tr>
</tbody>
</table>
</div>
<p><strong>低成本样本</strong>：接下来，我们切换到固定步长求解器，并比较表1中ImageNet - 32模型计算的低NFE（≤100）样本。在图7（左）中，我们比较了低NFE解与1000 NFE解的每像素均方误差（MSE）（我们使用256个随机噪声种子），发现基于最优传输的FM模型在计算成本方面产生的数值误差最小，达到与扩散模型相同误差阈值所需的NFE大约仅为扩散模型的60%。其次，图7（右）展示了FID随计算成本的变化，我们发现基于最优传输的FM模型即使在非常低的NFE值下也能实现不错的FID，与对比模型相比，在样本质量和成本之间实现了更好的平衡。图4（右）展示了2D棋盘实验中的低成本采样效果。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f7.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图7：流匹配，尤其是在使用最优传输（OT）路径时，能让我们在保持相似数值误差（左图）和样本质量（右图）的情况下，减少采样所需的评估次数。图中展示的是在ImageNet 32×32上训练的模型的结果，数值误差是基于中点法计算的。</em></td>
</tr>
</tbody>
</table>
</div>
<h4 id="6-3-低分辨率图像的条件采样"><a href="#6-3-低分辨率图像的条件采样" class="headerlink" title="6.3 低分辨率图像的条件采样"></a>6.3 低分辨率图像的条件采样</h4><p>最后，我们对流匹配在条件图像生成方面进行了实验，特别是将图像从64×64上采样到256×256。我们遵循Saharia等人（2022）中的评估流程，计算上采样后的验证图像的FID；基线方法包括参考值（原始验证集的FID）和回归方法。结果见表2。附录中的图14、15展示了上采样后的图像样本。基于最优传输的FM（FM - OT）在峰值信噪比（PSNR）和结构相似性指数测量（SSIM）值上与Saharia等人（2022）的方法相近，同时在FID和 inception分数（IS）上有显著提升，正如Saharia等人（2022）所指出的，FID和IS能更好地反映生成质量。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t2.png" width="70%" height="70%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表2：ImageNet验证集上的图像超分辨率结果。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7 结论"></a>7 结论</h3><p>我们引入了流匹配（Flow Matching），这是一种全新的、无需模拟的训练连续归一化流模型的框架。该框架借助条件构建方式，可轻松扩展到极高维度。此外，流匹配框架为扩散模型提供了新的视角，建议放弃随机/扩散构建方式，转而更直接地指定概率路径。这使我们能够构建出例如可实现更快采样和（或）提升生成效果的路径。我们通过实验展示了使用流匹配框架进行训练和采样的便捷性。未来，我们期望流匹配能够开启使用多种概率路径的大门（例如非各向同性高斯分布路径，甚至是更通用的内核路径）。</p>
<h3 id="8-社会责任"><a href="#8-社会责任" class="headerlink" title="8 社会责任"></a>8 社会责任</h3><p>除了诸多积极应用外，图像生成技术也可能被用于不良目的。使用经过内容管控的训练集，以及进行图像验证和分类，有助于减少此类不良应用。此外，训练大型深度学习模型的能源需求正迅速增长（Amodei等人，2018；Thompson等人，2020）。关注那些能够通过更少的梯度更新或图像吞吐量完成训练的方法，有助于大幅节省时间和能源。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/09/Improved-Denoising-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/09/Improved-Denoising-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Improved Denoising Diffusion Probabilistic Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-09 10:51:35" itemprop="dateCreated datePublished" datetime="2025-03-09T10:51:35+08:00">2025-03-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-11 20:48:26" itemprop="dateModified" datetime="2025-03-11T20:48:26+08:00">2025-03-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>去噪扩散概率模型（DDPM）是一类生成模型，最近研究表明，这类模型能够生成高质量样本。研究发现，通过一些简单的修改，DDPM在保持高样本质量的同时，还能获得具有竞争力的对数似然值。此外，研究人员还发现，对反向扩散过程的方差进行学习，可以在样本质量差异可忽略不计的情况下，将前向传递次数减少一个数量级，这对这些模型的实际应用至关重要。此外，研究人员使用精度和召回率来比较DDPM和生成对抗网络（GAN）对目标分布的覆盖程度。最后，研究表明，这些模型的样本质量和对数似然值会随着模型容量和训练计算量的增加而平稳提升，这使得它们易于扩展。研究人员已将代码发布在<a target="_blank" rel="noopener" href="https://github.com/openai/improved-diffusion">https://github.com/openai/improved-diffusion</a> 。</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h3><p>Sohl - Dickstein等人（2015年）提出了扩散概率模型，这是一类生成模型，通过学习逆转一个渐进的、多步的加噪过程来匹配数据分布。最近，Ho等人（2020年）揭示了去噪扩散概率模型（DDPM）和基于分数的生成模型（Song &amp; Ermon，2019年；2020年）之间的等价性，后者使用去噪分数匹配（Hyvärinen，2005年）来学习数据分布的对数密度梯度。最近的研究表明，这类模型能够生成高质量的图像（Ho等人，2020年；Song &amp; Ermon，2020年；Jolicoeur - Martineau等人，2020年）和音频（Chen等人，2020b；Kong等人，2020年），但DDPM能否在对数似然值上与其他基于似然的模型（如自回归模型（van den Oord等人，2016c）和变分自编码器（Kingma &amp; Welling，2013年））相媲美，尚未得到验证。这就引发了诸多问题，比如DDPM是否能够捕捉到分布的所有模式。此外，尽管Ho等人（2020年）在CIFAR - 10（Krizhevsky，2009年）和LSUN（Yu等人，2015年）数据集上取得了极为出色的成果，但DDPM在像ImageNet这样多样性更高的数据集上的扩展性如何，仍不明确。最后，虽然Chen等人（2020b）发现DDPM可以通过少量采样步骤高效地生成音频，但在图像生成方面是否同样如此，还有待证明。</p>
<p>在本文中，研究人员证明了DDPM在对数似然值上能够与其他基于似然的模型竞争，即使在像ImageNet这样多样性高的数据集上也是如此。为了更严格地优化变分下界（VLB），研究人员使用了一种简单的重参数化方法和一个混合学习目标（将VLB与Ho等人（2020年）提出的简化目标相结合）来学习反向过程的方差。</p>
<p>研究人员惊讶地发现，使用混合目标时，模型获得的对数似然值比直接优化对数似然得到的结果更好，并且发现直接优化对数似然的目标在训练过程中存在更多的梯度噪声。研究表明，一种简单的重要性采样技术可以减少这种噪声，使模型获得比使用混合目标时更好的对数似然值。</p>
<p>在将学习到的方差纳入模型后，研究人员意外地发现，可以用更少的步骤进行采样，且样本质量几乎没有变化。虽然Ho等人（2020年）的DDPM需要数百次前向传递才能生成高质量样本，但研究人员只需50次前向传递就能达到类似效果，从而加快了实际应用中的采样速度。在研究人员开展工作的同时，Song等人（2020a）开发了一种不同的快速采样方法，研究人员在实验中将其与该方法（DDIM）进行了比较。</p>
<p>虽然对数似然是与其他基于似然的模型进行比较的良好指标，但研究人员也希望将这些模型与GAN的分布覆盖范围进行对比。研究人员使用改进的精度和召回率指标（Kynkäänniemi等人，2019年），发现扩散模型在相似的FID下具有更高的召回率，这表明它们确实覆盖了目标分布的更大比例。最后，由于预计未来机器学习模型将消耗更多的计算资源，研究人员评估了随着模型规模和训练计算量增加，这些模型的性能变化。与（Henighan等人，2020年）类似，研究人员观察到，随着训练计算量的增加，模型性能呈现出可预测的提升趋势。</p>
<h3 id="2-去噪扩散概率模型"><a href="#2-去噪扩散概率模型" class="headerlink" title="2. 去噪扩散概率模型"></a>2. 去噪扩散概率模型</h3><p>研究人员简要回顾Ho等人（2020）提出的去噪扩散概率模型（DDPM）的公式。该公式做了各种简化假设，例如固定的加噪过程 $q$，它在每个时间步添加对角高斯噪声。更一般的推导过程，可参见Sohl - Dickstein等人（2015）的研究。</p>
<h4 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h4><p>给定数据分布 $x_{0} \sim q(x_{0})$，研究人员定义前向加噪过程 $q$，该过程通过在时间 $t$ 添加方差为 $\beta_{t} \in(0,1)$ 的高斯噪声，生成潜在变量 $x_{1}$ 到 $x_{T}$，具体如下：</p>
<script type="math/tex; mode=display">q\left(x_{1}, \ldots, x_{T} | x_{0}\right):=\prod_{t = 1}^{T} q\left(x_{t} | x_{t - 1}\right) \tag{1}</script><script type="math/tex; mode=display">q\left(x_{t} | x_{t - 1}\right):=\mathcal{N}\left(x_{t} ; \sqrt{1 - \beta_{t}} x_{t - 1}, \beta_{t} I\right) \tag{2}</script><p>在 $T$ 足够大且 $\beta_{t}$ 满足特定条件的情况下，潜在变量 $x_{T}$ 近似为各向同性高斯分布。因此，如果知道精确的反向分布 $q(x_{t - 1} | x_{t})$，就可以从 $x_{T} \sim N(0, I)$ 中采样，并反向运行该过程，从而从 $q(x_{0})$ 中获得样本。然而，由于 $q(x_{t - 1} | x_{t})$ 依赖于整个数据分布，因此研究人员使用神经网络对其进行近似：</p>
<script type="math/tex; mode=display">p_{\theta}\left(x_{t - 1} | x_{t}\right):=\mathcal{N}\left(x_{t - 1} ; \mu_{\theta}\left(x_{t}, t\right), \sum_{\theta}\left(x_{t}, t\right)\right) \tag{3}</script><p>$q$ 和 $p$ 的组合是一个变分自编码器（Kingma &amp; Welling，2013），变分下界（VLB）可以写为：</p>
<script type="math/tex; mode=display">L_{vlb}:=L_{0}+L_{1}+\cdots+L_{T - 1}+L_{T} \tag{4}</script><script type="math/tex; mode=display">L_{0}:=-\log p_{\theta}\left(x_{0} | x_{1}\right) \tag{5}</script><script type="math/tex; mode=display">L_{t - 1}:=D_{KL}\left(q\left(x_{t - 1} | x_{t}, x_{0}\right) \| p_{\theta}\left(x_{t - 1} | x_{t}\right)\right) \tag{6}</script><script type="math/tex; mode=display">L_{T}:=D_{KL}\left(q\left(x_{T} | x_{0}\right) \| p\left(x_{T}\right)\right) \tag{7}</script><p>除了 $L_{0}$ 之外，公式（4）中的每一项都是两个高斯分布之间的KL散度，因此可以通过解析形式进行计算。在评估图像的 $L_{0}$ 时，研究人员假设每个颜色分量被划分为256个区间，并计算 $p_{\theta}(x_{0} | x_{1})$ 落在正确区间的概率（利用高斯分布的累积分布函数可以计算该概率）。还需注意的是，虽然 $L_{T}$ 不依赖于 $\theta$，但如果前向加噪过程充分破坏了数据分布，使得 $q(x_{T} | x_{0}) \approx N(0, I)$，那么 $L_{T}$ 将接近0。</p>
<p>正如Ho等人（2020）所指出的，公式（2）中定义的加噪过程使得研究人员可以直接在输入 $x_{0}$ 的条件下，对加噪后的潜在变量的任意步骤进行采样。令 $\alpha_{t}:=1 - \beta_{t}$ 且 $\bar{\alpha}_{t}:=\prod_{s = 0}^{t} \alpha_{s}$，可以写出边缘分布：</p>
<script type="math/tex; mode=display">q\left(x_{t} | x_{0}\right)=\mathcal{N}\left(x_{t} ; \sqrt{\overline{\alpha}_{t}} x_{0},\left(1 - \overline{\alpha}_{t}\right) I\right) \tag{8}</script><script type="math/tex; mode=display">x_{t}=\sqrt{\overline{\alpha}_{t}} x_{0}+\sqrt{1 - \overline{\alpha}_{t}} \epsilon \tag{9}</script><p>其中 $\epsilon \sim N(0, I)$。这里，$1 - \bar{\alpha}_{t}$ 表示任意时间步的噪声方差，也可以用它来定义噪声调度，而不使用 $\beta_{t}$。</p>
<p>利用贝叶斯定理，可以根据 $\tilde{\beta}_{t}$ 和 $\tilde{\mu}_{t}(x_{t}, x_{0})$ 计算后验概率 $q(x_{t - 1} | x_{t}, x_{0})$，其定义如下：</p>
<script type="math/tex; mode=display">\tilde{\beta}_{t}:=\frac{1 - \overline{\alpha}_{t - 1}}{1 - \overline{\alpha}_{t}} \beta_{t} \tag{10}</script><script type="math/tex; mode=display">\tilde{\mu}_{t}\left(x_{t}, x_{0}\right):=\frac{\sqrt{\overline{\alpha}_{t - 1}} \beta_{t}}{1 - \overline{\alpha}_{t}} x_{0}+\frac{\sqrt{\alpha_{t}}\left(1 - \overline{\alpha}_{t - 1}\right)}{1 - \overline{\alpha}_{t}} x_{t} \tag{11}</script><script type="math/tex; mode=display">q\left(x_{t - 1} | x_{t}, x_{0}\right)=\mathcal{N}\left(x_{t - 1} ; \tilde{\mu}\left(x_{t}, x_{0}\right), \tilde{\beta}_{t} I\right) \tag{12}</script><h4 id="2-2-实际训练"><a href="#2-2-实际训练" class="headerlink" title="2.2 实际训练"></a>2.2 实际训练</h4><p>公式（4）中的目标函数是独立项 $L_{t - 1}$ 的和，公式（9）提供了一种有效的方法，可从正向加噪过程的任意步骤进行采样，并利用后验概率（公式（12））和先验概率（公式（3））来估计 $L_{t - 1}$。因此，可以随机采样 $t$，并使用期望 $E_{t, x_{0}, \epsilon}[L_{t - 1}]$ 来估计 $L_{vlb}$。Ho等人（2020）在每个小批量中为每个图像均匀采样 $t$。</p>
<p>在定义先验概率时，有多种方法对 $\mu_{\theta}(x_{t}, t)$ 进行参数化。最直接的方法是用神经网络直接预测 $\mu_{\theta}(x_{t}, t)$ 。另外，网络也可以预测 $x_{0}$，并将该输出用于公式（11）以生成 $\mu_{\theta}(x_{t}, t)$ 。网络还可以预测噪声 $\epsilon$，并利用公式（9）和（11）推导出：</p>
<script type="math/tex; mode=display">\mu_{\theta}\left(x_{t}, t\right)=\frac{1}{\sqrt{\alpha_{t}}}\left(x_{t}-\frac{\beta_{t}}{\sqrt{1 - \overline{\alpha}_{t}}} \epsilon_{\theta}\left(x_{t}, t\right)\right) \tag{13}</script><p>Ho等人（2020）发现，预测 $\epsilon$ 的效果最佳，特别是在与加权损失函数结合使用时：</p>
<script type="math/tex; mode=display">L_{simple }=E_{t, x_{0}, \epsilon}\left[\left\| \epsilon-\epsilon_{\theta}\left(x_{t}, t\right)\right\| ^{2}\right] \tag{14}</script><p>这个目标函数可以看作是 $L_{vib }$ 的加权形式（不包含影响 $\sum _{\theta}$ 的项）。作者发现，优化这个加权目标函数比直接优化 $L_{vlb}$ 能得到更好的样本质量，并通过与生成分数匹配（Song &amp; Ermon，2019；2020）建立联系来解释这一现象。</p>
<p>需要注意的是，$L_{simple }$ 没有为 $\sum _{\theta}(x_{t}, t)$ 提供学习信号。不过，这并不重要，因为Ho等人（2020）通过将方差固定为 $\sigma_{t}^{2} I$ 而非学习它，取得了最佳效果。他们发现，使用 $\sigma_{t}^{2}=\beta_{t}$ 或 $\sigma_{t}^{2}=\tilde{\beta}_{t}$（分别是 $q(x_{0})$ 为各向同性高斯噪声或狄拉克函数时方差的上下界），都能获得相似的样本质量。</p>
<h3 id="3-提高对数似然"><a href="#3-提高对数似然" class="headerlink" title="3. 提高对数似然"></a>3. 提高对数似然</h3><p>虽然Ho等人（2020年）发现，去噪扩散概率模型（DDPM）根据弗雷歇 inception 距离（FID, Frechet Inception Distance，Heusel等人，2017年）和inception分数（Salimans等人，2016年）能够生成高保真样本，但他们无法在这些模型上实现具有竞争力的对数似然。对数似然是生成式建模中广泛使用的指标，人们普遍认为，优化对数似然能促使生成式模型捕捉数据分布的所有模式（Razavi等人，2019年）。此外，最近的研究（Henighan等人，2020年）表明，对数似然的微小改进就能对样本质量和学习到的特征表示产生巨大影响。因此，探究为什么DDPM在这个指标上表现不佳很重要，因为这可能暗示了一个根本性的缺陷，比如模式覆盖不足。本节将探讨对第2节中描述的算法进行的几处修改，这些修改结合起来，能使DDPM在图像数据集上实现更好的对数似然，这表明这些模型与其他基于似然的生成式模型一样具有优势。</p>
<p>为了研究不同修改的效果，我们在ImageNet 64×64（van den Oord等人，2016b）和CIFAR-10（Krizhevsky，2009）数据集上，使用固定的超参数训练固定的模型架构。虽然CIFAR-10在这类模型中应用更为广泛，但我们也选择研究ImageNet 64×64，因为它在多样性和分辨率之间提供了良好的平衡，使我们能够快速训练模型而无需担心过拟合。此外，ImageNet 64×64在生成式建模领域已有广泛研究（van den Oord等人，2016c；Menick和Kalchbrenner，2018；Child等人，2019；Roy等人，2020），这使我们能够将DDPM直接与许多其他生成式模型进行比较。+</p>
<p>Ho等人（2020年）的设置（在将$\sigma_{t}^{2}=\beta_{t}$且$T = 1000$的情况下优化$L_{simple}$ ）在ImageNet 64×64上经过20万次训练迭代后，对数似然达到3.99（比特/维度）。我们在早期实验中发现，将$T$从1000增加到4000可以提高对数似然；经过这一调整，对数似然提高到3.77。在本节的其余部分，我们使用$T = 4000$，但我们将在第4节中探讨这一选择。</p>
<h4 id="3-1-学习-sum-theta-x-t-t"><a href="#3-1-学习-sum-theta-x-t-t" class="headerlink" title="3.1 学习$\sum_{\theta}(x_{t}, t)$"></a>3.1 学习$\sum_{\theta}(x_{t}, t)$</h4><p>在Ho等人（2020年）的研究中，作者将$\sum_{\theta}(x_{t}, t) = \sigma_{t}^{2}I$ ，其中$\sigma_{t}$ 是固定值而非学习得到的。奇怪的是，他们发现将$\sigma_{t}^{2}$固定为$\beta_{t}$与固定为<script type="math/tex">\tilde{\beta}_{t}</script>时，得到的样本质量大致相同。考虑到<script type="math/tex">\beta_{t}</script>和<script type="math/tex">\tilde{\beta}_{t}</script>代表了两个极端情况，人们有理由质疑为什么这种选择不会影响样本。图1给出了线索，该图显示，除了在$t = 0$附近，<script type="math/tex">\beta_{t}</script>和<script type="math/tex">\tilde{\beta}_{t}</script>几乎相等，即在模型处理难以察觉的细节时二者存在差异。此外，随着扩散步骤的增加，<script type="math/tex">\beta_{t}</script>和<script type="math/tex">\tilde{\beta}_{t}</script>在更多的扩散过程中似乎保持接近。这表明，在扩散步骤无限多的极限情况下，<script type="math/tex">\sigma_{t}</script>的选择对样本质量可能根本没有影响。换句话说，随着扩散步骤的增加，模型均值$\mu_{\theta}(x_{t}, t)$对分布的影响比$\sum_{\theta}(x_{t}, t)$大得多。</p>
<p>虽然上述观点表明，为了保证样本质量，固定$\sigma_{t}$是一个合理的选择，但这与对数似然无关。事实上，图2显示，扩散过程的前几个步骤对变分下界的贡献最大。因此，通过更好地选择$\sum_{\theta}(x_{t}, t)$，似乎有可能提高对数似然。为了实现这一点，我们必须在学习$\sum_{\theta}(x_{t}, t)$的过程中避免出现Ho等人（2020年）遇到的不稳定性问题。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f1.png" alt="f1"></th>
<th style="text-align:center"><img src="f2.png" alt="f2"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图1. 不同长度扩散过程中每个扩散步骤的$\tilde{\beta}</em>{t}/\beta<em>{t}$比值</em></td>
<td style="text-align:center"><em>图2. 变分下界（VLB）的各项与扩散步骤的关系。前几项对负对数似然（NLL）的贡献最大。</em></td>
</tr>
</tbody>
</table>
</div>
<p>如图1所示，$\sum_{\theta}(x_{t}, t)$的合理取值范围非常小，正如Ho等人（2020年）所观察到的，即使在对数域中，神经网络也很难直接预测$\sum_{\theta}(x_{t}, t)$。相反，我们发现在对数域中将方差参数化为$\beta_{t}$和<script type="math/tex">\tilde{\beta}_{t}</script>之间的插值会更好。具体来说，我们的模型输出一个向量$v$，每个维度都有一个分量，我们将这个输出转换为方差，如下所示：</p>
<script type="math/tex; mode=display">\sum_{\theta}(x_{t}, t) = \exp(v \log\beta_{t} + (1 - v)\log\tilde{\beta}_{t}) \tag{15}</script><p>我们没有对$v$施加任何约束，理论上允许模型预测超出插值范围的方差。然而，在实践中我们并未观察到网络这样做，这表明$\sum_{\theta}(x_{t}, t)$的取值范围确实具有足够的表达能力。</p>
<p>由于$L_{simple}$不依赖于$\sum_{\theta}(x_{t}, t)$，我们定义一个新的混合目标：</p>
<script type="math/tex; mode=display">L_{hybrid} = L_{simple} + \lambda L_{vlb} \tag{16}</script><p>在我们的实验中，我们将$\lambda$设置为0.001，以防止$L_{vlb}$主导$L_{simple}$。基于同样的思路，我们还对$L_{vlb}$项中的$\mu_{\theta}(x_{t}, t)$输出应用了停止梯度操作。这样，$L_{vlb}$可以指导$\sum_{\theta}(x_{t}, t)$的学习，而$L_{simple}$仍然是影响$\mu_{\theta}(x_{t}, t)$的主要因素。</p>
<h4 id="3-2-改进噪声调度"><a href="#3-2-改进噪声调度" class="headerlink" title="3.2 改进噪声调度"></a>3.2 改进噪声调度</h4><p>我们发现，虽然Ho等人（2020年）使用的线性噪声调度在高分辨率图像上效果良好，但对于分辨率为64×64和32×32的图像来说并非最优。特别是，前向加噪过程的后期噪声过多，对样本质量的提升贡献不大。从图3中可以直观地看出这一点。图4研究了这种影响的结果，我们可以看到，使用线性调度训练的模型在跳过高达20%的反向扩散过程时，（根据FID衡量）并没有变得更差。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f3.png" alt="f3"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图3. 分别从线性（上）和余弦（下）调度在从0到T的线性间隔t值处的潜在样本。线性调度最后四分之一的潜在样本几乎全是噪声，而余弦调度添加噪声的速度更慢。</em></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f4.png" alt="f4"></th>
<th style="text-align:center"><img src="f5.png" alt="f5"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图4. 在ImageNet 64×64上跳过反向扩散过程的前缀时的FID。</em></td>
<td style="text-align:center"><em>图5. 线性调度和我们提出的余弦调度在整个扩散过程中的$\bar{\alpha}_{t}$</em></td>
</tr>
</tbody>
</table>
</div>
<p>为了解决这个问题，我们根据$\bar{\alpha}_{t}$构建了一种不同的噪声调度：</p>
<script type="math/tex; mode=display">\bar{\alpha}_{t} = \frac{f(t)}{f(0)}, \quad f(t) = \cos\left(\frac{t/T + s}{1 + s} \cdot \frac{\pi}{2}\right)^{2} \tag{17}</script><p>为了从这个定义得到方差$\beta_{t}$，我们注意到$\beta_{t} = 1 - \frac{\bar{\alpha}_{t}}{\bar{\alpha}_{t - 1}}$。在实践中，我们将$\beta_{t}$裁剪为不大于0.999，以防止在扩散过程接近$t = T$时出现奇点。</p>
<p>我们的余弦调度旨在使$\bar{\alpha}_{t}$在过程中间呈线性下降，同时在$t = 0$和$t = T$的极端情况下变化很小，以防止噪声水平突然变化。图5展示了两种调度下$\bar{\alpha}_{t}$的变化情况。我们可以看到，Ho等人（2020年）的线性调度使$\bar{\alpha}_{t}$更快地趋近于零，比必要的情况更快地破坏了信息。</p>
<p>我们使用一个小的偏移量$s$来防止$\beta_{t}$在$t = 0$附近过小，因为我们发现，在过程开始时存在少量噪声会使网络难以准确预测$\epsilon$。具体来说，我们选择$s$使得$\sqrt{\beta_{0}}$略小于像素量化区间大小1/127.5，由此得到$s = 0.008$。我们特别选择使用$\cos^{2}$函数，是因为它是一种常见的数学函数，具有我们所需的形状。这个选择具有一定的任意性，我们预计许多其他形状相似的函数也会有类似的效果。</p>
<h4 id="3-3-减少梯度噪声"><a href="#3-3-减少梯度噪声" class="headerlink" title="3.3 减少梯度噪声"></a>3.3 减少梯度噪声</h4><p>我们原本期望通过直接优化$L_{vlb}$而不是$L_{hybrid}$来实现最佳的对数似然。然而，我们惊讶地发现，在实践中$L_{vlb}$实际上很难优化，至少在多样的ImageNet 64×64数据集上是如此。图6展示了$L_{vlb}$和$L_{hybrid}$的学习曲线。两条曲线都存在波动，但在相同的训练时间内，混合目标函数在训练集上显然实现了更好的对数似然。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f6.png" alt="f6"></th>
<th style="text-align:center"><img src="f7.png" alt="f7"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图6. 在ImageNet 64×64上比较不同目标函数实现的对数似然的学习曲线</em></td>
<td style="text-align:center"><em>图7. 在ImageNet 64×64上$L_{vlb}$和$L_{hybrid}$目标函数的梯度噪声尺度</em></td>
</tr>
</tbody>
</table>
</div>
<p>我们假设$L_{vlb}$的梯度比$L_{hybrid}$的梯度噪声大得多。通过评估使用这两种目标函数训练的模型的梯度噪声尺度（McCandlish等人，2018年），我们证实了这一假设，如图7所示。因此，我们寻求一种减少$L_{vlb}$方差的方法，以便直接优化对数似然。</p>
<p>注意到$L_{vlb}$的不同项的量级差异很大（图2），我们假设均匀采样$t$会在$L_{vlb}$目标函数中引入不必要的噪声。为了解决这个问题，我们采用重要性采样：</p>
<script type="math/tex; mode=display">L_{vlb} = E_{t \sim p_{t}}\left[\frac{L_{t}}{p_{t}}\right], \quad \text{其中} \quad p_{t} \propto \sqrt{E[L_{t}^{2}]} \quad \text{且} \quad \sum p_{t} = 1 \tag{18}</script><p>由于$E[L_{t}^{2}]$在训练前是未知的，并且可能在训练过程中发生变化，我们为每个损失项保留之前10个值的历史记录，并在训练过程中动态更新。在训练开始时，我们均匀采样$t$，直到为每个$t \in [0, T - 1]$都抽取到10个样本。</p>
<p>通过这种重要性采样目标函数，我们能够通过优化$L_{vlb}$实现最佳的对数似然。在图6中，$L_{vlb}$（重采样）曲线展示了这一点。该图还显示，重要性采样目标函数的噪声明显低于原始的均匀采样目标函数。我们发现，在直接优化噪声较小的$L_{hybrid}$目标函数时，重要性采样技术并无帮助。</p>
<h4 id="3-4-结果与消融实验"><a href="#3-4-结果与消融实验" class="headerlink" title="3.4 结果与消融实验"></a>3.4 结果与消融实验</h4><p>在本节中，我们对为提高对数似然而进行的更改进行消融实验。表1总结了我们在ImageNet 64×64上的消融实验结果，表2展示了在CIFAR-10上的结果。我们还对最佳的ImageNet 64×64模型进行了150万次迭代训练，并报告了这些结果。$L_{vlb}$和$L_{hybrid}$使用3.1节中的参数化方法学习$\sigma$进行训练。对于$L_{vlb}$，我们使用了3.3节中的重采样方案。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t1.png" alt="t1"></th>
<th style="text-align:center"><img src="t2.png" alt="t2"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表1. 在ImageNet 64×64上对调度和目标函数的消融实验。</em></td>
<td style="text-align:center"><em>表2. 在CIFAR-10数据集上对噪声调度和目标函数的消融实验。</em></td>
</tr>
</tbody>
</table>
</div>
<p>基于我们的消融实验，使用$L_{hybrid}$和我们的余弦调度在提高对数似然的同时，保持与Ho等人（2020年）的基线相似的FID。优化$L_{vlb}$进一步提高了对数似然，但代价是FID更高。我们通常更倾向于使用$L_{hybrid}$而不是$L_{vlb}$，因为它在不牺牲样本质量的情况下提高了似然。</p>
<p>在表3中，我们将表现最佳的似然模型与先前研究成果进行对比，结果显示，在对数似然方面，这些模型与传统的最优方法相比颇具竞争力。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "t3.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表3. 在CIFAR-10和无条件的ImageNet 64×64数据集上，去噪扩散概率模型（DDPMs）与其他基于似然的模型的比较。负对数似然（NLL）以比特/维度为单位报告。在ImageNet 64×64数据集上，我们的模型与最好的卷积模型相比具有竞争力，但比完全基于Transformer的架构要差。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-提高采样速度"><a href="#4-提高采样速度" class="headerlink" title="4. 提高采样速度"></a>4. 提高采样速度</h3><p>我们所有的模型都经过4000步扩散训练，因此在现代GPU上生成单个样本需要花费几分钟时间。在本节中，我们探究如果减少采样时使用的步数，模型性能会如何变化，并且发现我们预训练的$L_{hybrid}$模型能够在比训练时少得多的扩散步数下生成高质量样本（无需任何微调）。以这种方式减少步数后，我们的模型能够在几秒内而非几分钟内完成采样，大大提高了图像DDPM在实际应用中的可行性。</p>
<p>对于一个经过$T$步扩散训练的模型，我们通常会使用与训练时相同的$t$值序列$(1, 2, \ldots, T)$进行采样。然而，也可以使用$t$值的任意子序列$S$进行采样。给定训练噪声调度$\bar{\alpha}_{t}$ ，对于给定的序列$S$，我们可以得到采样噪声调度$\bar{\alpha}_{S_{t}}$ ，进而得到相应的采样方差：</p>
<script type="math/tex; mode=display">\beta_{S_{t}} = 1 - \frac{\bar{\alpha}_{S_{t}}}{\bar{\alpha}_{S_{t - 1}}}, \quad \tilde{\beta}_{S_{t}} = \frac{1 - \bar{\alpha}_{S_{t - 1}}}{1 - \bar{\alpha}_{S_{t}}} \beta_{S_{t}} \tag{19}</script><p>由于$\sum_{\theta}(x_{S_{t}}, S_{t})$被参数化为$\beta_{S_{t}}$和$\tilde{\beta}_{S_{t}}$之间的一个范围，它会自动针对更短的扩散过程进行重新缩放。因此，我们可以将$p(x_{S_{t - 1}} | x_{S_{t}})$计算为$\mathcal{N}(\mu_{\theta}(x_{S_{t}}, S_{t}), \sum_{\theta}(x_{S_{t}}, S_{t}))$ 。</p>
<p>为了将采样步数从$T$减少到$K$，我们在$1$到$T$（包含两端）之间取$K$个均匀分布的实数，然后将每个结果四舍五入到最接近的整数。在图8中，我们评估了一个$L_{hybrid}$模型和一个$L_{simple}$模型的FID，这两个模型都经过4000步扩散训练，使用25、50、100、200、400、1000和4000步采样。我们对完全训练好的模型和训练过程中的中间模型进行了这样的评估。对于CIFAR-10，我们使用20万次和50万次训练迭代，对于ImageNet 64，我们使用50万次和150万次训练迭代。我们发现，固定标准差的$L_{simple}$模型（无论是较大的$\sigma_{t}^{2} = \beta_{t}$还是较小的$\sigma_{t}^{2} = \tilde{\beta}_{t}$ ）在减少采样步数时，样本质量下降得更明显，而我们学习标准差的$L_{hybrid}$模型则能保持较高的样本质量。对于这个模型，100步采样就足以使完全训练好的模型达到接近最优的FID。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f8.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图8. 在ImageNet 64×64（上）和CIFAR-10（下）上训练的模型的FID与采样步数的关系。所有模型都经过4000步扩散训练。</em></td>
</tr>
</tbody>
</table>
</div>
<p>在我们进行研究的同时，Song等人（2020a）提出了一种用于DDPM的快速采样算法，通过生成一个新的隐式模型，该模型具有与原模型相同的边际噪声分布，但能将噪声确定性地映射为图像。我们将他们的算法DDIM也纳入图8中进行比较，发现DDIM在采样步数少于50步时能生成更好的样本，但在使用50步或更多步数时样本质量较差。有趣的是，DDIM在训练开始时表现较差，但随着训练的进行，它与其他采样器的差距逐渐缩小。我们发现，我们的跨步技术会显著降低DDIM的性能，因此我们的DDIM结果使用了Song等人（2020a）提出的常数跨步，即最后一步是$T - T/K + 1$而不是$T$ 。其他采样器在使用我们的跨步技术时表现略有提升。</p>
<h3 id="5-与生成对抗网络（GANs）的比较"><a href="#5-与生成对抗网络（GANs）的比较" class="headerlink" title="5. 与生成对抗网络（GANs）的比较"></a>5. 与生成对抗网络（GANs）的比较</h3><p>虽然对数似然是衡量模式覆盖程度的一个良好指标，但用这个指标来与GANs进行比较却很困难。因此，我们转而使用精度和召回率（Kynkänniemi等人，2019）进行对比。由于在GAN的研究文献中，训练类条件模型是很常见的做法，所以在本次实验中我们也采用了同样的方式。为了使我们的模型成为类条件模型，我们通过与时间步t相同的路径注入类别信息。具体来说，我们将类别嵌入向量$v_{i}$添加到时间步嵌入向量$e_{t}$中，并将这个嵌入向量传递给模型中的各个残差块。我们使用$L_{hybrid}$目标函数进行训练，并采用250步采样。我们训练了两个模型：一个是参数为1亿的“小”模型，训练了170万步；另一个是参数为2.7亿的较大模型，训练了25万步。我们还训练了一个BigGAN-deep模型，其生成器和判别器的参数总量为1亿。</p>
<p>在计算这个任务的指标时，我们生成了50,000个样本（而不是通常的10,000个），以便能直接与其他研究成果进行比较。这是我们在报告ImageNet 64×64的FID时，唯一一次使用50,000个样本进行计算的情况。对于FID，参考分布的特征是在整个训练集上计算得到的，这遵循了（Brock等人，2018）的方法。</p>
<p>图9展示了我们较大模型生成的样本，表4总结了实验结果。我们发现，BigGAN-deep在FID方面优于我们的小模型，但在召回率方面表现不佳。这表明，扩散模型在覆盖分布模式方面比类似的GANs表现更优。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "t4.png" width="80%" height="80%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表4. 在类条件ImageNet 64×64上的样本质量比较。精度和召回率（Kynkänniemi等人，2019年）使用Inception-V3特征和$K = 5$进行测量。我们对BigGAN-deep模型进行了12.5万次迭代训练，并且在采样时不使用截断以最大化GAN的召回率。</em></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f9.png" width="60%" height="60%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图9. 使用$L_{hybrid}$模型（FID为2.92）经过250步采样生成的类条件ImageNet 64×64样本。这些类分别是9：鸵鸟、11：金翅雀、130：火烈鸟、141：红脚鹬、154：哈巴狗、157：蝴蝶犬、97：公鸭和28：斑点蝾螈。我们可以看到每个类别的样本都具有很高的多样性，这表明模型对目标分布有很好的覆盖。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="6-扩展模型规模"><a href="#6-扩展模型规模" class="headerlink" title="6. 扩展模型规模"></a>6. 扩展模型规模</h3><p>在前面的章节中，我们展示了在不改变训练计算量的情况下，通过算法改进提升对数似然和FID的方法。然而，现代机器学习的一个趋势是，更大的模型和更长的训练时间往往能提升模型性能（Kaplan等人，2020；Chen等人，2020a；Brown等人，2020）。基于这一观察，我们研究FID和负对数似然（NLL）如何随着训练计算量的变化而变化。我们的结果虽然是初步的，但表明随着训练计算量的增加，DDPMs的性能有可预测的提升。</p>
<p>为了衡量性能如何随训练计算量变化，我们使用第3.1节中描述的$L_{hybrid}$目标函数，在ImageNet 64×64上训练了四个不同的模型。为了改变模型容量，我们在所有层应用深度乘数，使得第一层分别有64、96、128或192个通道。注意，我们之前的实验中第一层使用128个通道。由于每层的深度会影响初始权重的尺度，我们针对每个模型将Adam（Kingma和Ba，2014）学习率除以通道乘数的平方根进行调整，使得128通道的模型学习率为0.0001（与我们其他实验一致）。</p>
<p>图10展示了FID和NLL相对于理论训练计算量的提升情况。FID曲线在对数坐标图上大致呈线性，这表明FID遵循幂律变化（用黑色虚线表示）。NLL曲线与幂律的拟合度没有那么高，这表明验证集上的NLL变化方式不如FID理想。这可能是由多种因素导致的，比如1）这类扩散模型存在出乎意料的高不可约损失（Henighan等人，2020）；2）模型对训练分布过拟合。我们还注意到，这些模型一般无法达到最优的对数似然，因为它们是使用$L_{hybrid}$目标函数训练的，而不是直接使用$L_{vlb}$，目的是同时兼顾良好的对数似然和样本质量。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f10.png" width="60%" height="60%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图10. 在ImageNet 64×64上不同模型规模在训练过程中的FID和验证集NLL。FID趋势线的常数是通过分布内数据的FID近似得到的。对于NLL趋势线，常数是通过向下取整该数据集当前最先进的NLL（Roy等人，2020）近似得到的。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="7-相关工作"><a href="#7-相关工作" class="headerlink" title="7. 相关工作"></a>7. 相关工作</h3><p>Chen等人（2020b）和Kong等人（2020）是近期两项利用去噪扩散概率模型（DDPMs）在基于梅尔频谱图的条件下生成高保真音频的研究。与我们的工作同期，Chen等人（2020b）结合改进的调度和$L_{1}$损失，使得在采样步数减少的情况下，样本质量仅有轻微下降。然而，与我们的无条件图像生成任务相比，他们的生成任务有梅尔频谱图提供的强输入条件信号，我们推测这使得在较少的扩散步数下进行采样变得更容易。</p>
<p>Jolicoeur-Martineau等人（2020）探索了图像领域的分数匹配，并构建了一个对抗训练目标，以产生更好的$x_{0}$预测。然而，他们发现选择更好的网络架构消除了对这种对抗目标的需求，这表明对抗目标对于强大的生成式建模并非必要。</p>
<p>与我们的工作并行，Song等人（2020a）和Song等人（2020b）通过利用不同的采样过程，为使用DDPM目标训练的模型提出了快速采样算法。Song等人（2020a）通过推导一个隐式生成模型来实现这一点，该模型与DDPMs具有相同的边际噪声分布，同时能将噪声确定性地映射到图像。Song等人（2020b）将扩散过程建模为连续随机微分方程（SDE）的离散化，并观察到存在一个与反向SDE采样相对应的常微分方程（ODE）。通过改变ODE求解器的数值精度，他们可以在较少的函数评估次数下进行采样。然而，他们指出，这种技术在直接使用时，生成的样本比祖传采样更差，只有在结合朗之万校正步骤时才能实现更好的FID。这反过来又需要手动调整朗之万步骤的信噪比。我们的方法允许直接从祖传过程中快速采样，从而无需额外的超参数。</p>
<p>同样与我们的工作同期，Gao等人（2020）开发了一种扩散模型，其中反向扩散步骤由基于能量的模型建模。这种方法的一个潜在意义是，可能需要更少的扩散步骤就能获得高质量的样本。</p>
<h3 id="8-结论"><a href="#8-结论" class="headerlink" title="8. 结论"></a>8. 结论</h3><p>我们已经证明，通过一些修改，去噪扩散概率模型（DDPMs）可以在对样本质量影响极小的情况下，实现更快的采样速度和更高的对数似然。通过我们的参数化方法和$L_{hybrid}$目标函数来学习$\sum_{\theta}$，提高了模型的对数似然，使得这些模型的对数似然更接近其他基于似然的模型。我们还意外地发现，这一改变还使得从这些模型采样所需的步数大幅减少。</p>
<p>我们还发现，DDPMs在样本质量上可以与生成对抗网络（GANs）相媲美，同时在通过召回率衡量的模式覆盖方面表现更优。此外，我们研究了DDPMs的性能如何随着可用训练计算量的变化而变化，发现更多的训练计算量能显著提升样本质量和对数似然。</p>
<p>这些结果综合起来，使得DDPMs成为生成式建模中一个极具吸引力的选择。因为它们结合了良好的对数似然、高质量的样本、相当快的采样速度，以及一个坚实可靠、稳定的训练目标，并且该目标能随着训练计算量的增加而轻松扩展。这些结果表明，DDPMs是未来研究的一个很有前景的方向。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/08/GLIDE-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/08/GLIDE-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">GLIDE Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-08 11:08:14" itemprop="dateCreated datePublished" datetime="2025-03-08T11:08:14+08:00">2025-03-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-09 10:50:25" itemprop="dateModified" datetime="2025-03-09T10:50:25+08:00">2025-03-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>扩散模型最近已被证明能够生成高质量的合成图像，尤其是在与引导技术相结合，以在多样性和逼真度之间进行权衡时。我们探索了用于文本条件图像合成问题的扩散模型，并比较了两种不同的引导策略：CLIP引导和无分类器引导。我们发现，在逼真度和字幕相似度方面，人类评估者更倾向于后者，并且它通常能生成逼真的样本。使用无分类器引导的35亿参数文本条件扩散模型生成的样本，即使在DALL-E使用昂贵的CLIP重排序的情况下，也更受人类评估者的青睐。此外，我们发现我们的模型可以进行微调以执行图像修复，从而实现强大的文本驱动图像编辑。我们在经过筛选的数据集上训练了一个较小的模型，并在<a target="_blank" rel="noopener" href="https://github.com/openai/glide-text2im上发布了代码和权重。">https://github.com/openai/glide-text2im上发布了代码和权重。</a><br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/08/GLIDE-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/08/Palette-Image-to-Image-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/08/Palette-Image-to-Image-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Palette Image-to-Image Diffusion Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-08 09:58:48 / 修改时间：11:08:13" itemprop="dateCreated datePublished" datetime="2025-03-08T09:58:48+08:00">2025-03-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文基于条件扩散模型开发了一个统一的图像到图像转换框架，并在四项具有挑战性的图像到图像转换任务上对该框架进行了评估，这些任务分别是彩色化、图像修复、图像扩展和JPEG图像恢复。我们对图像到图像扩散模型的简单实现，在所有任务上均优于强大的生成对抗网络（GAN）和回归基线方法，且无需针对特定任务进行超参数调整、架构定制，也无需使用任何辅助损失函数或复杂的新技术。我们揭示了去噪扩散目标中L2和L1损失对样本多样性的影响，并通过实证研究证明了自注意力机制在神经架构中的重要性。重要的是，我们倡导基于ImageNet建立统一的评估协议，采用人工评估和样本质量评分（如FID、Inception Score、预训练ResNet50的分类准确率，以及与原始图像的感知距离）。我们期望这个标准化的评估协议能够推动图像到图像转换研究的发展。最后，我们展示了一个通用的多任务扩散模型，其性能与特定任务的专业模型相当，甚至更优。有关结果和代码的概述，请查看<a target="_blank" rel="noopener" href="https://diffusionpalette.github.io/。">https://diffusionpalette.github.io/。</a><br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/08/Palette-Image-to-Image-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/08/%E5%B8%B8%E7%94%A8%E7%A7%91%E7%A0%94%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/08/%E5%B8%B8%E7%94%A8%E7%A7%91%E7%A0%94%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86/" class="post-title-link" itemprop="url">常用科研网站合集</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-08 09:24:48 / 修改时间：09:45:41" itemprop="dateCreated datePublished" datetime="2025-03-08T09:24:48+08:00">2025-03-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Ps：本文转载于<a target="_blank" rel="noopener" href="https://hwcoder.top/Awesome-Sites">科研常用网站合集</a><br>记录科研常用网站，包括：论文检索、代码检索、学者信息、论文写作、科研论坛、截稿日期、电子书。本文持续更新。</p>
<h2 id="Paper"><a href="#Paper" class="headerlink" title="Paper"></a><a href="#paper"></a>Paper</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Site</th>
<th>Describe</th>
<th>推荐指数</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener" href="http://www.arxivdaily.com/">ArXiv Daily</a></td>
<td><strong>每日爬取 ArXiv</strong> 各个领域论文，适合速刷</td>
<td>※※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://papers.labml.ai/papers/daily">Daliy Papers</a></td>
<td>近期<strong>热点论文</strong>追踪，每天必刷！</td>
<td>※※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/">Semantic Scholar</a></td>
<td>查看一篇论文的<strong>被引</strong>，按次数排序，<strong>更新速度很快</strong></td>
<td>※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.connectedpapers.com/">Connected Papers</a></td>
<td>用<strong>连通图</strong>展示同领域论文，大小论文都适用</td>
<td>※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://openreview.net/">OpenReview</a></td>
<td>检索<strong>最新在投论文</strong>，追踪顶会动向，可以看到<strong>审稿意见</strong></td>
<td>※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.scholar-inbox.com/">Shcolar Inbox</a></td>
<td>将最新论文按照<strong>研究兴趣匹配程度</strong>进行排序并推送</td>
<td>※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/">ArXiv</a></td>
<td>预印版论文下载，适合占坑</td>
<td>※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/">GitHub</a></td>
<td>偶尔会有好心人放出领域论文集</td>
<td>※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.paperdigest.org/">Paper Digest</a></td>
<td>快速搜索<strong>领域论文</strong>、最新会议论文索引 + <strong>highlight</strong></td>
<td>※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/menu">CVF Open Access</a></td>
<td>CV 会议论文下载</td>
<td>※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://ai-paper-collector.vercel.app/">AI-Paper-Search</a></td>
<td>国人开发的插件，支持关键词匹配 AI 顶会</td>
<td>※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://ac.scmor.com/">思谋学术导航</a></td>
<td>谷歌学术镜像与 Sci-Hub 导航</td>
<td>※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://xueshu.dailyheadlines.cc/">深度学术搜索</a></td>
<td>谷歌学术镜像</td>
<td>※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://readpaper.com/">ReadPaper</a></td>
<td>国内论文社区，可以看到别人对热点论文的<strong>笔记</strong></td>
<td>※</td>
</tr>
<tr>
<td>其他途径</td>
<td>公众号、组会分享、学术主页、顶会 Accept List</td>
<td>※※※※</td>
</tr>
</tbody>
</table>
</div>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/08/%E5%B8%B8%E7%94%A8%E7%A7%91%E7%A0%94%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/07/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/07/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">High-Resolution Image Synthesis with Latent Diffusion Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-07 18:05:33" itemprop="dateCreated datePublished" datetime="2025-03-07T18:05:33+08:00">2025-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-12 15:27:54" itemprop="dateModified" datetime="2025-03-12T15:27:54+08:00">2025-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>通过将图像生成过程分解为去噪自编码器的顺序应用，扩散模型（DMs）在图像数据及其他领域取得了最先进的合成结果。此外，其公式允许在无需重新训练的情况下，通过一种引导机制来控制图像生成过程。然而，由于这些模型通常直接在像素空间中运行，训练强大的扩散模型往往需要消耗数百个GPU日的计算资源，并且由于顺序评估，推理成本也很高。为了在有限的计算资源上训练扩散模型，同时保持其质量和灵活性，我们将其应用于强大的预训练自编码器的潜在空间中。与以往的工作不同，在这种表示上训练扩散模型首次在降低复杂度和保留细节之间达到了接近最优的平衡，极大地提高了视觉保真度。通过在模型架构中引入交叉注意力层，我们将扩散模型转变为强大且灵活的生成器，适用于文本或边界框等一般条件输入，并且以卷积方式实现高分辨率合成也成为可能。我们的潜在扩散模型（LDMs）在图像修复和类别条件图像合成方面取得了新的最先进分数，在包括文本到图像合成、无条件图像生成和超分辨率在内的各种任务中表现出极具竞争力的性能，同时与基于像素的扩散模型相比，显著降低了计算需求。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/07/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/02/NCSN%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/02/NCSN%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">NCSN论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-02 22:25:20" itemprop="dateCreated datePublished" datetime="2025-03-02T22:25:20+08:00">2025-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-08 09:46:51" itemprop="dateModified" datetime="2025-03-08T09:46:51+08:00">2025-03-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>Generative Modeling by Estimating Gradients of the Data Distribution</strong></p>
<h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>我们提出了一种新的生成模型，该模型通过朗之万动力学（Langevin dynamics）来生成样本，所使用的梯度是通过分数匹配（score matching）估计的数据分布梯度。由于当数据位于低维流形上时，梯度可能定义不明确且难以估计，因此我们用不同程度的高斯噪声对数据进行扰动，并联合估计相应的分数，即所有噪声水平下扰动数据分布的梯度向量场。在采样时，我们提出了一种退火朗之万动力学方法，在采样过程接近数据流形时，使用对应逐渐降低噪声水平的梯度。我们的框架允许灵活的模型架构，在训练过程中无需采样或使用对抗方法，并且提供了一个可用于原则性模型比较的学习目标。我们的模型在MNIST、CelebA和CIFAR - 10数据集上生成的样本可与生成对抗网络（GANs）相媲美，在CIFAR - 10数据集上达到了8.87的新最先进的初始得分（inception score）。此外，我们通过图像修复实验证明了我们的模型能够学习到有效的表示。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/02/NCSN%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/02/28/Classifier-Free-Diffusion-Guidance%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/02/28/Classifier-Free-Diffusion-Guidance%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Classifier-Free Diffusion Guidance论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-02-28 16:36:13" itemprop="dateCreated datePublished" datetime="2025-02-28T16:36:13+08:00">2025-02-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-08 09:57:33" itemprop="dateModified" datetime="2025-03-08T09:57:33+08:00">2025-03-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>分类器引导（Classifier guidance）是最近提出的一种方法，用于在条件扩散模型训练后，在模式覆盖和样本保真度之间进行权衡，这与其他类型生成模型中的低温采样或截断操作思路相似。分类器引导将扩散模型的得分估计与图像分类器的梯度相结合，因此需要训练一个与扩散模型分离的图像分类器。这也引发了一个问题：能否在不使用分类器的情况下进行引导。我们证明，确实可以通过一个纯生成模型在不使用分类器的情况下进行引导：在我们称为无分类器引导（classifier-free guidance）的方法中，我们联合训练一个条件扩散模型和一个无条件扩散模型，并结合得到的条件和无条件得分估计，在样本质量和多样性之间实现类似于使用分类器引导时的权衡。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/02/28/Classifier-Free-Diffusion-Guidance%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zongqing Li"
      src="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
  <p class="site-author-name" itemprop="name">Zongqing Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">49</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/hqulzq" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hqulzq" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hqulzq@163.com" title="E-Mail → mailto:hqulzq@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

      
<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
<div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div id="myCanvasContainer" class="widget tagcloud">
        <canvas width="250" height="250" id="resCanvas" style="width=100%">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/2019/" rel="tag">2019</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2020/" rel="tag">2020</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2021/" rel="tag">2021</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2022/" rel="tag">2022</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2023/" rel="tag">2023</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2025/" rel="tag">2025</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bug%E6%80%BB%E7%BB%93/" rel="tag">Bug总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR/" rel="tag">CVPR</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR-Workshop/" rel="tag">CVPR Workshop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/" rel="tag">ICLR</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/" rel="tag">ICML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Knife4j/" rel="tag">Knife4j</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MinIO/" rel="tag">MinIO</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mybatis-Plus/" rel="tag">Mybatis-Plus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NeurIPS/" rel="tag">NeurIPS</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx/" rel="tag">Nginx</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RabbitMQ/" rel="tag">RabbitMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RocketMQ/" rel="tag">RocketMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a><span class="tag-list-count">17</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/" rel="tag">k8s</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/latex/" rel="tag">latex</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/" rel="tag">mongodb</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/" rel="tag">代码随想录</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%B4%E5%87%BD%E6%95%B0/" rel="tag">头函数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%9A%E5%BA%AD%E5%85%AC%E5%AF%93/" rel="tag">尚庭公寓</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/" rel="tag">异常处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" rel="tag">快速入门</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/" rel="tag">技术总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B3%A8%E8%A7%A3/" rel="tag">注解</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%AB%99/" rel="tag">网站</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%8B%A5%E4%BE%9D/" rel="tag">若依</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" rel="tag">设计模式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E8%A1%A8i/" rel="tag">链表i</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/" rel="tag">项目实战</a><span class="tag-list-count">6</span></li></ul>
        </canvas>
    </div>
</div>



    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zongqing Li</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #4D4D4C;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #F7F7F7;
      background-image: linear-gradient(#F7F7F7, #F7F7F7);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>

  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('post.copy_button').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('post.copy_success')
          else $(this).text('post.copy_failure')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('post.copy_button')
        }, 300)
      }).append(e)
    })
  </script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
