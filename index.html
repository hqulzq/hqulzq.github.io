<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"hqulzq.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Lzq&#39;s blog">
<meta property="og:url" content="https://hqulzq.github.io/index.html">
<meta property="og:site_name" content="Lzq&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Zongqing Li">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://hqulzq.github.io/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>Lzq's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lzq's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">43</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">12</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">51</span></a>

  </li>
        <li class="menu-item menu-item-book">

    <a href="/book" rel="section"><i class="fas fa-book fa-fw"></i>Book</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/14/diffusion%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%84%9F%E6%82%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/14/diffusion%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E6%84%9F%E6%82%9F/" class="post-title-link" itemprop="url">diffusion论文阅读感悟</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-14 20:56:45 / 修改时间：21:07:57" itemprop="dateCreated datePublished" datetime="2025-03-14T20:56:45+08:00">2025-03-14</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>按照时间排序</strong></p>
<h2 id="NSCN-Noise-Conditional-Score-Networks-Generative-Modeling-by-Estimating-Gradients-of-the-Data-Distribution"><a href="#NSCN-Noise-Conditional-Score-Networks-Generative-Modeling-by-Estimating-Gradients-of-the-Data-Distribution" class="headerlink" title="(NSCN- Noise Conditional Score Networks) Generative Modeling by Estimating Gradients of the Data Distribution"></a>(NSCN- Noise Conditional Score Networks) Generative Modeling by Estimating Gradients of the Data Distribution</h2><ul>
<li>发表于<strong>2029-NeurIPS</strong></li>
</ul>
<h2 id="DDPM-Denoising-Diffusion-Probabilistic-Models"><a href="#DDPM-Denoising-Diffusion-Probabilistic-Models" class="headerlink" title="(DDPM) Denoising Diffusion Probabilistic Models"></a>(DDPM) Denoising Diffusion Probabilistic Models</h2><ul>
<li>发表于<strong>2020-NeurIPS</strong></li>
<li>提出了一种马尔可夫的加噪与去噪过程，diffusion的经典之作</li>
</ul>
<h2 id="Palette-Image-to-Image-Diffusion-Models"><a href="#Palette-Image-to-Image-Diffusion-Models" class="headerlink" title="Palette Image-to-Image Diffusion Models"></a>Palette Image-to-Image Diffusion Models</h2><ul>
<li>发表于<strong>2021-CVPR</strong></li>
</ul>
<h2 id="Classifier-Free-Diffusion-Guidance"><a href="#Classifier-Free-Diffusion-Guidance" class="headerlink" title="Classifier-Free Diffusion Guidance"></a>Classifier-Free Diffusion Guidance</h2><ul>
<li>发表于<strong>2021-CVPR-Workshop</strong></li>
</ul>
<h2 id="GLIDE-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models"><a href="#GLIDE-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models" class="headerlink" title="GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models"></a>GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models</h2><ul>
<li>发表于<strong>2021</strong></li>
</ul>
<h2 id="DDIM-Denoising-Diffusion-Implicit-Models"><a href="#DDIM-Denoising-Diffusion-Implicit-Models" class="headerlink" title="(DDIM) Denoising Diffusion Implicit Models"></a>(DDIM) Denoising Diffusion Implicit Models</h2><ul>
<li>发表于<strong>2021-ICLR</strong></li>
</ul>
<h2 id="Score-Based-Models-Score-Based-Generative-Modeling-through-Stochastic-Differential-Equations"><a href="#Score-Based-Models-Score-Based-Generative-Modeling-through-Stochastic-Differential-Equations" class="headerlink" title="(Score-Based Models) Score-Based Generative Modeling through Stochastic Differential Equations"></a>(Score-Based Models) Score-Based Generative Modeling through Stochastic Differential Equations</h2><ul>
<li>发表于<strong>2021-ICLR</strong></li>
</ul>
<h2 id="IDDPM-Improved-Denoising-Diffusion-Probabilistic-Model"><a href="#IDDPM-Improved-Denoising-Diffusion-Probabilistic-Model" class="headerlink" title="(IDDPM) Improved Denoising Diffusion Probabilistic Model"></a>(IDDPM) Improved Denoising Diffusion Probabilistic Model</h2><ul>
<li>发表于<strong>2021-ICML</strong></li>
</ul>
<h2 id="Classifier-Guidance-diffusion-models-beat-gans-on-image-synthesis"><a href="#Classifier-Guidance-diffusion-models-beat-gans-on-image-synthesis" class="headerlink" title="(Classifier Guidance) diffusion-models-beat-gans-on-image-synthesis"></a>(Classifier Guidance) diffusion-models-beat-gans-on-image-synthesis</h2><ul>
<li>发表于<strong>2021-NeurIPS</strong></li>
</ul>
<h2 id="LDM-Stable-Diffusion原型-High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models"><a href="#LDM-Stable-Diffusion原型-High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models" class="headerlink" title="(LDM: Stable Diffusion原型) High-Resolution Image Synthesis with Latent Diffusion Models"></a>(LDM: Stable Diffusion原型) High-Resolution Image Synthesis with Latent Diffusion Models</h2><ul>
<li>发表于<strong>2022-CVPR</strong></li>
</ul>
<h2 id="ADPM-Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models"><a href="#ADPM-Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models" class="headerlink" title="(ADPM) Analytic-DPM an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models"></a>(ADPM) Analytic-DPM an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models</h2><ul>
<li>发表于<strong>2022-ICLR</strong></li>
</ul>
<h2 id="DPM-Solver-DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps"><a href="#DPM-Solver-DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps" class="headerlink" title="(DPM-Solver) DPM-Solver-A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps"></a>(DPM-Solver) DPM-Solver-A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps</h2><ul>
<li>发表于<strong>2022-NeurIPS</strong></li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/DPM-Solver-A-Fast-ODE-Solver-for-Diffusion-Probabilistic-Model-Sampling-in-Around-10-Steps%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">DPM-Solver-A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-12 20:59:26" itemprop="dateCreated datePublished" datetime="2025-03-12T20:59:26+08:00">2025-03-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-14 21:26:25" itemprop="dateModified" datetime="2025-03-14T21:26:25+08:00">2025-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>扩散概率模型（DPMs）是新兴的强大生成模型。尽管DPMs具有高质量的生成性能，但它们的采样速度仍然较慢，因为通常需要对大型神经网络进行数百或数千次的顺序函数评估（步骤）才能生成一个样本。从DPMs中采样可以看作是求解相应的扩散常微分方程（ODEs）。在这项工作中，我们提出了扩散ODEs解的精确公式。该公式通过解析计算解的线性部分，而不是像以往工作那样将所有项都留给黑箱ODE求解器处理。通过变量变换，解可以等效简化为神经网络的指数加权积分。基于我们的公式，我们提出了DPM-Solver，这是一种快速的、具有收敛阶保证的专用高阶扩散ODE求解器。DPM-Solver适用于离散时间和连续时间的DPMs，且无需任何额外训练。实验结果表明，DPM-Solver在各种数据集上仅需10 - 20次函数评估就能生成高质量样本。在CIFAR10数据集上，我们在10次函数评估中达到了4.70的FID（Frechet Inception Distance），在20次函数评估中达到了2.87的FID，并且与之前最先进的无训练采样器相比，在各种数据集上实现了4 - 16倍的加速。</p>
<h3 id="2-扩散概率模型"><a href="#2-扩散概率模型" class="headerlink" title="2 扩散概率模型"></a>2 扩散概率模型</h3><p>在本节中，我们将回顾扩散概率模型及其相关的微分方程。</p>
<h4 id="2-1-正向过程和扩散随机微分方程"><a href="#2-1-正向过程和扩散随机微分方程" class="headerlink" title="2.1 正向过程和扩散随机微分方程"></a>2.1 正向过程和扩散随机微分方程</h4><p>假设我们有一个$D$维随机变量$x_{0} \in \mathbb{R}^{D}$，其分布$q_{0}(x_{0})$未知。扩散概率模型（DPMs）[1-3,10]定义了一个从$x_{0}$开始的正向过程$\{x_{t}\}_{t \in[0, T]}$（$T&gt;0$），使得对于任意$t \in[0, T]$，在给定$x_{0}$的条件下，$x_{t}$的分布满足：</p>
<script type="math/tex; mode=display">q_{0 t}\left(x_{t} | x_{0}\right)=\mathcal{N}\left(x_{t} | \alpha(t) x_{0}, \sigma^{2}(t) I\right), \tag{2.1}</script><p>其中$\alpha(t)$、$\sigma(t) \in \mathbb{R}^{+}$是关于$t$的可微函数，且导数有界，为简化表示，我们将它们记为$\alpha_{t}$、$\sigma_{t}$。$\alpha_{t}$和$\sigma_{t}$的选择被称为DPM的噪声调度。令$q_{t}(x_{t})$表示$x_{t}$的边际分布，DPMs通过选择噪声调度，确保对于某个$\bar{\sigma}&gt;0$，有$q_{T}(x_{T}) \approx \mathcal{N}(x_{T} | 0, \tilde{\sigma}^{2} I)$，并且信噪比（SNR）$\alpha_{t}^{2} / \sigma_{t}^{2}$随$t$严格递减[10]。此外，Kingma等人[10]证明，对于任意$t \in[0, T]$，以下随机微分方程（SDE）与公式（2.1）具有相同的转移分布$q_{0 t}(x_{t} | x_{0})$：</p>
<script type="math/tex; mode=display">d x_{t}=f(t) x_{t} d t+g(t) d w_{t}, x_{0} \sim q_{0}\left(x_{0}\right), \tag{2.2}</script><p>其中$w_{t} \in \mathbb{R}^{D}$是标准维纳过程，并且</p>
<script type="math/tex; mode=display">f(t)=\frac{d \log \alpha_{t}}{d t}, g^{2}(t)=\frac{d \sigma_{t}^{2}}{d t}-2 \frac{d \log \alpha_{t}}{d t} \sigma_{t}^{2} \tag{2.3}</script><p>在一些正则条件下，Song等人[3]表明，公式（2.2）中的正向过程存在一个从时间$T$到$0$的等效反向过程，从边际分布$q_{T}(x_{T})$开始：</p>
<script type="math/tex; mode=display">d x_{t}=\left[f(t) x_{t}-g^{2}(t) \nabla_{x} \log q_{t}\left(x_{t}\right)\right] d t+g(t) d \overline{w}_{t}, x_{T} \sim q_{T}\left(x_{T}\right), \tag{2.4}</script><p>其中$\overline{w}_{t}$是反向时间的标准维纳过程。公式（2.4）中唯一未知的项是每个时间$t$的得分函数$\nabla_{x} \log q_{t}(x_{t})$。在实践中，DPMs使用由$\theta$参数化的神经网络$\epsilon_{\theta}(x_{t}, t)$来估计缩放后的得分函数：$-\sigma_{t} \nabla_{x} \log q_{t}(x_{t})$ 。通过最小化以下目标来优化参数$\theta$[2,3]：</p>
<script type="math/tex; mode=display">\begin{aligned} \mathcal{L}(\theta ; \omega(t)) & :=\frac{1}{2} \int_{0}^{T} \omega(t) \mathbb{E}_{q_{t}\left(x_{t}\right)}\left[\left\| \epsilon_{\theta}\left(x_{t}, t\right)+\sigma_{t} \nabla_{x} \log q_{t}\left(x_{t}\right)\right\| _{2}^{2}\right] d t \\ & =\frac{1}{2} \int_{0}^{T} \omega(t) \mathbb{E}_{q_{0}\left(x_{0}\right)} \mathbb{E}_{q(\epsilon)}\left[\left\| \epsilon_{\theta}\left(x_{t}, t\right)-\epsilon\right\| _{2}^{2}\right] d t+C, \end{aligned}</script><p>其中$\omega(t)$是一个加权函数，$\epsilon \sim q(\epsilon)=\mathcal{N}(\epsilon | 0, I)$，$x_{t}=\alpha_{t} x_{0}+\sigma_{t} \epsilon$，$C$是一个与$\theta$无关的常数。由于$\epsilon_{\theta}(x_{t}, t)$也可以被视为预测添加到$x_{t}$的高斯噪声，所以它通常被称为噪声预测模型。由于$\epsilon_{\theta}(x_{t}, t)$的真实值是$-\sigma_{t} \nabla_{x} \log q_{t}(x_{t})$，DPMs用$-\epsilon_{\theta}(x_{t}, t)/\sigma_{t}$替换公式（2.4）中的得分函数，并定义了一个从时间$T$到$0$的参数化反向过程（扩散SDE），从$x_{T} \sim \mathcal{N}(0, \tilde{\sigma}^{2} I)$开始：</p>
<script type="math/tex; mode=display">d x_{t}=\left[f(t) x_{t}+\frac{g^{2}(t)}{\sigma_{t}} \epsilon_{\theta}\left(x_{t}, t\right)\right] d t+g(t) d \overline{w}_{t}, x_{T} \sim \mathcal{N}\left(0, \tilde{\sigma}^{2} I\right) .  \tag{2.5}</script><p>可以使用数值求解器求解公式（2.5）中的扩散SDE来从DPMs生成样本，该数值求解器将SDE从$T$离散到$0$ 。Song等人[3]证明，DPMs传统的祖传采样方法[2]可以看作是公式（2.5）的一阶SDE求解器。然而，这些一阶方法通常需要数百或数千次函数评估才能收敛[3]，导致采样速度极慢。</p>
<h4 id="2-2-扩散（概率流）常微分方程"><a href="#2-2-扩散（概率流）常微分方程" class="headerlink" title="2.2 扩散（概率流）常微分方程"></a>2.2 扩散（概率流）常微分方程</h4><p>在离散化SDE时，步长受到维纳过程随机性的限制[27，第11章]。较大的步长（较少的步数）通常会导致不收敛，尤其是在高维空间中。为了实现更快的采样，可以考虑相关的概率流ODE[3]，它在每个时间$t$的边际分布与SDE相同。具体来说，对于DPMs，Song等人[3]证明了公式（2.4）的概率流ODE为：</p>
<script type="math/tex; mode=display">\frac{d x_{t}}{d t}=f(t) x_{t}-\frac{1}{2} g^{2}(t) \nabla_{x} \log q_{t}\left(x_{t}\right), x_{T} \sim q_{T}\left(x_{T}\right),  \tag{2.6}</script><p>其中$x_{t}$的边际分布也是$q_{t}(x_{t})$ 。通过用噪声预测模型替换得分函数，Song等人[3]定义了以下参数化ODE（扩散ODE）：</p>
<script type="math/tex; mode=display">\frac{d x_{t}}{d t}=h_{\theta}\left(x_{t}, t\right):=f(t) x_{t}+\frac{g^{2}(t)}{2 \sigma_{t}} \epsilon_{\theta}\left(x_{t}, t\right), x_{T} \sim \mathcal{N}\left(0, \tilde{\sigma}^{2} I\right). \tag{2.7}</script><p>可以通过从$T$到$0$求解该ODE来生成样本。与SDE相比，ODE可以使用更大的步长求解，因为它们没有随机性。此外，我们可以利用高效的数值ODE求解器来加速采样。Song等人[3]使用RK45 ODE求解器[28]求解扩散ODE，在CIFAR-10数据集[29]上，该方法通过约60次函数评估生成的样本质量，可与公式（2.5）的1000步SDE求解器相媲美。然而，现有的通用ODE求解器仍然无法在少步（约10步）采样中生成令人满意的样本。据我们所知，目前仍然缺乏适用于少步采样的无训练DPM采样器，DPM的采样速度仍然是一个关键问题。</p>
<h3 id="3-扩散常微分方程的定制快速求解器"><a href="#3-扩散常微分方程的定制快速求解器" class="headerlink" title="3 扩散常微分方程的定制快速求解器"></a>3 扩散常微分方程的定制快速求解器</h3><p>如2.2节所述，在高维情况下离散化随机微分方程（SDEs）通常很困难[27，第11章]，且很难在几步内收敛。相比之下，常微分方程（ODEs）更容易求解，这为快速采样器提供了潜力。然而，正如2.2节提到的，先前工作[3]中使用的通用黑箱ODE求解器在经验上无法在几步内收敛。这促使我们设计一种专门用于扩散ODEs的求解器，以实现快速且高质量的少步采样。我们从详细研究扩散ODEs的具体结构开始。</p>
<h4 id="3-1-扩散常微分方程精确解的简化公式"><a href="#3-1-扩散常微分方程精确解的简化公式" class="headerlink" title="3.1 扩散常微分方程精确解的简化公式"></a>3.1 扩散常微分方程精确解的简化公式</h4><p>这项工作的关键见解是，给定时间$s&gt;0$时的初始值$x_{s}$，式（2.7）中扩散ODEs在每个时间$t&lt;s$的解$x_{t}$可以简化为一个非常特殊的精确公式，并且可以有效地进行近似。</p>
<p>我们的第一个关键观察结果是，考虑到扩散ODEs的特殊结构，解$x_{t}$的一部分可以精确计算。式（2.7）中扩散ODEs的右侧由两部分组成：$f(t)x_{t}$这部分是$x_{t}$的线性函数，而另一部分$\frac{g^{2}(t)}{2\sigma_{t}}\epsilon_{\theta}(x_{t},t)$由于神经网络$\epsilon_{\theta}(x_{t},t)$的存在，通常是$x_{t}$的非线性函数。这种类型的ODE被称为半线性ODE。先前工作[3]采用的黑箱ODE求解器忽略了这种半线性结构，因为它们将式（2.7）中的整个$h_{\theta}(x_{t},t)$作为输入，这导致了线性项和非线性项的离散化误差。我们注意到，对于半线性ODEs，时间$t$的解可以通过 “常数变易” 公式[30]精确表示为：</p>
<script type="math/tex; mode=display">x_{t}=e^{\int_{s}^{t} f(\tau) d \tau} x_{s}+\int_{s}^{t}\left(e^{\int_{\tau}^{t} f(r) d r} \frac{g^{2}(\tau)}{2 \sigma_{\tau}} \epsilon_{\theta}\left(x_{\tau}, \tau\right)\right) d \tau . \tag{3.1}</script><p>这个公式将线性部分和非线性部分解耦。与黑箱ODE求解器不同，现在线性部分被精确计算，消除了线性项的近似误差。然而，非线性部分的积分仍然很复杂，因为它将与噪声调度相关的系数（即$f(\tau)$、$g(\tau)$等）和复杂的神经网络$\epsilon_{\theta}$耦合在一起，仍然难以近似。</p>
<p>我们的第二个关键观察结果是，通过引入一个特殊变量，非线性部分的积分可以大大简化。令$\lambda_{t}:=\log (\alpha_{t} / \sigma_{t})$（即对数信噪比的一半），那么$\lambda_{t}$是$t$的严格递减函数（根据2.1节中对DPMs的定义）。我们可以将式（2.3）中的$g(t)$重写为：</p>
<script type="math/tex; mode=display">g^{2}(t)=\frac{d \sigma_{t}^{2}}{d t}-2 \frac{d \log \alpha_{t}}{d t} \sigma_{t}^{2}=2 \sigma_{t}^{2}\left(\frac{d \log \sigma_{t}}{d t}-\frac{d \log \alpha_{t}}{d t}\right)=-2 \sigma_{t}^{2} \frac{d \lambda_{t}}{d t} .\tag{3.2}</script><p>结合式（2.3）中的$f(t)=d \log \alpha_{t} / d t$，我们可以将式（3.1）重写为：</p>
<script type="math/tex; mode=display">x_{t}=\frac{\alpha_{t}}{\alpha_{s}} x_{s}-\alpha_{t} \int_{s}^{t}\left(\frac{d \lambda_{\tau}}{d \tau}\right) \frac{\sigma_{\tau}}{\alpha_{\tau}} \epsilon_{\theta}\left(x_{\tau}, \tau\right) d \tau .\tag{3.3}</script><p>由于$\lambda(t)=\lambda_{t}$是$t$的严格递减函数，它有一个反函数$t_{\lambda}(\cdot)$，满足$t=t_{\lambda}(\lambda(t))$。我们进一步将$x$和$\epsilon_{\theta}$的下标从$t$改为$\lambda$，并表示$\hat{x}_{\lambda}:=x_{t_{\lambda}(\lambda)}$，$\hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda):=\epsilon_{\theta}(x_{t_{\lambda}(\lambda)}, t_{\lambda}(\lambda))$。通过对$\lambda$进行 “变量变换” 重写式（3.3），我们得到：</p>
<p><strong>命题3.1（扩散ODEs的精确解）</strong>：给定时间$s&gt;0$时的初始值$x_{s}$，式（2.7）中扩散ODEs在时间$t \in[0, s]$的解$x_{t}$为：</p>
<script type="math/tex; mode=display">x_{t}=\frac{\alpha_{t}}{\alpha_{s}} x_{s}-\alpha_{t} \int_{\lambda_{s}}^{\lambda_{t}} e^{-\lambda} \hat{\epsilon}_{\theta}\left(\hat{x}_{\lambda}, \lambda\right) d \lambda . \tag{3.4}</script><p>我们将积分$\int e^{-\lambda} \hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda) d \lambda$称为$\hat{\epsilon}_{\theta}$的指数加权积分，它非常特殊，并且与ODE求解器文献中的指数积分器[25]密切相关。据我们所知，在扩散模型的先前工作中尚未揭示这种公式。</p>
<p>式（3.4）为近似扩散ODEs的解提供了新的视角。具体来说，给定时间$s$的$x_{s}$，根据式（3.4），近似时间$t$的解等同于直接近似从$\lambda_{s}$到$\lambda_{t}$的$\hat{\epsilon}_{\theta}$的指数加权积分，这避免了线性项的误差，并且在指数积分器的文献[25, 31]中已有深入研究。基于这一见解，我们提出了用于扩散ODEs的快速求解器，详见以下章节。</p>
<h4 id="3-2-扩散常微分方程的高阶求解器"><a href="#3-2-扩散常微分方程的高阶求解器" class="headerlink" title="3.2 扩散常微分方程的高阶求解器"></a>3.2 扩散常微分方程的高阶求解器</h4><p>在本节中，我们利用所提出的解公式（3.4），提出了具有收敛阶保证的扩散ODEs高阶求解器。所提出的求解器和分析受到ODE文献中指数积分器方法[25, 31]的启发。</p>
<p>具体来说，给定时间$T$的初始值$x_{T}$和从$t_{0}=T$到$t_{M}=0$递减的$M + 1$个时间步$\{t_{i}\}_{i = 0}^{M}$。令$\tilde{x}_{t_{0}} = x_{T}$为初始值。所提出的求解器使用$M$步迭代计算序列$\{\tilde{x}_{t_{i}}\}_{i = 0}^{M}$，以近似时间步$\{t_{i}\}_{i = 0}^{M}$的真实解。特别地，最后一次迭代$\tilde{x}_{t_{M}}$近似时间$0$的真实解。</p>
<p>为了减少$\tilde{x}_{t_{M}}$与时间$0$真实解之间的近似误差，我们需要在每一步减少$\tilde{x}_{t_{i}}$的近似误差[30]。从时间$t_{i - 1}$的先前值$\tilde{x}_{t_{i - 1}}$开始，根据式（3.4），时间$t_{i}$的精确解$x_{t_{i - 1} \to t_{i}}$为：</p>
<script type="math/tex; mode=display">x_{t_{i - 1} \to t_{i}}=\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \overline{x}_{t_{i - 1}}-\alpha_{t_{i}} \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_{i}}} e^{-\lambda} \hat{\epsilon}_{\theta}\left(\hat{x}_{\lambda}, \lambda\right) d \lambda .\tag{3.5}</script><p>因此，为了计算用于近似$x_{t_{i - 1} \to t_{i}}$的$\tilde{x}_{t_{i}}$值，我们需要近似从$\lambda_{t_{i - 1}}$到$\lambda_{t_{i}}$的$\hat{\epsilon}_{\theta}$的指数加权积分。记$h_{i}:=\lambda_{t_{i}}-\lambda_{t_{i - 1}}$，$\hat{\epsilon}_{\theta}^{(n)}(\hat{x}_{\lambda}, \lambda):=\frac{d^{n} \hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda)}{d \lambda^{n}}$为$\hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda)$关于$\lambda$的$n$阶全导数。对于$k \geq 1$，$\hat{\epsilon}_{\theta}(\hat{x}_{\lambda}, \lambda)$在$\lambda_{t_{i - 1}}$处关于$\lambda$的$(k - 1)$阶泰勒展开式为：</p>
<script type="math/tex; mode=display">\hat{\epsilon}_{\theta}\left(\hat{x}_{\lambda}, \lambda\right)=\sum_{n = 0}^{k - 1} \frac{\left(\lambda-\lambda_{t_{i - 1}}\right)^{n}}{n!} \hat{\epsilon}_{\theta}^{(n)}\left(\hat{x}_{\lambda_{t_{i - 1}}}, \lambda_{t_{i - 1}}\right)+\mathcal{O}\left(\left(\lambda-\lambda_{t_{i - 1}}\right)^{k}\right) .</script><p>将上述泰勒展开式代入式（3.5），得到：</p>
<script type="math/tex; mode=display">x_{t_{i - 1} \to t_{i}}=\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \tilde{x}_{t_{i - 1}}-\alpha_{t_{i}} \sum_{n = 0}^{k - 1} \hat{\epsilon}_{\theta}^{(n)}\left(\hat{x}_{\lambda_{t_{i - 1}}}, \lambda_{t_{i - 1}}\right) \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_{i}}} e^{-\lambda} \frac{\left(\lambda-\lambda_{t_{i - 1}}\right)^{n}}{n!} d \lambda+\mathcal{O}\left(h_{i}^{k + 1}\right) .\tag{3.6}</script><p>其中积分$\int e^{-\lambda} \frac{(\lambda-\lambda_{t_{i - 1}})^{n}}{n!} d \lambda$可以通过反复应用$n$次分部积分法进行解析计算（见附录B.2）。因此，为了近似$x_{t_{i - 1} \to t_{i}}$，我们只需要近似$n \leq k - 1$时的$n$阶全导数$\hat{\epsilon}_{\theta}^{(n)}(\hat{x}_{\lambda}, \lambda)$，这在ODE文献[31, 32]中是一个研究得较为充分的问题。通过舍弃$O(h_{i}^{k + 1})$误差项，并使用 “刚性阶条件” [31, 32]近似前$(k - 1)$阶全导数，我们可以推导出用于扩散ODEs的$k$阶ODE求解器。我们将这类求解器统称为DPM-Solver，对于特定的阶数$k$，则称为DPM-Solver-$k$。这里我们以$k = 1$为例进行说明。在这种情况下，式（3.6）变为：</p>
<script type="math/tex; mode=display">\begin{aligned} x_{t_{i - 1} \to t_{i}} & =\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \overline{x}_{t_{i - 1}}-\alpha_{t_{i}} \epsilon_{\theta}\left(\tilde{x}_{t_{i - 1}}, t_{i - 1}\right) \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_{i}}} e^{-\lambda} d \lambda+\mathcal{O}\left(h_{i}^{2}\right) \\ & =\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \tilde{x}_{t_{i - 1}}-\sigma_{t_{i}}\left(e^{h_{i}} - 1\right) \epsilon_{\theta}\left(\tilde{x}_{t_{i - 1}}, t_{i - 1}\right)+\mathcal{O}\left(h_{i}^{2}\right) 。 \end{aligned}</script><p>通过舍弃高阶误差项$O(h_{i}^{2})$，我们可以得到$x_{t_{i - 1} \to t_{i}}$的近似值。由于这里$k = 1$，我们将这个求解器称为DPM-Solver-1，详细算法如下：</p>
<p><strong>DPM-Solver-1</strong>：给定初始值$x_{T}$和从$t_{0}=T$到$t_{M}=0$递减的$M + 1$个时间步$\{t_{i}\}_{i = 0}^{M}$。从$\tilde{x}_{t_{0}} = x_{T}$开始，序列$\{\tilde{x}_{t_{i}}\}_{i = 1}^{M}$通过以下方式迭代计算：</p>
<script type="math/tex; mode=display">\tilde{x}_{t_{i}}=\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \tilde{x}_{t_{i - 1}}-\sigma_{t_{i}}\left(e^{h_{i}} - 1\right) \epsilon_{\theta}\left(\tilde{x}_{t_{i - 1}}, t_{i - 1}\right), \text{其中} h_{i}=\lambda_{t_{i}}-\lambda_{t_{i - 1}} . \tag{3.7}</script><p>对于$k \geq 2$，近似泰勒展开式的前$k$项需要在$t$和$s$之间设置额外的中间点[31]。推导过程更具技术性，因此我们将其推迟到附录B。下面我们提出$k = 2, 3$的算法，并分别将它们命名为DPM-Solver-2和DPM-Solver-3。</p>
<p><img src="a1.png" alt=""><br><img src="a2.png" alt=""></p>
<p>在这里，$t_{\lambda}(\cdot)$ 是 $\lambda(t)$ 的反函数，对于文献[2, 16]中使用的实际噪声调度，它有一个解析表达式，如附录D所示。对于二阶龙格 - 库塔扩散概率模型求解器（DPM - Solver - 2），选择的中间点是 $(s_{i}, u_{i})$ ，对于三阶龙格 - 库塔扩散概率模型求解器（DPM - Solver - 3），选择的中间点是 $(s_{2i - 1}, u_{2i - 1})$ 和 $(s_{2i}, u_{2i})$ 。如算法中所示，对于 $k = 1, 2, 3$，DPM - Solver - $k$ 每一步需要 $k$ 次函数求值。尽管高阶求解器（$k = 2, 3$）的每一步计算成本更高，但由于它们的收敛阶更高，达到收敛所需的步数要少得多，所以通常效率更高。我们证明了 DPM - Solver - $k$ 是 $k$ 阶求解器，如以下定理所述。证明见附录B。</p>
<p><strong>定理3.2（DPM - Solver - $k$ 作为 $k$ 阶求解器）</strong> 假设 $\epsilon_{\theta}(x_{t}, t)$ 满足附录B.1中详细说明的正则条件，那么对于 $k = 1, 2, 3$ ，DPM - Solver - $k$ 是扩散常微分方程（ODE）的 $k$ 阶求解器，也就是说，对于由DPM - Solver - $k$ 计算得到的序列 $\{\tilde{x}_{t_{i}}\}_{i = 1}^{M}$ ，在时间 $t = 0$ 处的近似误差满足 $\tilde{x}_{t_{M}} - x_{0} = \mathcal{O}(h_{max}^{k})$ ，其中 $h_{max} = \max_{1\leq i\leq M}(\lambda_{t_{i}} - \lambda_{t_{i - 1}})$ 。</p>
<p>最后，如先前关于指数积分器的文献[31, 32]所示，$k\geq4$ 的求解器需要更多的中间点。因此，在这项工作中我们仅考虑 $k$ 从1到3 的情况，而将更高 $k$ 值的求解器留待未来研究。</p>
<h3 id="3-3-步长调度"><a href="#3-3-步长调度" class="headerlink" title="3.3 步长调度"></a>3.3 步长调度</h3><p>3.2节中提出的求解器需要预先指定时间步${t_{i}}_{i = 0}^{M}$。我们提出了两种步长调度的选择。一种是手动设定的，即均匀划分区间$[\lambda_{T}, \lambda_{0}]$，也就是$\lambda_{t_{i}} = \lambda_{T} + \frac{i}{M}(\lambda_{0} - \lambda_{T})$，其中$i = 0, \ldots, M$。需要注意的是，这与之前的工作[2, 3]不同，之前的工作是对$t_{i}$选择均匀的时间步。从经验上看，采用均匀时间步长$\lambda_{t_{i}}$的DPM-Solver已经能够在几步内生成相当不错的样本，附录E中列出了相关结果。作为另一种选择，我们提出了一种自适应步长算法，通过结合不同阶数的DPM-Solver来动态调整步长。这种自适应算法的灵感来自于[20]，我们将其实现细节放在附录C中。</p>
<p>对于少步采样，我们需要充分利用所有的函数评估次数（NFE）。当NFE不能被3整除时，我们首先尽可能多地应用DPM-Solver-3，然后根据NFE除以3的余数，添加单步的DPM-Solver-1或DPM-Solver-2（具体取决于余数），附录D中有详细说明。在后续实验中，对于NFE ≤ 20的情况，我们使用这种结合均匀步长调度的求解器组合；对于其他情况，则使用自适应步长调度。</p>
<h3 id="3-4-从离散时间扩散概率模型采样"><a href="#3-4-从离散时间扩散概率模型采样" class="headerlink" title="3.4 从离散时间扩散概率模型采样"></a>3.4 从离散时间扩散概率模型采样</h3><p>离散时间扩散概率模型（DPMs）[2]在$N$个固定时间步${t_{n}}_{n = 1}^{N}$训练噪声预测模型，噪声预测模型由$\tilde{\epsilon}_{\theta}(x_{n}, n)$参数化，其中$n = 0, \ldots, N - 1$，每个$x_{n}$对应于时间$t_{n + 1}$的值。我们可以通过令$\epsilon_{\theta}(x, t):=\tilde{\epsilon}_{\theta}(x, \frac{(N - 1)t}{T})$，将离散时间噪声预测模型转换为连续版本，其中$x \in \mathbb{R}^{d}$，$t \in [0, T]$。注意，$\tilde{\epsilon}_{\theta}$的输入时间可能不是整数，但我们发现噪声预测模型仍然能够很好地工作，我们推测这是因为平滑的时间嵌入（例如位置嵌入[2]）。通过这种重新参数化，噪声预测模型可以采用连续时间步作为输入，因此我们也可以使用DPM-Solver进行快速采样。</p>
<h3 id="4-与现有快速采样方法的比较"><a href="#4-与现有快速采样方法的比较" class="headerlink" title="4 与现有快速采样方法的比较"></a>4 与现有快速采样方法的比较</h3><p>在此，我们探讨DPM-Solver与现有的基于ODE的DPM快速采样方法之间的关系，并突出它们的差异。我们还将简要讨论无训练采样器相较于有训练采样器的优势。</p>
<h4 id="4-1-作为DPM-Solver-1的DDIM"><a href="#4-1-作为DPM-Solver-1的DDIM" class="headerlink" title="4.1 作为DPM-Solver-1的DDIM"></a>4.1 作为DPM-Solver-1的DDIM</h4><p>去噪扩散隐式模型（DDIM）[19]设计了一种用于从DPM快速采样的确定性方法。对于两个相邻的时间步$t_{i - 1}$和$t_{i}$，假设在时间$t_{i - 1}$我们有一个解$\tilde{x}_{t_{i - 1}}$，那么从时间$t_{i - 1}$到$t_{i}$的DDIM单步更新为：</p>
<script type="math/tex; mode=display">\overline{x}_{t_{i}}=\frac{\alpha_{t_{i}}}{\alpha_{t_{i - 1}}} \overline{x}_{t_{i - 1}}-\alpha_{t_{i}}\left(\frac{\sigma_{t_{i - 1}}}{\alpha_{t_{i - 1}}}-\frac{\sigma_{t_{i}}}{\alpha_{t_{i}}}\right) \epsilon_{\theta}\left(\overline{x}_{t_{i - 1}}, t_{i - 1}\right) 。</script><p>尽管动机完全不同，但我们发现DPM-Solver-1和去噪扩散隐式模型（DDIM）[19]的更新是相同的。根据$\lambda$的定义，我们有$\frac{\sigma_{t_{i - 1}}}{\alpha_{t_{i - 1}}}=e^{-\lambda_{t_{i - 1}}}$和$\frac{\sigma_{t_{i}}}{\alpha_{t_{i}}}=e^{-\lambda_{t_{i}}}$。将这些以及$h_{i}=\lambda_{t_{i}}-\lambda_{t_{i - 1}}$代入公式（4.1），得到的结果与公式（3.7）中DPM-Solver-1的一步更新完全一致。然而，DPM-Solver的半线性ODE公式允许有原则地推广到高阶求解器，并进行收敛阶分析。</p>
<p>最近的工作[13]也表明，通过对公式（4.1）两边求导，DDIM是扩散ODE的一阶离散化。然而，他们无法解释DDIM与扩散ODE的一阶欧拉离散化之间的差异。相比之下，通过证明DDIM是DPM-Solver的一个特殊情况，我们揭示了DDIM充分利用了扩散ODE的半线性，这解释了它相较于传统欧拉方法的优越性。</p>
<h4 id="4-2-与传统龙格-库塔方法的比较"><a href="#4-2-与传统龙格-库塔方法的比较" class="headerlink" title="4.2 与传统龙格 - 库塔方法的比较"></a>4.2 与传统龙格 - 库塔方法的比较</h4><p>通过将传统的显式龙格 - 库塔（RK）方法直接应用于公式（2.7）中的扩散ODE，可以得到一个高阶求解器。具体来说，RK方法将公式（2.7）的解写成以下积分形式：</p>
<script type="math/tex; mode=display">x_{t}=x_{s}+\int_{s}^{t} h_{\theta}\left(x_{\tau}, \tau\right) d \tau=x_{s}+\int_{s}^{t}\left(f(\tau) x_{\tau}+\frac{g^{2}(\tau)}{2 \sigma_{\tau}} \epsilon_{\theta}\left(x_{\tau}, \tau\right)\right) d \tau,</script><p>并在$[t, s]$之间使用一些中间时间步，结合$h_{\theta}$在这些时间步的评估值来近似整个积分。显式RK方法的近似误差取决于$h_{\theta}$，它包含了与线性项$f(\tau) x_{\tau}$和非线性噪声预测模型$\epsilon_{\theta}$相对应的误差。然而，由于线性项的精确解具有指数系数（如公式（3.1）所示），线性项的误差可能会呈指数增长。有许多经验证据[25, 31]表明，对于半线性ODEs，直接使用显式RK方法在大步长情况下可能会遇到数值不稳定问题。我们在5.1节中也展示了所提出的DPM-Solver与传统显式RK方法在经验上的差异，结果表明在相同阶数下，DPM-Solver的离散化误差比RK方法更小。</p>
<h4 id="4-3-基于训练的DPM快速采样方法"><a href="#4-3-基于训练的DPM快速采样方法" class="headerlink" title="4.3 基于训练的DPM快速采样方法"></a>4.3 基于训练的DPM快速采样方法</h4><p>需要额外训练或优化的采样器包括知识蒸馏[13, 14]、学习噪声水平或方差[15, 16, 33]以及学习噪声调度或样本轨迹[17, 18]。尽管渐进蒸馏方法[13]可以在4步内获得快速采样器，但它需要额外的训练成本，并且会丢失原始DPM中的部分信息（例如，蒸馏后，噪声预测模型无法预测$[0, T]$之间每个时间步的噪声（得分函数））。相比之下，无训练采样器可以保留原始模型的所有信息，从而可以通过将原始模型与外部分类器结合直接扩展到条件采样（例如，见附录D中带分类器引导的条件采样）。</p>
<p>除了直接为DPM设计快速采样器外，一些工作还提出了新型的DPM，以支持更快的采样。例如，为DPM定义低维潜在变量[34]；设计具有有界得分函数的特殊扩散过程[35]；将GAN与DPM的反向过程相结合[36]。所提出的DPM-Solver也可能适用于加速这些DPM的采样，我们将其留作未来的工作。</p>
<h3 id="5-实验"><a href="#5-实验" class="headerlink" title="5 实验"></a>5 实验</h3><p>在本节中，我们展示了作为一种无需训练的采样器，DPM - Solver（扩散概率模型求解器）能够显著加快现有预训练扩散概率模型（DPMs）的采样速度，这些模型既包括连续时间的，也包括离散时间的，并且涵盖了线性噪声调度[2, 19]和余弦噪声调度[16]。我们改变函数评估次数（NFE，即对噪声预测模型$\epsilon_{\theta}(x_{t}, t)$ 的调用次数），并比较DPM - Solver与其他方法生成样本的质量。在每个实验中，我们生成50000个样本，并使用广泛采用的弗雷歇初始距离（FID）分数[37]来评估样本质量，通常FID分数越低意味着样本质量越好。</p>
<p>除非另有明确说明，若函数评估次数（NFE）预算小于20，我们始终采用3.3节中结合均匀步长调度的求解器组合；否则，采用3.3节中结合自适应步长调度的三阶龙格 - 库塔扩散概率模型求解器（DPM - Solver - 3）。关于DPM - Solver的其他实现细节，请参见附录D，详细设置请参见附录E。</p>
<h4 id="5-1-与连续时间采样方法的比较"><a href="#5-1-与连续时间采样方法的比较" class="headerlink" title="5.1 与连续时间采样方法的比较"></a>5.1 与连续时间采样方法的比较</h4><p>我们首先将DPM-Solver与其他用于扩散概率模型（DPMs）的连续时间采样方法进行比较。对比的方法包括扩散随机微分方程（SDE）的欧拉-丸山离散化方法[3]、扩散SDE的自适应步长求解器[20]以及用于扩散常微分方程（ODE）的龙格-库塔（RK）方法[3, 28]（见公式(2.7)）。我们从在CIFAR-10数据集[29]上预训练的连续时间 “VP deep” 模型中进行采样，该模型采用线性噪声调度，以此来对比这些方法。</p>
<p>图2a展示了对比求解器的效率。对于使用欧拉离散化的扩散SDE，我们采用均匀时间步长，分别设置50、200、1000次函数评估（NFE）；对于自适应步长的SDE求解器[20]和RK45 ODE求解器[28]，我们通过调整容差超参数来控制NFE。DPM-Solver能够在约10次NFE内生成高质量样本，而其他求解器即使在50次NFE时仍有较大的离散化误差，这表明DPM-Solver相比之前最优的求解器实现了约5倍的加速。具体而言，我们在10次NFE时达到4.70的FID，12次NFE时为3.75，15次NFE时为3.24，20次NFE时为2.87，在CIFAR-10数据集上，这是最快的采样器。</p>
<p>作为一项消融研究，我们还对比了二阶和三阶的DPM-Solver与RK方法，结果见表1。我们对扩散ODE的RK方法分别基于时间t（公式(2.7)）和半对数信噪比λ（通过变量变换，详见附录E.1中的具体公式）进行比较。结果表明，在相同NFE的情况下，DPM-Solver生成的样本质量始终优于相同阶数的RK方法。DPM-Solver在15次NFE以下的少步采样场景中的卓越效率尤为明显，此时RK方法存在较大的离散化误差。这主要是因为DPM-Solver通过解析计算线性项，避免了相应的离散化误差。此外，更高阶的DPM-Solver-3比DPM-Solver-2收敛更快，这与定理3.2中的阶数分析相符。</p>
<h4 id="5-2-与离散时间采样方法的比较"><a href="#5-2-与离散时间采样方法的比较" class="headerlink" title="5.2 与离散时间采样方法的比较"></a>5.2 与离散时间采样方法的比较</h4><p>我们采用3.4节中的方法，将DPM-Solver应用于离散时间扩散概率模型（DPMs），随后将其与其他无需训练的离散时间采样器进行比较，这些采样器包括去噪扩散概率模型（DDPM）[2]、去噪扩散隐式模型（DDIM）[19]、解析去噪扩散概率模型（Analytic-DDPM）[21]、解析去噪扩散隐式模型（Analytic-DDIM）[21]、伪数值方法（PNDM）[22]、快速扩散概率模型采样（FastDPM）[38]以及伊藤 - 泰勒（Itô-Taylor）方法[24]。我们还与生成引导扩散模型（GGDM）[18]进行了对比，GGDM使用相同的预训练模型，但需要对采样轨迹进行进一步训练。我们通过将函数评估次数（NFE）从10变化到1000，来比较样本质量。</p>
<p>具体来说，我们使用文献[2]中通过$L_{simple }$训练的具有线性噪声调度的CIFAR-10数据集上的离散时间模型；文献[19]中具有线性噪声调度的CelebA 64x64数据集[39]上的离散时间模型；文献[16]中通过$L_{hybrid }$训练的具有余弦噪声调度的ImageNet 64x64数据集[26]上的离散时间模型；文献[4]中具有线性噪声调度和分类器引导的ImageNet 128x128数据集[26]上的离散时间模型；文献[4]中具有线性噪声调度的LSUN卧室256x256数据集[40]上的离散时间模型。对于在ImageNet上训练的模型，我们仅使用其 “均值” 模型，忽略 “方差” 模型。如图2所示，在所有数据集上，DPM-Solver能够在12步内获得质量合理的样本（CIFAR-10数据集上FID为4.65，CelebA 64x64数据集上为3.71，ImageNet 64x64数据集上为19.97，ImageNet 128x128数据集上为4.08），比之前最快的无需训练的采样器快4 - 16倍。DPM-Solver甚至优于需要额外训练的GGDM。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f2.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图2：使用不同采样方法从扩散概率模型（DPMs）中采样的样本质量，通过弗雷歇初始距离（FID）衡量。这些方法应用于CIFAR-10数据集上的连续时间和离散时间模型、CelebA 64x64数据集、ImageNet 64x64数据集、ImageNet 128x128数据集以及LSUN卧室256x256数据集的离散时间模型，并改变函数评估次数（NFE）。方法†GGDM [18] 需要额外训练以优化采样轨迹，而其他方法无需训练。为获得最强的基线结果，在CelebA数据集上对去噪扩散隐式模型（DDIM）使用二次步长，其FID比原始论文[19]中均匀步长的FID更优。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h3><p>我们解决了从扩散概率模型（DPMs）进行快速且无需训练的采样问题。我们提出了DPM-Solver，这是一种快速、专门用于求解扩散常微分方程（ODE）的无需训练的求解器，可在约10次函数评估步骤内实现对DPMs的快速采样。DPM-Solver利用了扩散ODE的半线性结构，直接逼近扩散ODE精确解的简化公式，该公式由噪声预测模型的指数加权积分构成。受指数积分器数值方法的启发，我们提出了一阶、二阶和三阶的DPM-Solver，以在理论上保证收敛的情况下逼近噪声预测模型的指数加权积分。我们提出了手动设定和自适应的步长调度，并将DPM-Solver应用于连续时间和离散时间的DPMs。我们的实验结果表明，DPM-Solver可以在各种数据集上，通过约10次函数评估生成高质量样本，与之前最先进的无需训练的采样器相比，实现了4 - 16倍的加速。</p>
<h4 id="局限性和更广泛的影响"><a href="#局限性和更广泛的影响" class="headerlink" title="局限性和更广泛的影响"></a>局限性和更广泛的影响</h4><p>尽管DPM-Solver在加速性能方面前景良好，但它是为快速采样而设计的，可能不适用于加速DPMs的似然评估。此外，与常用的生成对抗网络（GANs）相比，使用DPM-Solver的扩散模型在实时应用中仍然不够快。另外，与其他深度生成模型一样，DPMs可能被用于生成有害的虚假内容，而本文提出的求解器可能会进一步放大深度生成模型在恶意应用中的潜在不良影响。</p>
<h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><h3 id="3-扩散常微分方程的定制快速求解器-1"><a href="#3-扩散常微分方程的定制快速求解器-1" class="headerlink" title="3 扩散常微分方程的定制快速求解器"></a>3 扩散常微分方程的定制快速求解器</h3><h4 id="公式3-4的推导"><a href="#公式3-4的推导" class="headerlink" title="公式3.4的推导"></a>公式3.4的推导</h4><script type="math/tex; mode=display">
\begin{align*}
\mathbf{x}_t &= \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{s}^{t} \left( \frac{\mathrm{d}\lambda_{\tau}}{\mathrm{d}\tau} \right) \frac{\sigma_{\tau}}{\alpha_{\tau}} \epsilon_{\theta}(\mathbf{x}_{\tau}, \tau) \mathrm{d}\tau \\
&= \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} \left( \frac{\mathrm{d}\lambda_{\tau}}{\mathrm{d}\tau} \right) \frac{\sigma_{t_{\lambda}(\lambda)}}{\alpha_{t_{\lambda}(\lambda)}} \epsilon_{\theta}(\mathbf{x}_{t_{\lambda}(\lambda)}, t_{\lambda}(\lambda)) \frac{\mathrm{d}\tau}{\mathrm{d}\lambda} \mathrm{d}\lambda \\

&= \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} \frac{\sigma_{t_{\lambda}(\lambda)}}{\alpha_{t_{\lambda}(\lambda)}} \epsilon_{\theta}(\mathbf{x}_{t_{\lambda}(\lambda)}, t_{\lambda}(\lambda)) \mathrm{d}\lambda \\
&又 {\lambda_t} = \log{\frac{\alpha_t}{\sigma_t}}，得：\\
&= \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \hat{\epsilon}_{\theta}(\hat{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda
\end{align*}</script><h4 id="DPM-Solver-1"><a href="#DPM-Solver-1" class="headerlink" title="DPM-Solver-1"></a>DPM-Solver-1</h4><script type="math/tex; mode=display">x_t = \frac{\alpha_t}{\alpha_s}\mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \hat{\epsilon}_{\theta}(\hat{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda \tag{28}</script><p>由于通常的采样过程都是离散形式的，假设这个采样过程经过$M + 1$步完成，也即有$M + 1$个时间点序列$\{t_i\}_{i = 0}^M$，其中$t_0 = T$，$t_M = 0$，$t$随着$i$的增加严格单调递减。$M + 1$个时间点对应$M$个采样步骤，采样初始值$\tilde{x}_{t_0}=x_T$，采样终点$\tilde{x}_{t_M}$要尽可能的接近真实的解$x_0$。论文所有带波浪线上标的都是采样估计值，不带波浪线的都是真实值！有了上述假设，基于公式(28)就可以写出单步采样公式，形式如下：</p>
<script type="math/tex; mode=display">\mathbf{x}_{t_{i - 1} \to t_i} = \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}}\tilde{\mathbf{x}}_{t_{i - 1}} - \alpha_{t_i} \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_i}} e^{-\lambda} \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda \tag{29}</script><p>观察公式(29)，公式右边的第二部分，也即：</p>
<script type="math/tex; mode=display">\alpha_{t_i} \int_{\lambda_{t_{i - 1}}}^{\lambda_{t_i}} e^{-\lambda} \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda \tag{30}</script><p>这是一个对神经网络输出$\hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda)$的指数加权积分，还没有很好的求解计算手段。既然没办法直接求得精确值，我们的核心目标就是得到一个对于公式(30)的近似，这个近似可以通过代码实现且误差较小。好了，到目前为止有没有思路了，毫无头绪，但一想到近似，又不得不喊出我们心中的四字法则——泰勒救我！不失一般性，同时为了和论文附录的推导过程对应，这里还是令起点时间为$s$，终点时间为$t$，有$t &lt; s$，$\lambda_t &gt; \lambda_s$。试着对公式(30)中唯一的不稳定项$\hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda)$进行泰勒展开。在哪个点展开呢？记住已知点法则，很显然起始点$s$的信息是已知的，也即$\lambda_s$的信息是已知的，那我们就在该点展开$n$阶。注意，这里视$\hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda)$为$\lambda$的函数，泰勒展开中的导数项为全导数形式：</p>
<script type="math/tex; mode=display">\hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda) = \sum_{k = 0}^{n} \frac{(\lambda - \lambda_s)^k}{k!} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) + \mathcal{O}(h^{n + 1}) \tag{31}</script><p>其中，$h := \lambda_t - \lambda_s$，$\hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda}, \lambda)$是关于$\lambda$的$k$阶全导数，也即：</p>
<script type="math/tex; mode=display">\hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda}, \lambda) = \frac{\mathrm{d}^k \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda)}{\mathrm{d}\lambda^k} \tag{32}</script><p>公式(30)对应的指数加权积分是数学中研究的比较“透”的部分，为了更好的分析这个指数加权积分，定义：</p>
<script type="math/tex; mode=display">\varphi_k(z) := \int_{0}^{1} e^{(1 - \delta)z} \frac{\delta^{k - 1}}{(k - 1)!} \mathrm{d}\delta, \quad \varphi_0(z) = e^z \tag{33}</script><p>目前来看，这个式子并没有什么用处。别急，先把公式(31)的泰勒展开代入公式(30)中，同时替换积分上下限时间为$s$和$t$，有：</p>
<script type="math/tex; mode=display">
\alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \sum_{k = 0}^{n} \frac{(\lambda - \lambda_s)^k}{k!} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) \mathrm{d}\lambda + \mathcal{O}(h^{n + 2}) \tag{34}</script><p>这个形式有一部分就和公式(33)有点像了，很明显$\lambda - \lambda_s$好像就是$\delta$，但是积分上下限不满足，指数项也不同。论文令$h := \lambda_t - \lambda_s$，积分上下限调整可用换元法。假定$\lambda = \lambda_t + (\delta - 1)h$成立，当$\delta = 0$时，$\lambda = \lambda_t - h = \lambda_s$对应积分下限，当$\delta = 1$时，$\lambda = \lambda_t$对应积分上限，$\mathrm{d}\lambda = \mathrm{d}(\lambda_t + (\delta - 1)h) = h\mathrm{d}\delta$。由此可以完成积分换元，公式(34)可以变为：</p>
<script type="math/tex; mode=display">
\begin{align*}
&\alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \sum_{k = 0}^{n} \frac{(\lambda - \lambda_s)^k}{k!} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) \mathrm{d}\lambda + \mathcal{O}(h^{n + 2})\\
=&\alpha_t \int_{0}^{1} e^{-\lambda_t - (\delta - 1)h} \sum_{k = 0}^{n} \frac{(\delta h)^k}{k!} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) h\mathrm{d}\delta + \mathcal{O}(h^{n + 2})\\
=&\sum_{k = 0}^{n} \alpha_t e^{-\lambda_t} h^{k + 1} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) \int_{0}^{1} e^{(1 - \delta)h} \frac{\delta^k}{k!} \mathrm{d}\delta + \mathcal{O}(h^{n + 2})\\
=&\sum_{k = 0}^{n} \alpha_t \frac{\sigma_t}{\alpha_t} h^{k + 1} \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) \varphi_{k + 1}(h) + \mathcal{O}(h^{n + 2})\\
=&\sigma_t \sum_{k = 0}^{n} h^{k + 1} \varphi_{k + 1}(h) \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) + \mathcal{O}(h^{n + 2}) \tag{35}
\end{align*}</script><p>通过公式(35)能够发现定义(33)的巧妙用途。进一步的，$\varphi_k(h)$的解析形式是能写出来的，有：</p>
<script type="math/tex; mode=display">\varphi_1(h) = \frac{e^h - 1}{h} \tag{36}</script><script type="math/tex; mode=display">\varphi_2(h) = \frac{e^h - h - 1}{h^2} \tag{37}</script><script type="math/tex; mode=display">\varphi_3(h) = \frac{e^h - \frac{h^2}{2} - h - 1}{h^3} \tag{38}</script><p>上面三个式子如何获得？实际上就是对原始式子求积分得到，需要用到$\Gamma$函数的性质，在这里就不在赘述，大家就当已知量就好。</p>
<p>现在，将公式(35)代入公式(28)中，立即获得：</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbf{x}_t &= \frac{\alpha_t}{\alpha_s} \mathbf{x}_s - \alpha_t \int_{\lambda_s}^{\lambda_t} e^{-\lambda} \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda}, \lambda) \mathrm{d}\lambda\\
&= \frac{\alpha_t}{\alpha_s} \mathbf{x}_s - \sigma_t \sum_{k = 0}^{n} h^{k + 1} \varphi_{k + 1}(h) \hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) + \mathcal{O}(h^{n + 2}) \tag{39}
\end{align*}</script><p>公式(39)就是DPM Solver基于指数积分的数学性质得到的简化的迭代公式，最明显的特点是不再存在积分项，变成了对神经网络各阶导数$\hat{\epsilon}_\theta^{(k)}(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s)$的加权求和，同时由于采用求和近似积分，自然也有一定的精度损失，这个损失项是$h^{n + 2}$的同阶无穷小量。</p>
<p><strong>一阶DPM Solver采样公式推导</strong></p>
<p>前面都是准备工作，接下来我们首先讨论一阶公式情况，对于一阶情况，对应于公式(39)的$n = 0$。代入$n = 0$，有：</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbf{x}_t &= \frac{\alpha_t}{\alpha_s} \mathbf{x}_s - \sigma_t (e^h - 1) \hat{\epsilon}_\theta(\tilde{\mathbf{x}}_{\lambda_s}, \lambda_s) + \mathcal{O}(h^2) \tag{40}\\
&= \frac{\alpha_t}{\alpha_s} \mathbf{x}_s - \sigma_t (e^h - 1) \epsilon_\theta(\mathbf{x}_s, s) + \mathcal{O}(h^2) \tag{41}
\end{align*}</script><p>公式(41)和公式(40)等价，是因为$\lambda$和时间是一一对应关系，后面的推导都会混合用到这两种形式，大家重点就看时间点是什么，时间确定$\lambda$就确定，千万不要被这种形式的不同干扰迷惑，二者完全等价。对应于相邻两步的情况，公式(41)自然可以写为：</p>
<script type="math/tex; mode=display">
\mathbf{x}_{t_i} = \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} \mathbf{x}_{t_{i - 1}} - \sigma_t (e^{h_i} - 1) \epsilon_\theta(\mathbf{x}_{t_{i - 1}}, t_{i - 1}) + \mathcal{O}(h_i^2) \tag{42}</script><p>公式(42)没有带波浪线，就意味着$\mathbf{x}_{t_i}$和$\mathbf{x}_{t_{i - 1}}$都是精确值。然而，实际上这两个值都应该是数值计算的估计值，我们把$\mathbf{x}_{t_i}$和$\mathbf{x}_{t_{i - 1}}$分别用$\tilde{\mathbf{x}}_{t_i}$和$\tilde{\mathbf{x}}_{t_{i - 1}}$代替，有：</p>
<script type="math/tex; mode=display">
\begin{align*}
\tilde{\mathbf{x}}_{t_i} &= \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} \tilde{\mathbf{x}}_{t_{i - 1}} - \sigma_t (e^{h_i} - 1) \epsilon_\theta(\tilde{\mathbf{x}}_{t_{i - 1}}, t_{i - 1})\\
&= \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} \tilde{\mathbf{x}}_{t_{i - 1}} - \sigma_t (e^{h_i} - 1) \underbrace{(\epsilon_\theta(\mathbf{x}_{t_{i - 1}}, t_{i - 1}) + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}}))}_{\text{Taylor Expansion/Lipschitz(利普希茨)}}\\
&= \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} (\mathbf{x}_{t_{i - 1}} + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}})) - \sigma_t (e^{h_i} - 1) \epsilon_\theta(\mathbf{x}_{t_{i - 1}}, t_{i - 1}) + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}})\\
&= \frac{\alpha_{t_i}}{\alpha_{t_{i - 1}}} \mathbf{x}_{t_{i - 1}} - \sigma_t (e^{h_i} - 1) \epsilon_\theta(\mathbf{x}_{t_{i - 1}}, t_{i - 1}) + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}})\\
&= \mathbf{x}_{t_{i - 1}} + \mathcal{O}(h_i^2) + \mathcal{O}(\tilde{\mathbf{x}}_{t_{i - 1}} - \mathbf{x}_{t_{i - 1}}) \tag{43}
\end{align*}</script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/Analytic-DPM-an-Analytic-Estimate-of-the-Optimal-Reverse-Variance-in-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Analytic-DPM an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-12 19:33:01 / 修改时间：20:53:14" itemprop="dateCreated datePublished" datetime="2025-03-12T19:33:01+08:00">2025-03-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>扩散概率模型（Diffusion Probabilistic Models, DPMs）是一类强大的生成模型。尽管它们取得了成功，但DPMs的推理成本很高，因为通常需要迭代数千个时间步。推理中的一个关键问题是估计反向过程中每个时间步的方差。在这项工作中，我们给出了一个令人惊讶的结果：DPM的最优反向方差和相应的最优KL散度都可以用其得分函数的解析形式表示。在此基础上，我们提出了Analytic-DPM，这是一个无需训练的推理框架，它使用蒙特卡罗方法和预训练的基于得分的模型来估计方差和KL散度的解析形式。此外，为了纠正基于得分的模型可能带来的偏差，我们推导了最优方差的上下界，并对估计值进行裁剪以获得更好的结果。在实验中，我们的Analytic-DPM提高了各种DPM的对数似然性，生成了高质量的样本，同时实现了20到80倍的加速。</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h3><p>扩散过程会在一系列时间步中逐渐向数据分布添加噪声。通过学习逆向操作，扩散概率模型（DPMs）（Sohl-Dickstein等人，2015；Ho等人，2020；Song等人，2020b）定义了一种数据生成过程。最近研究表明，DPMs能够生成高质量样本（Ho等人，2020；Nichol和Dhariwal，2021；Song等人，2020b；Dhariwal和Nichol，2021），这些样本与当前最先进的生成对抗网络（GAN）模型（Goodfellow等人，2014；Brock等人，2018；Wu等人，2019；Karras等人，2020b）相当，甚至更优。</p>
<p>尽管取得了成功，但DPMs的推理（如采样和密度评估）通常需要迭代数千个时间步，这比其他生成模型（如GANs）慢两到三个数量级（Song等人，2020a）。推理中的一个关键问题是估计反向过程中每个时间步的方差。大多数先前的工作在所有时间步都使用手工设定的值，这通常需要运行很长的链才能获得合理的样本和密度值（Nichol和Dhariwal，2021）。Nichol和Dhariwal（2021）试图通过在反向过程中学习方差网络来提高采样效率。然而，它仍然需要相对较长的轨迹才能获得合理的对数似然（见Nichol和Dhariwal（2021）的附录E）。</p>
<p>在这项工作中，我们给出了一个令人惊讶的结果：DPM的最优反向方差和相应的最优KL散度都可以用其得分函数（即对数密度的梯度）的解析形式表示。在此基础上，我们提出了Analytic-DPM，这是一个无需训练的推理框架，用于在实现可比甚至更优性能的同时提高预训练DPM的效率。Analytic-DPM使用蒙特卡罗方法和预训练DPM中的基于得分的模型来估计方差和KL散度的解析形式。相应的轨迹通过动态规划算法（Watson等人，2021）计算。此外，为了纠正基于得分的模型可能导致的潜在偏差，我们推导出最优方差的上下界，并对估计值进行裁剪以获得更好的结果。最后，我们揭示了得分函数与数据协方差矩阵之间的有趣关系。</p>
<p>Analytic-DPM以即插即用的方式适用于多种DPM（Ho等人，2020；Song等人，2020a；Nichol和Dhariwal，2021）。在实验中，Analytic-DPM持续提高这些DPM的对数似然，同时实现20到40倍的加速。此外，Analytic-DPM还持续提高去噪扩散隐式模型（DDIMs）（Song等人，2020a）的样本质量，并且最多需要50个时间步（与完整时间步相比，加速20到80倍）就能达到与相应基线相当的弗雷歇 inception距离（FID） 。</p>
<h3 id="2-背景"><a href="#2-背景" class="headerlink" title="2. 背景"></a>2. 背景</h3><p>扩散概率模型（DPMs）首先构建一个正向过程$q(x_{1:N}|x_{0})$，向数据分布$q(x_{0})$中注入噪声，然后逆向这个正向过程来恢复数据。给定正向噪声调度$\beta_{n} \in (0,1)$（$n = 1,\cdots,N$），去噪扩散概率模型（DDPMs）（Ho等人，2020）考虑一个马尔可夫正向过程：</p>
<script type="math/tex; mode=display">q_{M}(x_{1:N}|x_{0})=\prod_{n = 1}^{N}q_{M}(x_{n}|x_{n - 1}),q_{M}(x_{n}|x_{n - 1})=\mathcal{N}(x_{n}|\sqrt{\alpha_{n}}x_{n - 1},\beta_{n}I), \tag{1}</script><p>其中$I$是单位矩阵，$\alpha_{n}$和$\beta_{n}$是标量，且$\alpha_{n}:=1 - \beta_{n}$。Song等人（2020a）引入了一种更一般的非马尔可夫过程，由非负向量$\lambda = (\lambda_{1},\cdots,\lambda_{N}) \in \mathbb{R}_{\geq0}^{N}$索引：</p>
<script type="math/tex; mode=display">q_{\lambda}(x_{1:N}|x_{0})=q_{\lambda}(x_{N}|x_{0})\prod_{n = 2}^{N}q_{\lambda}(x_{n - 1}|x_{n},x_{0}), \tag{2}</script><script type="math/tex; mode=display">q_{\lambda}(x_{N}|x_{0})=\mathcal{N}(x_{N}|\sqrt{\overline{\alpha}_{N}}x_{0},\overline{\beta}_{N}I),</script><script type="math/tex; mode=display">\tilde{\mu}_{n}(x_{n},x_{0})=\sqrt{\overline{\alpha}_{n - 1}}x_{0}+\sqrt{\overline{\beta}_{n - 1}-\lambda_{n}^{2}}\cdot\frac{x_{n}-\sqrt{\overline{\alpha}_{n}}x_{0}}{\sqrt{\overline{\beta}}_{n}},</script><script type="math/tex; mode=display">q_{\lambda}(x_{n - 1}|x_{n},x_{0})=\mathcal{N}(x_{n - 1}|\tilde{\mu}_{n}(x_{n},x_{0}),\lambda_{n}^{2}I),</script><p>这里$\overline{\alpha}_{n}:=\prod_{i = 1}^{n}\alpha_{i}$，$\overline{\beta}_{n}:=1-\overline{\alpha}_{n}$。实际上，当$\lambda_{n}^{2}=\tilde{\beta}_{n}$时，公式（2）包含了DDPM的正向过程作为一个特殊情况，其中$\tilde{\beta}_{n}:=\frac{\overline{\beta}_{n - 1}}{\overline{\beta}_{n}}\beta_{n}$。公式（2）的另一个特殊情况是去噪扩散隐式模型（DDIM）的正向过程，其中$\lambda_{n}^{2}=0$。此外，我们还可以进一步推导出$q_{\lambda}(x_{n}|x_{0})=\mathcal{N}(x_{n}|\sqrt{\overline{\alpha}_{n}}x_{0},\overline{\beta}_{n}I)$，它与$\lambda$无关。在本文的其余部分，我们将重点关注公式（2）中的正向过程，因为它更具一般性，为了简单起见，我们将省略索引$\lambda$，并将其表示为$q(x_{1:N}|x_{0})$。</p>
<p>公式（2）的反向过程被定义为一个马尔可夫过程，旨在通过从标准高斯分布$p(x_{N})=\mathcal{N}(x_{N}|\overline{0},I)$逐渐去噪来逼近$q(x_{0})$：</p>
<script type="math/tex; mode=display">p(x_{0:N})=p(x_{N})\prod_{n = 1}^{N}p(x_{n - 1}|x_{n}),p(x_{n - 1}|x_{n})=\mathcal{N}(x_{n - 1}|\mu_{n}(x_{n}),\sigma_{n}^{2}I),</script><p>其中$\mu_{n}(x_{n})$通常由一个与时间相关的基于得分的模型$s_{n}(x_{n})$（Song和Ermon，2019；Song等人，2020b）参数化：</p>
<script type="math/tex; mode=display">\mu_{n}(x_{n})=\overline{\mu}_{n}(x_{n},\frac{1}{\sqrt{\overline{\alpha}_{n}}}(x_{n}+\overline{\beta}_{n}s_{n}(x_{n}))). \tag{3}</script><script type="math/tex; mode=display">L_{vb}=\mathbb{E}_{q}[- \log p(x_{0}|x_{1})+\sum_{n = 2}^{N}D_{KL}(q(x_{n - 1}|x_{0},x_{n})||p(x_{n - 1}|x_{n}))+D_{KL}(q(x_{N}|x_{0})||p(x_{N}))],</script><p>反向过程可以通过优化负对数似然的变分下界$L_{vb}$来学习：<br>1 Ho等人（2020）；Song等人（2020a）用$\tilde{\mu}_{n}(x_{n},\frac{1}{\sqrt{\alpha_{n}}}(x_{n}-\sqrt{\overline{\beta}_{n}}\epsilon_{n}(x_{n})))$对$\mu_{n}(x_{n})$进行参数化，通过令$s_{n}(x_{n})=-\frac{1}{\sqrt{\overline{\beta}_{n}}}\epsilon_{n}(x_{n})$，这与公式（3）等价。<br>这等价于优化正向过程和反向过程之间的KL散度：</p>
<script type="math/tex; mode=display">\min_{\{\mu_{n},\sigma_{n}^{2}\}_{n = 1}^{N}}L_{vb}\Leftrightarrow\min_{\{\mu_{n},\sigma_{n}^{2}\}_{n = 1}^{N}}D_{KL}(q(x_{0:N})||p(x_{0:N})). \tag{4}</script><p>在实际应用中，为了提高样本质量，Ho等人（2020）没有直接优化$L_{vb}$，而是考虑了$L_{vb}$的一个重新加权变体来学习$s_{n}(x_{n})$：</p>
<script type="math/tex; mode=display">\min_{\{s_{n}\}_{n = 1}^{N}}\mathbb{E}_{n}\overline{\beta}_{n}\mathbb{E}_{q_{n}(x_{n})}||s_{n}(x_{n})-\nabla_{x_{n}}\log q_{n}(x_{n})||^{2}=\mathbb{E}_{n,x_{0},\epsilon}||\epsilon+\sqrt{\beta_{n}}s_{n}(x_{n})||^{2}+c, \tag{5}</script><p>其中$n$在$1$到$N$之间均匀分布，$q_{n}(x_{n})$是正向过程在时间步$n$的边际分布，$\epsilon$是标准高斯噪声，等式右边的$x_{n}$通过$x_{n}=\sqrt{\overline{\alpha}_{n}}x_{0}+\sqrt{\overline{\beta}_{n}}\epsilon$进行重参数化，$c$是一个仅与$q$相关的常数。实际上，公式（5）正是得分匹配目标（Song和Ermon，2019）的加权和，它对于所有$n \in \{1,2,\cdots,N\}$都有一个最优解$s_{n}^{*}(x_{n})=\nabla_{x_{n}}\log q_{n}(x_{n})$。<br>注意，公式（5）没有为方差$\sigma_{n}^{2}$提供学习信号。实际上，在大多数先前的工作中，$\sigma_{n}^{2}$通常是手工设定的。在DDPMs（Ho等人，2020）中，两种常用的设置是$\sigma_{n}^{2}=\beta_{n}$和$\sigma_{n}^{2}=\tilde{\beta}_{n}$。在DDIMs中，Song等人（2020a）始终使用$\sigma_{n}^{2}=\lambda_{n}^{2}$。我们认为，这些手工设定的值通常不是公式（4）的真正最优解，会导致次优的性能。</p>
<h3 id="3-最优反向方差的解析估计"><a href="#3-最优反向方差的解析估计" class="headerlink" title="3. 最优反向方差的解析估计"></a>3. 最优反向方差的解析估计</h3><p>对于一个DPM，我们首先证明，式（4）的最优均值<script type="math/tex">\mu_{n}^{*}(x_{n})</script>和最优方差<script type="math/tex">\sigma_{n}^{*2}</script>都可以用得分函数的解析形式表示，这在定理1中进行了总结。</p>
<p><strong>定理1</strong>（式（4）最优解的得分表示，证明见附录A.2）。式（4）的最优解<script type="math/tex">\mu_{n}^{*}(x_{n})</script>和<script type="math/tex">\sigma_{n}^{*2}</script>为：</p>
<script type="math/tex; mode=display">\mu_{n}^{*}\left(x_{n}\right)=\tilde{\mu}_{n}\left(x_{n}, \frac{1}{\sqrt{\overline{\alpha}_{n}}}\left(x_{n}+\overline{\beta}_{n} \nabla_{x_{n}} log q_{n}\left(x_{n}\right)\right)\right), \tag{6}</script><script type="math/tex; mode=display">\sigma_{n}^{*2}=\lambda_{n}^{2}+\left(\sqrt{\frac{\overline{\beta}_{n}}{\alpha_{n}}}-\sqrt{\overline{\beta}_{n-1}-\lambda_{n}^{2}}\right)^{2}\left(1-\overline{\beta}_{n} \mathbb{E}_{q_{n}\left(x_{n}\right)} \frac{\left\| \nabla_{x_{n}} log q_{n}\left(x_{n}\right)\right\| ^{2}}{d}\right), \tag{7}</script><p>其中$q_{n}(x_{n})$是正向过程在时间步$n$的边际分布，$d$是数据的维度。</p>
<p>定理1的证明包含三个关键步骤：</p>
<ul>
<li>第一步（见引理9）称为矩匹配（Minka，2013），它表明在KL散度下用高斯密度逼近任意密度，等同于将两个密度的前两阶矩设置为相同。据我们所知，矩匹配与DPM之间的联系此前尚未被揭示。</li>
<li>第二步（见引理13），我们仔细利用以$x_{0}$为条件的总方差定律，将$q(x_{n - 1}|x_{n})$的二阶矩转换为$q(x_{0}|x_{n})$的二阶矩。</li>
<li>第三步（见引理11），我们意外地发现$q(x_{0}|x_{n})$的二阶矩可以用得分函数表示，然后将得分表示代入$q(x_{n - 1}|x_{n})$的二阶矩中，从而得到定理1中的最终结果。</li>
</ul>
<p>定理1中的结果（以及后面出现的其他结果）对于DDPM正向过程（即$\lambda_{n}^{2}=\tilde{\beta}_{n}$）可以进一步简化，详细内容见附录D。此外，我们还可以将定理1扩展到具有连续时间步的DPM（Song等人，2020b；Kingma等人，2021），在这种情况下，它们相应的最优均值和方差也可以由得分函数以解析形式确定（扩展内容见附录E.1）。</p>
<p>注意，我们在式（6）中最优均值$\mu_{n}^{*}(x_{n})$的解析形式，与之前（Ho等人，2020）在式（3）中对$\mu_{n}(x_{n})$的参数化形式是一致的。唯一的区别在于，式（3）用基于得分的模型$s_{n}(x_{n})$，替代了式（6）中的得分函数$\nabla_{x_{n}} log q_{n}(x_{n})$ 。这一结果明确表明，式（5）在本质上与$L_{vb}$目标具有相同的最优均值解，为先前的研究提供了一种简单且不同的视角。</p>
<p>与（Ho等人，2020；Song等人，2020a）中使用的手工设定策略不同，定理1表明，在给定预训练的基于得分的模型$s_{n}(x_{n})$的情况下，最优反向方差$\sigma_{n}^{*2}$也可以在无需任何额外训练的情况下进行估计。实际上，我们首先通过$\Gamma = (\Gamma_{1}, \cdots, \Gamma_{N})$来估计$\nabla_{x_{n}} log q_{n}(x_{n})$的期望均方范数，其中：</p>
<script type="math/tex; mode=display">\Gamma_{n}=\frac{1}{M} \sum_{m=1}^{M} \frac{\left\| s_{n}\left(x_{n, m}\right)\right\| ^{2}}{d}, x_{n, m} \stackrel{i i d}{\sim} q_{n}\left(x_{n}\right). \tag{8}</script><p>$M$是蒙特卡罗样本的数量。对于一个预训练模型，我们只需要计算一次$\Gamma$，并在下游计算中重复使用它（关于$\Gamma$计算成本的详细讨论见附录H.1）。然后，根据式（7），我们按如下方式估计$\sigma_{n}^{*2}$：</p>
<script type="math/tex; mode=display">\hat{\sigma}_{n}^{2}=\lambda_{n}^{2}+\left(\sqrt{\frac{\overline{\beta}_{n}}{\alpha_{n}}}-\sqrt{\overline{\beta}_{n-1}-\lambda_{n}^{2}}\right)^{2}\left(1-\overline{\beta}_{n} \Gamma_{n}\right). \tag{9}</script><p>我们通过实验验证了定理1。在图1（a）中，我们绘制了在CIFAR10上训练的DDPM的解析估计值$\hat{\sigma}_{n}^{2}$，以及Ho等人（2020）使用的基线$\beta_{n}$和$\tilde{\beta}_{n}$。在较小的时间步长下，这些策略的表现有所不同。图1（b）表明，对于$L_{vb}$的每一项，我们的$\hat{\sigma}_{n}^{2}$都优于基线，尤其是在较小的时间步长下。我们在其他数据集上也得到了类似的结果（见附录G.1）。此外，我们发现，只需少量的蒙特卡罗（MC）样本（例如，$M = 10, 100$），就足以使蒙特卡罗方法带来的方差足够小，并且能够获得与大量样本（大$M$）相似的性能（见附录G.2）。我们还在附录H.2中讨论了插入$\hat{\sigma}_{n}^{2}$后$L_{vb}$的随机性。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f1.png" alt="f1"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图1：比较我们的解析估计值$\hat{\sigma}_{n}^{2}$与先前工作中手工设定的方差$\beta_{n}$和$\tilde{\beta}_{n}$ 。(a)比较了不同时间步长下的方差值。(b)比较了$L_{vb}$中每个时间步长对应的项。$L_{vb}$的值是相应曲线下的面积。</em></td>
</tr>
</tbody>
</table>
</div>
<h4 id="3-1-界定最优反向方差以减少偏差"><a href="#3-1-界定最优反向方差以减少偏差" class="headerlink" title="3.1 界定最优反向方差以减少偏差"></a>3.1 界定最优反向方差以减少偏差</h4><p>根据式（7）和式（9），解析估计值$\hat{\sigma}_{n}^{2}$的偏差为：</p>
<script type="math/tex; mode=display">\left|\sigma_{n}^{* 2}-\hat{\sigma}_{n}^{2}\right|=\underbrace{\left(\sqrt{\frac{\overline{\beta}_{n}}{\alpha_{n}}}-\sqrt{\overline{\beta}_{n-1}-\lambda_{n}^{2}}\right)^{2} \overline{\beta}_{n}}_{系数} \underbrace{\left|\Gamma_{n}-\mathbb{E}_{q_{n}\left(x_{n}\right)} \frac{\left|\nabla_{x_{n}} log q_{n}\left(x_{n}\right)\right|^{2}}{d}\right|}_{近似误差}. \tag{10}</script><p>我们对方差的估计使用了基于得分的模型$s_{n}(x_{n})$来近似真实的得分函数$\nabla_{x_{n}} log q_{n}(x_{n})$。因此，对于一个预训练模型，式（10）中的近似误差是不可避免的。同时，如果我们使用更短的轨迹进行采样（详见第4节），式（10）中的系数可能会很大，这可能会导致较大的偏差。</p>
<p>为了减少偏差，我们推导了最优反向方差<script type="math/tex">\sigma_{n}^{*2}</script>的上下界，并根据这些界限对估计值进行裁剪。重要的是，这些界限与数据分布$q(x_{0})$无关，因此可以高效地计算。我们首先在不做任何数据假设的情况下，推导出<script type="math/tex">\sigma_{n}^{*2}</script>的上下界。然后，如果数据分布有界，我们展示了<script type="math/tex">\sigma_{n}^{*2}</script>的另一个上界。我们在定理2中正式给出这些界限。</p>
<p><strong>定理2</strong>（最优反向方差的界限，证明见附录A.3）。$\sigma_{n}^{*2}$具有以下上下界：</p>
<script type="math/tex; mode=display">\lambda_{n}^{2} \leq \sigma_{n}^{*2} \leq \lambda_{n}^{2}+\left(\sqrt{\frac{\overline{\beta}_{n}}{\alpha_{n}}}-\sqrt{\overline{\beta}_{n-1}-\lambda_{n}^{2}}\right)^{2}. \tag{11}</script><p>如果我们进一步假设$q(x_{0})$是在$[a, b]^{d}$上的有界分布，其中$d$是数据的维度，那么$\sigma_{n}^{_2}$可以进一步被上界约束为：</p>
<script type="math/tex; mode=display">\sigma_{n}^{*2} \leq \lambda_{n}^{2}+\left(\sqrt{\overline{\alpha}_{n-1}}-\sqrt{\overline{\beta}_{n-1}-\lambda_{n}^{2}} \cdot \sqrt{\frac{\overline{\alpha}_{n}}{\overline{\beta}_{n}}}\right)^{2}\left(\frac{b - a}{2}\right)^{2}. \tag{12}</script><p>定理2表明，先前工作（Ho等人，2020；Song等人，2020a）中手工设定的反向方差$\lambda_{n}^{2}$低估了$\sigma_{n}^{*2}$。例如，在DDPM中$\lambda_{n}^{2}=\tilde{\beta}_{n}$。我们在图1（a）中将其与我们的估计值进行比较，结果与定理2一致。此外，$q(x_{0})$的有界性假设在包括图像生成建模在内的许多场景中都成立，式（11）和式（12）中的哪个上界更紧取决于$n$。因此，我们根据最小的上界对估计值进行裁剪。此外，我们在附录G.3中通过数值方法展示了这些界限是紧密的。</p>
<h3 id="4-最优轨迹的解析估计"><a href="#4-最优轨迹的解析估计" class="headerlink" title="4. 最优轨迹的解析估计"></a>4. 最优轨迹的解析估计</h3><p>完整时间步长$N$的数量可能很大，这使得实际推理过程较为缓慢。因此，我们可以构建一个更短的正向过程$q(x_{\tau_{1}},\cdots,x_{\tau_{K}}|x_{0})$，该过程受限于由$K$个时间步组成的轨迹$1 = \tau_{1}&lt;\cdots&lt;\tau_{K}=N$（Song等人，2020a；Nichol和Dhariwal，2021；Watson等人，2021），$K$可以远小于$N$，从而加快推理速度。正式地，较短的过程定义为$q(x_{\tau_{1}},\cdots,x_{\tau_{K}}|x_{0}) = q(x_{\tau_{K}}|x_{0})\prod_{k = 2}^{K}q(x_{\tau_{k - 1}}|x_{\tau_{k}},x_{0})$，其中：</p>
<script type="math/tex; mode=display">q(x_{\tau_{k - 1}}|x_{\tau_{k}},x_{0})=\mathcal{N}(x_{\tau_{k - 1}}|\tilde{\mu}_{\tau_{k - 1}|\tau_{k}}(x_{\tau_{k}},x_{0}),\lambda_{\tau_{k - 1}|\tau_{k}}^{2}I), \tag{13}</script><script type="math/tex; mode=display">\tilde{\mu}_{\tau_{k - 1}|\tau_{k}}(x_{\tau_{k}},x_{0})=\sqrt{\overline{\alpha}_{\tau_{k - 1}}}x_{0}+\sqrt{\overline{\beta}_{\tau_{k - 1}}-\lambda_{\tau_{k - 1}|\tau_{k}}^{2}}\cdot\frac{x_{\tau_{k}}-\sqrt{\overline{\alpha}_{\tau_{k}}}x_{0}}{\sqrt{\overline{\beta}_{\tau_{k}}}}.</script><p>相应的反向过程为$p(x_{0},x_{\tau_{1}},\cdots,x_{\tau_{K}})=p(x_{\tau_{K}})\prod_{k = 1}^{K}p(x_{\tau_{k - 1}}|x_{\tau_{k}})$，其中：</p>
<script type="math/tex; mode=display">p(x_{\tau_{k - 1}}|x_{\tau_{k}})=\mathcal{N}(x_{\tau_{k - 1}}|\mu_{\tau_{k - 1}|\tau_{k}}(x_{\tau_{k}}),\sigma_{\tau_{k - 1}|\tau_{k}}^{2}I).</script><p>根据定理1，在KL散度最小化的意义下，最优<script type="math/tex">p^{*}(x_{\tau_{k - 1}}|x_{\tau_{k}})</script>的均值和方差为：</p>
<script type="math/tex; mode=display">\mu_{\tau_{k - 1}|\tau_{k}}^{*}(x_{\tau_{k}})=\tilde{\mu}_{\tau_{k - 1}|\tau_{k}}(x_{\tau_{k}},\frac{1}{\sqrt{\overline{\alpha}_{\tau_{k}}}}(x_{\tau_{k}}+\overline{\beta}_{\tau_{k}}\nabla_{x_{\tau_{k}}}\log q(x_{\tau_{k}}))),</script><script type="math/tex; mode=display">\sigma_{\tau_{k - 1}|\tau_{k}}^{*2}=\lambda_{\tau_{k - 1}|\tau_{k}}^{2}+(\sqrt{\frac{\overline{\beta}_{\tau_{k}}}{\alpha_{\tau_{k}|\tau_{k - 1}}}}-\sqrt{\overline{\beta}_{\tau_{k - 1}}-\lambda_{\tau_{k - 1}|\tau_{k}}^{2}})^{2}(1-\overline{\beta}_{\tau_{k}}\mathbb{E}_{q(x_{\tau_{k}})}\frac{\|\nabla_{x_{\tau_{k}}}\log q(x_{\tau_{k}})\|^{2}}{d}),</script><p>其中$\alpha_{\tau_{k}|\tau_{k - 1}}:=\overline{\alpha}_{\tau_{k}}/\overline{\alpha}_{\tau_{k - 1}}$。根据定理2，我们可以推导出<script type="math/tex">\sigma_{\tau_{k - 1}|\tau_{k}}^{*2}</script>的类似界限（详见附录C）。与式（9）类似，<script type="math/tex">\sigma_{\tau_{k - 1}|\tau_{k}}^{*2}</script>的估计值为：</p>
<script type="math/tex; mode=display">\hat{\sigma}_{\tau_{k - 1}|\tau_{k}}^{2}=\lambda_{\tau_{k - 1}|\tau_{k}}^{2}+(\sqrt{\frac{\overline{\beta}_{\tau_{k}}}{\alpha_{\tau_{k}|\tau_{k - 1}}}}-\sqrt{\overline{\beta}_{\tau_{k - 1}}-\lambda_{\tau_{k - 1}|\tau_{k}}^{2}})^{2}(1-\overline{\beta}_{\tau_{k}}\Gamma_{\tau_{k}}),</script><p>其中$\Gamma$在式（8）中定义，并且可以在不同的轨迹选择中共享。基于上述最优反向过程$p^{*}$，我们进一步优化轨迹：</p>
<script type="math/tex; mode=display">\min_{\tau_{1},\cdots,\tau_{K}}D_{KL}(q(x_{0},x_{\tau_{1}},\cdots,x_{\tau_{K}})\|p^{*}(x_{0},x_{\tau_{1}},\cdots,x_{\tau_{K}}))=\frac{d}{2}\sum_{k = 2}^{K}J(\tau_{k - 1},\tau_{k})+c, \tag{14}</script><p>其中$J(\tau_{k - 1},\tau_{k})=\log(\sigma_{\tau_{k - 1}|\tau_{k}}^{*2}/\lambda_{\tau_{k - 1}|\tau_{k}}^{2})$，$c$是与轨迹$\tau$无关的常数（证明见附录A.4）。式（14）中的KL散度可以分解为$K - 1$项，并且每一项都可以用得分函数的解析形式表示。我们将每一项视为在$(\tau_{k - 1},\tau_{k})$处评估的成本函数$J$，并且在给定$\Gamma$的情况下，它可以通过$J(\tau_{k - 1},\tau_{k})\approx\log(\hat{\sigma}_{\tau_{k - 1}|\tau_{k}}^{2}/\lambda_{\tau_{k - 1}|\tau_{k}}^{2})$有效地估计，这不需要任何神经网络计算。虽然对数函数即使在已知正确得分函数的情况下也会引入偏差，但可以通过增加$M$来减小偏差。</p>
<p>结果，式（14）简化为一个有向图上的经典最小成本路径问题（Watson等人，2021），其中节点为$\{1,2,\cdots,N\}$，从$s$到$t$的边的成本为$J(s,t)$。我们想要找到一条从1开始并终止于$N$的$K$个节点的最小成本路径。这个问题可以通过Watson等人（2021）引入的动态规划（DP）算法来解决。我们在附录B中给出了该算法。此外，我们还可以将式（14）扩展到具有连续时间步的DPM（Song等人，2020b；Kingma等人，2021），在这种情况下，它们相应的最优KL散度也可以分解为由得分函数确定的项。因此，DP算法同样适用。扩展内容见附录E.2。</p>
<h3 id="5-得分函数与数据协方差矩阵之间的关系"><a href="#5-得分函数与数据协方差矩阵之间的关系" class="headerlink" title="5. 得分函数与数据协方差矩阵之间的关系"></a>5. 得分函数与数据协方差矩阵之间的关系</h3><p>在这部分内容中，我们进一步揭示得分函数与数据协方差矩阵之间的关系。实际上，数据协方差矩阵可以分解为$\mathbb{E}_{q(x_{n})}Cov_{q(x_{0}|x_{n})}[x_{0}]$与$Cov_{q(x_{n})}\mathbb{E}_{q(x_{0}|x_{n})}[x_{0}]$之和，其中第一项可以用得分函数表示。此外，当$n$足够大时，由于$x_{0}$和$x_{n}$几乎相互独立，第二项可以忽略不计。在这种情况下，数据协方差矩阵几乎由得分函数决定。目前，这种关系仅停留在理论层面，其实际意义尚不清楚。详细内容见附录A.5。</p>
<h3 id="6-实验"><a href="#6-实验" class="headerlink" title="6. 实验"></a>6. 实验</h3><p>我们考虑DDPM正向过程（$\lambda_{n}^{2}=\tilde{\beta}_{n}$）和DDIM正向过程（$\lambda_{n}^{2}=0$），这是公式（2）最常用的两个特殊情况。我们将使用解析估计$\sigma_{n}^{2}=\hat{\sigma}_{n}^{2}$的方法称为Analytic-DPM，并根据所使用的正向过程明确地将其称为Analytic-DDPM或Analytic-DDIM。我们将我们的Analytic-DPM与原始DDPM（Ho等人，2020）进行比较，原始DDPM的反向方差为$\sigma_{n}^{2}=\tilde{\beta}_{n}$或$\sigma_{n}^{2}=\beta_{n}$，同时也与原始DDIM（Song等人，2020a）进行比较，原始DDIM的反向方差为$\sigma_{n}^{2}=\lambda_{n}^{2}=0$。</p>
<p>我们为Analytic-DPM和基线模型采用两种方法来获取轨迹。第一种是均匀轨迹（Even Trajectory，ET）（Nichol和Dhariwal，2021），其中时间步根据固定步长确定（详见附录F.4）。第二种是最优轨迹（Optimal Trajectory，OT）（Watson等人，2021），其中时间步通过动态规划计算（见第4节）。注意，基线模型基于带有手工设定方差的$L_{vb}$来计算OT（Watson等人，2021）。</p>
<p>我们将Analytic-DPM应用于先前工作提供的三个预训练基于得分的模型（Ho等人，2020；Song等人，2020a；Nichol和Dhariwal，2021），以及我们自己训练的两个基于得分的模型。预训练的基于得分的模型分别在CelebA 64x64（Liu等人，2015）、ImageNet 64x64（Deng等人，2009）和LSUN Bedroom（Yu等人，2015）上进行训练。我们的基于得分的模型在CIFAR10（Krizhevsky等人，2009）上使用两种不同的正向噪声调度进行训练：线性调度（Linear Schedule，LS）（Ho等人，2020）和余弦调度（Cosine Schedule，CS）（Nichol和Dhariwal，2021）。我们分别将它们表示为CIFAR10（LS）和CIFAR10（CS）。对于ImageNet 64x64，完整时间步的数量$N$为4000，对于其他数据集为1000。在采样过程中，我们按照Ho等人（2020）的方法，仅显示$p(x_{0}|x_{1})$的均值并丢弃噪声，并且我们对表2中比较的所有方法额外裁剪$p(x_{1}|x_{2})$的噪声尺度$\sigma_{2}$（详见附录F.2及其在附录G.4中的消融研究）。更多实验细节见附录F。</p>
<p>我们进行了广泛的实验，以证明Analytic-DPM可以在提高预训练DPM推理效率的同时，实现可比甚至更优的性能。具体来说，6.1节和6.2节分别展示了似然性和样本质量的结果。附录G中提供了消融研究等其他实验。</p>
<h4 id="6-1-似然性结果"><a href="#6-1-似然性结果" class="headerlink" title="6.1 似然性结果"></a>6.1 似然性结果</h4><p>由于在DDIM正向过程中$\lambda_{n}^{2}=0$，其变分下界$L_{vb}$是无穷大的。因此，我们仅考虑DDPM正向过程下的似然性结果。如表1所示，在所有三个数据集上，我们的Analytic-DPM使用ET和OT都一致地提高了原始DDPM的似然性结果。值得注意的是，使用更短的轨迹（即更少的推理时间），带有OT的Analytic-DPM仍然可以超越基线模型。在表1中，我们选择使Analytic-DPM能够超越具有完整时间步的基线模型的最小$K$，并对相应结果加下划线。具体而言，Analytic-DPM在CIFAR10（LS）和ImageNet 64x64上实现了40倍的加速，在CIFAR10（CS）和CelebA 64x64上实现了20倍的加速。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t1.png" alt="t1"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表1：DDPM正向过程下的负对数似然（比特/维度）。我们展示了不同时间步数量K的轨迹下的结果。我们选择使得Analytic-DPM能够超越具有完整时间步的基线模型的最小K值，并对相应结果加下划线。</em></td>
</tr>
</tbody>
</table>
</div>
<p>虽然我们主要关注选择反向方差的无学习策略，但我们也与另一个强大的基线模型进行了比较，该基线模型通过神经网络预测方差（Nichol和Dhariwal，2021）。在使用完整时间步的情况下，Analytic-DPM在ImageNet 64x64上实现了3.61的负对数似然（NLL），与Nichol和Dhariwal（2021）中报告的3.57非常接近。此外，虽然Nichol和Dhariwal（2021）报告说ET会大幅降低他们的神经网络参数化方差的对数似然性能，但Analytic-DPM在使用ET时表现良好。详见附录G.6。</p>
<h4 id="6-2-样本质量"><a href="#6-2-样本质量" class="headerlink" title="6.2 样本质量"></a>6.2 样本质量</h4><p>至于样本质量，我们考虑常用的弗雷歇初始距离（Frechet Inception Distance，FID）分数（Heusel等人，2017），分数越低表示样本质量越好。如表2所示，在不同$K$的轨迹下，我们的Analytic-DDIM一致地提高了原始DDIM的样本质量。这使我们能够在少于50个时间步内生成高质量样本，与完整时间步相比，实现了20到80倍的加速。实际上，在大多数情况下，Analytic-DDIM最多只需要50个时间步就能获得与基线相似的性能。此外，Analytic-DDPM在大多数情况下也提高了原始DDPM的样本质量。为了公平起见，我们对表2中的所有结果都使用了Nichol和Dhariwal（2021）中的ET实现。我们还在附录G.7中报告了使用Song等人（2020a）中略微不同的ET实现对CelebA 64x64的结果，我们的Analytic-DPM仍然有效。我们在附录G.9中展示了生成的样本。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t2.png" alt="t2"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表2：DDPM和DDIM正向过程下的弗雷歇初始距离（FID）。所有结果均在均匀轨迹（ET）下进行评估。带有†的结果略优于Ho等人（2020）报告的3.17，这是因为我们采用了Nichol和Dhariwal（2021）改进后的模型架构。</em></td>
</tr>
</tbody>
</table>
</div>
<p>我们观察到，在FID指标下，Analytic-DDPM并不总是优于基线模型，这与表1中的似然性结果不一致。这种现象本质上源于这两个指标的不同性质，并且在许多先前的工作中已有研究（Theis等人，2015；Ho等人，2020；Nichol和Dhariwal，2021；Song等人，2021；Vahdat等人，2021；Watson等人，2021；Kingma等人，2021）。同样，使用更多的时间步并不一定能获得更好的FID。例如，见表2中CIFAR10（LS）上的Analytic-DDPM结果和ImageNet 64x64上的DDIM结果。在Nichol和Dhariwal（2021）的图8中也观察到了类似的现象。此外，带有OT的DPM（包括Analytic-DPM）并不一定能获得更好的FID分数（Watson等人，2021）（见附录G.5中Analytic-DPM中ET和OT的比较）。</p>
<p>我们在表3中总结了不同方法的效率，其中我们将达到FID约为6所需的最少时间步作为指标，以便进行更直接的比较。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t3.png" alt="t3"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表3：效率对比，基于达到FID约为6所需的最少时间步数（以及相应的FID）。为获得最强的基线结果，带有†的结果是通过使用Song等人（2020a）的二次轨迹而非默认的均匀轨迹得到的。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="7-相关工作"><a href="#7-相关工作" class="headerlink" title="7. 相关工作"></a>7. 相关工作</h3><ul>
<li><strong>DPMs及其应用</strong>：扩散概率模型（DPM）最初由Sohl-Dickstein等人（2015）提出，通过优化变分下界$L_{vb}$进行训练。Ho等人（2020）提出了DPMs的新参数化形式（公式3），并使用$L_{vb}$的重新加权变体（公式5）来学习DPMs。Song等人（2020b）将添加噪声的正向过程建模为随机微分方程（SDE），并引入了具有连续时间步的DPMs。随着这些重要改进，DPMs在各种应用中展现出巨大潜力，包括语音合成（Chen等人，2020；Kong等人，2020；Popov等人，2021；Lam等人，2021）、可控生成（Choi等人，2021；Sinha等人，2021）、图像超分辨率（Saharia等人，2021；Li等人，2021）、图像到图像转换（Sasaki等人，2021）、形状生成（Zhou等人，2021）和时间序列预测（Rasul等人，2021）。</li>
<li><strong>更快的DPMs</strong>：一些研究试图在保持DPM性能的同时找到短轨迹。Chen等人（2020）通过网格搜索找到了仅六个时间步的有效轨迹。然而，由于网格搜索的时间复杂度呈指数增长，它仅适用于非常短的轨迹。Watson等人（2021）将轨迹搜索建模为最小成本路径问题，并引入动态规划（DP）算法来解决该问题。我们的工作使用了这种DP算法，其中成本被定义为最优KL散度的一项。除了这些轨迹搜索技术，Luhman和Luhman（2021）将反向去噪过程压缩为单步模型；San-Roman等人（2021）在推理过程中动态调整轨迹。这两种方法在获得预训练的DPM后都需要额外的训练。对于具有连续时间步的DPMs（Song等人，2020b），Song等人（2020b）引入了常微分方程（ODE），提高了采样效率并实现了精确的似然计算。然而，似然计算涉及随机迹估计器，需要多次运行才能准确计算。Jolicoeur-Martineau等人（2021）引入了一种先进的SDE求解器，以更高效的方式模拟反向过程。然而，基于该求解器的对数似然计算并未明确说明。</li>
<li><strong>DPMs中的方差学习</strong>：除了反向方差，也有研究致力于学习正向噪声调度（即正向方差）。Kingma等人（2021）提出了连续时间步上的变分扩散模型（VDMs），它使用信噪比函数对正向方差进行参数化，并直接优化变分下界目标以获得更好的对数似然。虽然我们主要将方法应用于DDPMs和DDIMs，但估计最优反向方差也可应用于VDMs（见附录E）。</li>
</ul>
<h3 id="8-结论"><a href="#8-结论" class="headerlink" title="8. 结论"></a>8. 结论</h3><p>我们证明了扩散概率模型的最优反向方差和相应的最优KL散度都可以用其得分函数的解析形式表示。在此基础上，我们提出了Analytic-DPM，这是一个无需训练的推理框架，它利用蒙特卡罗方法和预训练的基于得分的模型来估计方差和KL散度的解析形式。我们推导了最优方差的边界以纠正潜在偏差，并揭示了得分函数与数据协方差矩阵之间的关系。在实验中，我们的Analytic-DPM提高了多种扩散概率模型在似然结果方面的效率和性能，并且能高效生成高质量样本。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/Understanding-Diffusion-Models-A-Unified-Perspective%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/Understanding-Diffusion-Models-A-Unified-Perspective%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Understanding Diffusion Models: A Unified Perspective论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-12 16:44:25" itemprop="dateCreated datePublished" datetime="2025-03-12T16:44:25+08:00">2025-03-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-14 10:42:26" itemprop="dateModified" datetime="2025-03-14T10:42:26+08:00">2025-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="引言：生成模型"><a href="#引言：生成模型" class="headerlink" title="引言：生成模型"></a>引言：生成模型</h3><p>给定来自目标分布的观测样本x，生成模型的目标是学习对其真实数据分布$p(x)$进行建模。一旦完成学习，我们就可以根据需要从近似模型中生成新样本。此外，在某些公式中，我们还可以使用所学模型来评估观测数据或生成数据的似然性。</p>
<p>当前文献中有几个著名的研究方向，我们将仅在较高层次上简要介绍。生成对抗网络（GANs）对复杂分布的采样过程进行建模，这种建模是通过对抗方式学习的。另一类生成模型被称为“基于似然的”，旨在学习一个为观测数据样本分配高似然的模型。这包括自回归模型、归一化流和变分自编码器（VAEs）。另一种类似的方法是基于能量的建模，其中分布被学习为一个任意灵活的能量函数，然后进行归一化。</p>
<p>分数生成模型与之高度相关；它们不是直接学习对能量函数本身进行建模，而是通过神经网络学习基于能量模型的分数。在本文中，我们将探讨并回顾扩散模型，正如我们将展示的那样，扩散模型同时具有基于似然和基于分数的解释。我们将极其详细地展示这些模型背后的数学原理，旨在让任何人都能理解扩散模型是什么以及它们的工作原理。</p>
<h3 id="背景：证据下界、变分自编码器和分层变分自编码器"><a href="#背景：证据下界、变分自编码器和分层变分自编码器" class="headerlink" title="背景：证据下界、变分自编码器和分层变分自编码器"></a>背景：证据下界、变分自编码器和分层变分自编码器</h3><p>对于许多模态，我们可以认为所观察到的数据是由一个相关的不可见潜在变量表示或生成的，我们用随机变量$z$来表示这个潜在变量。表达这一概念的最佳直观方式是通过柏拉图的洞穴寓言。在这个寓言中，一群人一生都被锁在洞穴里，只能看到投射在他们面前墙壁上的二维影子，这些影子是由在火前经过的不可见三维物体产生的。对于这些人来说，他们所观察到的一切实际上是由他们永远无法看到的更高维抽象概念所决定的。</p>
<p>类似地，我们在现实世界中遇到的物体也可能是由一些更高级的表示生成的；例如，这些表示可以封装颜色、大小、形状等抽象属性。那么，我们所观察到的可以被解释为这些抽象概念的三维投影或实例化，就像洞穴里的人所观察到的实际上是三维物体的二维投影一样。虽然洞穴里的人永远无法看到（甚至完全理解）隐藏的物体，但他们仍然可以对其进行推理和推断；同样，我们可以近似描述所观察数据的潜在表示。</p>
<p>柏拉图的洞穴寓言说明了潜在变量作为决定观察结果的潜在不可观察表示的概念，但这个类比的一个局限性是，在生成建模中，我们通常寻求学习低维潜在表示，而不是高维表示。这是因为在没有强先验的情况下，尝试学习比观察结果维度更高的表示是徒劳的。另一方面，学习低维潜在表示也可以被视为一种压缩形式，并且有可能揭示描述观察结果的语义有意义的结构。</p>
<h4 id="证据下界"><a href="#证据下界" class="headerlink" title="证据下界"></a>证据下界</h4><p>从数学角度来看，我们可以将潜在变量和观察到的数据想象为由联合分布$p(x,z)$建模。回想一下，生成建模的一种方法，即 “基于似然” 的方法，是学习一个模型来最大化所有观察到的x的似然$p(x)$。我们有两种方法可以处理这个联合分布，以得到纯粹观察数据的似然$p(x)$：我们可以明确地对潜在变量$z$进行边缘化：</p>
<script type="math/tex; mode=display">p(x)=\int p(x,z)dz \tag{1}</script><p>或者，我们也可以利用概率的链式法则：</p>
<script type="math/tex; mode=display">p(x)=\frac{p(x,z)}{p(z|x)} \tag{2}</script><p>直接计算并最大化似然$p(x)$是困难的，因为这要么涉及在公式（1）中对所有潜在变量$z$进行积分，对于复杂模型来说这是难以处理的；要么在公式（2）中需要访问真实的潜在编码器$p(z|x)$。然而，利用这两个公式，我们可以推导出一个称为证据下界（ELBO）的项，正如其名称所示，它是证据的下界。在这种情况下，证据被量化为观察数据的对数似然。因此，最大化ELBO成为优化潜在变量模型的替代目标；在理想情况下，当ELBO被强大地参数化并完美优化时，它与证据完全等价。正式地，ELBO的公式为：</p>
<script type="math/tex; mode=display">\mathbb{E}_{q_{\phi}(z|x)}\left[\log \frac{p(x,z)}{q_{\phi}(z|x)}\right] \tag{3}</script><p>为了明确与证据的关系，我们可以用数学公式表示为：</p>
<script type="math/tex; mode=display">\log p(x) \geq \mathbb{E}_{q_{\phi}(z|x)}\left[\log \frac{p(x,z)}{q_{\phi}(z|x)}\right]\tag{4}</script><p>这里，$q_{\phi}(z|x)$是一个灵活的近似变分分布，其参数为$\phi$，我们试图对其进行优化。直观地说，它可以被认为是一个可参数化的模型，用于估计给定观察值x时潜在变量的真实分布；换句话说，它试图逼近真实后验分布$p(z|x)$。正如我们在探索变分自编码器时将会看到的，通过调整参数$\phi$来最大化ELBO，从而提高下界，我们能够获得可用于对真实数据分布进行建模并从中采样的组件，进而学习一个生成模型。现在，让我们更深入地探究为什么ELBO是我们想要最大化的目标。</p>
<p>让我们从推导ELBO开始，使用公式（1）：</p>
<script type="math/tex; mode=display">
\begin{align*}
\log p(x) &= \log \int p(x,z) dz & & (应用公式1) \tag{5}\\
&= \log \int \frac{p(x,z)q_{\phi}(z|x)}{q_{\phi}(z|x)} dz & & (乘以1=\frac{q_{\phi}(z|x)}{q_{\phi}(z|x)}) \tag{6}\\
&= \log \mathbb{E}_{q_{\phi}(z|x)}\left[\frac{p(x,z)}{q_{\phi}(z|x)}\right] & & (期望的定义) \tag{7}\\
&\geq \mathbb{E}_{q_{\phi}(z|x)}\left[\log \frac{p(x,z)}{q_{\phi}(z|x)}\right] & & (应用詹森不等式) \tag{8}
\end{align*}</script><p>在这个推导中，我们通过应用詹森不等式直接得到了下界。然而，这并没有为我们提供太多关于底层实际情况的有用信息；关键的是，这个证明没有直观地解释为什么ELBO实际上是证据的下界，因为詹森不等式只是一笔带过。此外，仅仅知道ELBO确实是数据的下界，并不能真正告诉我们为什么要将其作为目标进行最大化。为了更好地理解证据和ELBO之间的关系，让我们进行另一种推导，这次使用公式（2）：</p>
<script type="math/tex; mode=display">
\begin{align*}
\log p(x) &= \log p(x)\int q_{\phi}(z|x)dz & (乘以1=\int q_{\phi}(z|x)dz)\\
&= \int q_{\phi}(z|x)(\log p(x))dz & & (将证据放入积分中)\\
&= E_{q_{\phi}(x|x)}[\log p(x)] & (期望的定义)\\
&= \mathbb{E}_{q_{\phi}(x|x)}\left[\log \frac{p(z,z)}{p(z|x)}\right] & (应用公式2)\\
&= \mathbb{E}_{q_{\phi}(x|x)}\left[\log \frac{p(x,z)q_{\phi}(z|x)}{p(z|x)}\right] & (乘以1=\frac{q_{\phi}(z|x)}{q_{\phi}(z|x)})\\
&= \mathbb{E}_{q_{\phi}(z|x)}\left[\log \frac{p(x,z)}{q_{\phi}(z|x)}\frac{p(z|x)}{p(z|x)}\right] + D_{KL}(q_{\phi}(z|x)||p(z|x)) & (拆分期望)\\
&= \mathbb{E}_{q_{\phi}(x|x)}\left[\log \frac{p(z,z)}{q_{\phi}(z|x)}\right] + D_{KL}(q_{\phi}(z|x)||p(z|x)) & (化简)
\end{align*}</script><p>从这个推导中，我们从公式（15）清楚地观察到，证据等于ELBO加上近似后验分布$q_{\phi}(z|x)$和真实后验分布$p(z|x)$之间的KL散度。事实上，在第一次推导的公式（8）中，正是这个KL散度项被詹森不等式神奇地消除了。理解这个项不仅是理解ELBO和证据之间关系的关键，也是理解为什么优化ELBO是一个合适目标的关键。</p>
<p>首先，我们现在知道为什么ELBO确实是一个下界：证据和ELBO之间的差异是一个严格非负的KL项，因此ELBO的值永远不会超过证据。<br><img src="https://pic1.zhimg.com/v2-8757675769575957959_b.jpg" alt="图1：变分自编码器的图形表示"><br><em>图1：变分自编码器的图形表示。这里，编码器$q(z|x)$为观察值x定义了潜在变量z的分布，$p(x|z)$将潜在变量解码为观察值</em></p>
<p>其次，我们探究为什么要最大化ELBO。在引入了我们想要建模的潜在变量z之后，我们的目标是学习描述观察数据的潜在结构。换句话说，我们希望优化变分后验分布$q_{\phi}(z|x)$的参数，使其与真实后验分布$p(z|x)$完全匹配，这可以通过最小化它们的KL散度（理想情况下为零）来实现。不幸的是，直接最小化这个KL散度项是难以处理的，因为我们无法访问真实的$p(z|x)$分布。然而，请注意，在公式（15）的左侧，数据的似然（因此我们的证据项$\log p(x)$）相对于$\phi$始终是一个常数，因为它是通过对联合分布$p(x,z)$中的所有潜在变量z进行边缘化计算得到的，与$\phi$无关。由于ELBO和KL散度项的和是一个常数，任何相对于$\phi$对ELBO项的最大化必然会导致对KL散度项的等量最小化。因此，最大化ELBO可以作为学习如何完美建模真实潜在后验分布的替代方法；我们对ELBO的优化越多，我们的近似后验分布就越接近真实后验分布。此外，一旦训练完成，ELBO也可以用于估计观察到的数据或生成数据的似然，因为它是为了逼近模型证据$\log p(x)$而学习的。</p>
<h4 id="变分自编码器"><a href="#变分自编码器" class="headerlink" title="变分自编码器"></a>变分自编码器</h4><p>在变分自编码器（VAE）的默认公式中，我们直接最大化ELBO。这种方法是变分的，因为我们在由$\phi$参数化的一系列潜在后验分布中优化出最佳的$q_{\phi}(z|x)$。它被称为自编码器，是因为它让人联想到传统的自编码器模型，在该模型中，输入数据经过中间瓶颈表示步骤后被训练来预测自身。为了更清楚地说明这种联系，让我们进一步剖析ELBO项：</p>
<script type="math/tex; mode=display">
\begin{align*}
\mathbb{E}_{q_{\phi}(z|x)}\left[\log \frac{p(x,z)}{q_{\phi}(z|x)}\right] &= \mathbb{E}_{q_{\phi}(z|x)}\left[\log \frac{p_{\theta}(x|z)p(z)}{q_{\phi}(z|x)}\right] & & (概率链式法则)\\
&= \mathbb{E}_{q_{\phi}(z|x)}\left[\log p_{\theta}(x|z)\right] + \mathbb{E}_{q_{\phi}(z|x)}\left[\log \frac{p(z)}{q_{\phi}(z|x)}\right] & (拆分期望)\\
&= \underbrace{\mathbb{E}_{q_{\phi}(z|x)}\left[\log p_{\theta}(x|z)\right]}_{重构项} - \underbrace{D_{KL}(q_{\phi}(z|x)||p(z))}_{先验匹配项} & (KL散度的定义)
\end{align*}</script><p>在这种情况下，我们学习一个中间瓶颈分布$q_{\phi}(z|x)$，它可以被视为一个编码器；它将输入转换为潜在变量的分布。同时，我们学习一个确定性函数$p_{\theta}(x|z)$，将给定的潜在向量z转换为观察值x，这可以被解释为一个解码器。</p>
<p>公式（19）中的两项都有直观的解释：第一项衡量解码器从我们的变分分布中重构的似然性；这确保了学习到的分布正在对有效的潜在变量进行建模，以便可以从这些潜在变量中再生原始数据。第二项衡量学习到的变分分布与对潜在变量的先验信念的相似程度。最小化这项鼓励编码器实际学习一个分布，而不是坍缩为狄拉克δ函数。因此，最大化ELBO相当于最大化其第一项并最小化其第二项。</p>
<p>VAE的一个显著特点是如何联合优化参数$\phi$和$\theta$来最大化ELBO。VAE的编码器通常被选择为对具有对角协方差的多元高斯分布进行建模，而先验通常被选择为标准多元高斯分布：</p>
<script type="math/tex; mode=display">q_{\phi}(z|x)=\mathcal{N}(z;\mu_{\phi}(x),\sigma_{\phi}^{2}(x)I) \tag{20}</script><script type="math/tex; mode=display">p(z)=\mathcal{N}(z;0,I) \tag{21}</script><p>然后，ELBO的KL散度项可以通过解析计算，重构项可以使用蒙特卡罗估计进行近似。我们的目标可以重写为：</p>
<script type="math/tex; mode=display">\underset{\phi,\theta}{arg \max} \mathbb{E}_{q_{\phi}(z|x)}\left[\log p_{\theta}(x|z)\right] - D_{KL}(q_{\phi}(z|x)||p(z)) \approx \underset{\phi,\theta}{arg \max} \sum_{l=1}^{L} \log p_{\theta}(x|z^{(l)}) - D_{KL}(q_{\phi}(z|x)||p(z))</script><p>其中，潜在变量$\{z^{(l)}\}_{l = 1}^{L}$是从$q_{\phi}(z|x)$中采样得到的，对于数据集中的每个观察值x都是如此。然而，在这个默认设置中出现了一个问题：我们计算损失所依据的每个$z^{(l)}$都是通过随机采样过程生成的，而这个过程通常是不可微的。幸运的是，当$q_{\phi}(z|x)$被设计为对某些分布进行建模时，包括多元高斯分布，可以通过重参数化技巧来解决这个问题。</p>
<p>重参数化技巧将一个随机变量重写为一个噪声变量的确定性函数；这允许通过梯度下降来优化非随机项。例如，从均值为$\mu$、方差为$\sigma^{2}$的正态分布$x \sim N(x;\mu,\sigma^{2})$中采样可以重写为：</p>
<script type="math/tex; mode=display">x = \mu + \sigma\epsilon \text{ ，其中 } \epsilon \sim \mathcal{N}(\epsilon;0,I)</script><p>换句话说，任意高斯分布可以被解释为标准高斯分布（$\epsilon$是其样本），其均值通过加法从0移动到目标均值$\mu$，方差通过目标方差$\sigma^{2}$进行拉伸。因此，通过重参数化技巧，从任意高斯分布中采样可以通过从标准高斯分布中采样、将结果按目标标准差缩放并按目标均值移动来实现。</p>
<p>在VAE中，每个$z$因此被计算为输入x和辅助噪声变量$\epsilon$的确定性函数：</p>
<script type="math/tex; mode=display">z = \mu_{\phi}(x) + \sigma_{\phi}(x) \odot \epsilon \text{ ，其中 } \epsilon \sim \mathcal{N}(\epsilon;0,I)</script><p>其中$\odot$表示逐元素相乘。在这种重参数化的$z$版本下，可以根据需要计算关于$\phi$的梯度，以优化$\mu_{\phi}$和$\sigma_{\phi}$。因此，VAE利用重参数化技巧和蒙特卡罗估计来联合优化$\phi$和$\theta$以最大化ELBO。</p>
<p>训练完VAE后，可以通过直接从潜在空间$p(z)$中采样，然后将其通过解码器来生成新数据。当$z$的维度小于输入$x$的维度时，变分自编码器特别有趣，因为我们可能正在学习紧凑、有用的表示。此外，当学习到一个语义有意义的潜在空间时，可以在将潜在向量传递给解码器之前对其进行编辑，以更精确地控制生成的数据。</p>
<h4 id="分层变分自编码器"><a href="#分层变分自编码器" class="headerlink" title="分层变分自编码器"></a>分层变分自编码器</h4><p>分层变分自编码器（HVAE）是VAE的一种推广，它扩展到潜在变量的多个层次。在这种公式下，潜在变量本身被解释为由其他更高级、更抽象的潜在变量生成。直观地说，就像我们将观察到的三维物体视为由更高级的抽象潜在变量生成一样，柏拉图洞穴中的人将三维物体视为生成他们二维观察结果的潜在变量。因此，从柏拉图洞穴居民的角度来看，他们的观察结果可以被视为由深度为二（或更多）的潜在层次结构建模。</p>
<p>在具有T个层次的一般HVAE中，每个潜在变量都可以依赖于所有先前的潜在变量，在本文中，我们关注一个特殊情况，称为马尔可夫HVAE（MHVAE）。在MHVAE中，生成过程是一个马尔可夫链；也就是说，层次结构中的每次转换都是马尔可夫的，解码每个潜在变量$z_{t}$仅依赖于前一个潜在变量$z_{t + 1}$。直观地说，从视觉上看，这可以看作是简单地将VAE堆叠在一起，如图2所示；描述这个模型的另一个合适术语是递归VAE。在数学上，我们将马尔可夫HVAE的联合分布和后验表示为：</p>
<script type="math/tex; mode=display">p(x,z_{1:T}) = p(z_{T})p_{\theta}(x|z_{1})\prod_{t = 2}^{T}p_{\theta}(z_{t - 1}|z_{t})</script><script type="math/tex; mode=display">q_{\phi}(z_{1:T}|x) = q_{\phi}(z_{1}|x)\prod_{t = 2}^{T}q_{\phi}(z_{t}|z_{t - 1}) \tag{24}</script><p>然后，我们可以很容易地将ELBO扩展为：</p>
<script type="math/tex; mode=display">
\begin{align*}
\log p(x) &= \log \int p(x,z_{1:T})dz_{1:T} & & (应用公式1)\\
&= \log \int \frac{p(x,z_{1:T})q_{\phi}(z_{1:T}|x)}{q_{\phi}(z_{1:T}|x)}dz_{1:T} & & (乘以1=\frac{q_{\phi}(z_{1:T}|x)}{q_{\phi}(z_{1:T}|x)})\\
&= \log \mathbb{E}_{q_{\phi}(z_{1:T}|x)}\left[\frac{p(x,z_{1:T})}{q_{\phi}(z_{1:T}|x)}\right] & & (期望的定义)\\
&\geq \mathbb{E}_{q_{\phi}(z_{1:T}|x)}\left[\log \frac{p(x,z_{1:T})}{q_{\phi}(z_{1:T}|x)}\right] & & (应用詹森不等式)
\end{align*}</script><p>然后，我们可以将联合分布（公式23）和后验（公式24）代入公式28，得到另一种</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/12/FLOW-MATCHING-FOR-GENERATIVE-MODELING%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/12/FLOW-MATCHING-FOR-GENERATIVE-MODELING%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">FLOW MATCHING FOR GENERATIVE MODELING论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-12 15:37:40 / 修改时间：16:22:45" itemprop="dateCreated datePublished" datetime="2025-03-12T15:37:40+08:00">2025-03-12</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>我们提出了一种基于连续归一化流（CNFs）的生成式建模新范式，使我们能够以前所未有的规模训练CNFs。具体来说，我们提出了流匹配（FM）的概念，这是一种无需模拟的训练CNFs的方法，它基于对固定条件概率路径的向量场进行回归。流匹配与用于在噪声和数据样本之间进行转换的一般高斯概率路径族兼容，现有扩散路径是其中的特定实例。有趣的是，我们发现将FM与扩散路径结合使用，为训练扩散模型提供了一种更强大、更稳定的替代方法。此外，流匹配为使用其他非扩散概率路径训练CNFs开辟了道路。特别值得关注的一个实例是使用最优传输（OT）位移插值来定义条件概率路径。这些路径比扩散路径更高效，训练和采样速度更快，泛化性能也更好。在ImageNet数据集上使用流匹配训练CNFs，在似然性和样本质量方面均优于基于扩散的替代方法，并且使用现成的数值常微分方程（ODE）求解器就能快速可靠地生成样本。</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h3><p>深度生成模型是一类深度学习算法，旨在从未知数据分布中进行估计和采样。近年来，生成式建模取得了惊人的进展，例如在图像生成领域（Ramesh等人，2022；Rombach等人，2022），这主要得益于基于扩散的模型（Ho等人，2020；Song等人，2020b）可扩展且相对稳定的训练。然而，由于局限于简单的扩散过程，采样概率路径的空间相当有限，导致训练时间极长，并且需要采用专门的方法（例如Song等人，2020a；Zhang和Chen，2022）来进行高效采样。</p>
<p>在这项工作中，我们考虑连续归一化流（CNFs；Chen等人，2018）这一通用且确定性的框架。CNFs能够对任意概率路径进行建模，尤其值得注意的是，它涵盖了扩散过程所建模的概率路径（Song等人，2021）。然而，除了可以通过例如去噪得分匹配（Vincent，2011）进行有效训练的扩散模型外，目前还没有可扩展的CNF训练算法。实际上，最大似然训练（例如Grathwohl等人，2018）需要进行昂贵的数值ODE模拟，而现有的无模拟方法要么涉及难以处理的积分（Rozen等人，2021），要么存在有偏差的梯度（Ben-Hamu等人，2022）。</p>
<p>这项工作的目标是提出流匹配（FM），这是一种高效的无模拟方法，用于训练CNF模型，使得可以采用通用概率路径来指导CNF训练。重要的是，FM打破了除扩散之外可扩展CNF训练的障碍，并且无需考虑扩散过程，直接处理概率路径。</p>
<p>特别是，我们提出了流匹配目标（第3节），这是一个简单直观的训练目标，用于回归到生成所需概率路径的目标向量场。我们首先展示了可以通过逐样本（即条件）公式来构建这样的目标向量场。然后，受去噪得分匹配的启发，我们表明一种称为条件流匹配（CFM）的逐样本训练目标能提供等效的梯度，并且不需要明确知道难以处理的目标向量场。此外，我们讨论了可用于流匹配的一般逐样本概率路径族（第4节），现有扩散路径是该族的特殊实例。即使在扩散路径上，我们发现使用FM也能提供更强大、更稳定的训练，并且与得分匹配相比，性能更优。此外，这个概率路径族还包括一个特别有趣的情况：对应于最优传输（OT）位移插值的向量场（McCann，1997）。我们发现条件OT路径比扩散路径更简单，形成直线轨迹，而扩散路径则形成曲线。这些特性在实验中似乎转化为更快的训练速度、更快的生成速度和更好的性能。</p>
<p>我们在ImageNet上通过实验验证了流匹配以及基于最优传输路径的构建，ImageNet是一个大型且多样性高的图像数据集。我们发现，在与基于扩散的竞争方法的比较中，我们能够轻松训练模型，在似然估计和样本质量方面都取得良好的性能。此外，我们发现与先前的方法相比，我们的模型在计算成本和样本质量之间实现了更好的平衡。图1展示了从我们模型中选取的无条件ImageNet 128×128样本。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f1.png" width="70%" height="70%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图1：使用基于最优传输概率路径的流匹配方法训练的连续归一化流（CNF）生成的无条件ImageNet - 128样本。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="2-预备知识：连续归一化流"><a href="#2-预备知识：连续归一化流" class="headerlink" title="2 预备知识：连续归一化流"></a>2 预备知识：连续归一化流</h3><p>设$\mathbb{R}^{d}$表示数据空间，数据点$x = (x^{1}, \ldots, x^{d}) \in \mathbb{R}^{d}$。本文中使用的两个重要概念是：概率密度路径$p: [0, 1] \times \mathbb{R}^{d} \to \mathbb{R}_{&gt;0}$，它是一个随时间变化的概率密度函数，即$\int p_{t}(x)dx = 1$；以及一个随时间变化的向量场$v: [0, 1] \times \mathbb{R}^{d} \to \mathbb{R}^{d}$。向量场$v_{t}$可用于构建一个随时间变化的微分同胚映射，称为流（flow）$\phi: [0, 1] \times \mathbb{R}^{d} \to \mathbb{R}^{d}$，其由常微分方程（ODE）定义：</p>
<script type="math/tex; mode=display">\frac{d}{dt} \phi_{t}(x) = v_{t}(\phi_{t}(x)) \tag{1}</script><script type="math/tex; mode=display">\phi_{0}(x) = x \tag{2}</script><p>此前，Chen等人（2018）提出用神经网络$v_{t}(x; \theta)$对向量场$v_{t}$进行建模，其中$\theta \in \mathbb{R}^{p}$是其可学习参数，这进而产生了一个关于流$\phi_{t}$的深度参数化模型，称为连续归一化流（Continuous Normalizing Flow，CNF）。CNF用于通过推送前向方程（push - forward equation）将简单的先验密度$p_{0}$（例如纯噪声）重塑为更复杂的密度$p_{1}$：</p>
<script type="math/tex; mode=display">p_{t} = [\phi_{t}]_{*}p_{0} \tag{3}</script><p>其中，推送前向（或变量变换）算子<script type="math/tex">*</script>定义为：</p>
<script type="math/tex; mode=display">[\phi_{t}]_{*}p_{0}(x) = p_{0}(\phi_{t}^{-1}(x)) \det[\frac{\partial \phi_{t}^{-1}}{\partial x}(x)] \tag{4}</script><p>如果向量场$v_{t}$的流$\phi_{t}$满足方程（3），则称$v_{t}$生成了概率密度路径$p_{t}$。一种检验向量场是否生成概率路径的实用方法是使用连续性方程，这是我们证明过程中的一个关键部分，详见附录B。我们在附录C中补充了更多关于CNF的信息，特别是如何计算$\mathbb{R}^{d}$中任意点$x$处的概率$p_{1}(x)$。</p>
<h3 id="3-流匹配"><a href="#3-流匹配" class="headerlink" title="3 流匹配"></a>3 流匹配</h3><p>令$x_1$表示一个服从某种未知数据分布$q(x_1)$的随机变量。我们假设只能从$q(x_1)$中获取数据样本，但无法得到其密度函数。此外，令$p_t$为一条概率路径，使得$p_0 = p$是一个简单分布，例如标准正态分布$p(x) = N(x|0, I)$，并且令$p_1$的分布近似等于$q$。稍后我们将讨论如何构建这样的路径。流匹配目标旨在匹配这个目标概率路径，从而使我们能够从$p_0$流向$p_1$。</p>
<p>给定目标概率密度路径$p_t(x)$以及相应的生成$p_t(x)$的向量场$u_t(x)$，我们将流匹配（FM）目标定义为：</p>
<script type="math/tex; mode=display">\mathcal{L}_{FM}(\theta)=\mathbb{E}_{t, p_{t}(x)}\left\| v_{t}(x)-u_{t}(x)\right\| ^{2} \tag{5}</script><p>其中，$\theta$表示CNF向量场$v_t$（如第2节所定义）的可学习参数，$t \sim U[0, 1]$（均匀分布），$x \sim p_t(x)$。简单来说，FM损失通过神经网络$v_t$对向量场$u_t$进行回归。当损失达到零时，学习到的CNF模型将生成$p_t(x)$。流匹配是一个简单且有吸引力的目标，但就其本身而言，在实际中直接使用是难以处理的，因为我们事先不知道合适的$p_t$和$u_t$是什么。有许多概率路径选择都可以满足$p_1(x) \approx q(x)$，更重要的是，我们通常无法得到生成所需$p_t$的封闭形式的$u_t$。在本节中，我们将展示可以使用仅在每个样本上定义的概率路径和向量场来构建$p_t$和$u_t$，并且通过适当的聚合方法可以得到所需的$p_t$和$u_t$。此外，这种构建方式为流匹配创建了一个更易于处理的目标。</p>
<h4 id="3-1-从条件概率路径和向量场构建-p-t-、-u-t"><a href="#3-1-从条件概率路径和向量场构建-p-t-、-u-t" class="headerlink" title="3.1 从条件概率路径和向量场构建$p_t$、$u_t$"></a>3.1 从条件概率路径和向量场构建$p_t$、$u_t$</h4><p>一种构建目标概率路径的简单方法是通过混合更简单的概率路径：对于一个特定的数据样本$x_1$，我们用$p_t(x|x_1)$表示条件概率路径，使得在$t = 0$时，它满足$p_0(x|x_1) = p(x)$；在$t = 1$时，我们将$p_1(x|x_1)$设计为一个集中在$x = x_1$附近的分布，例如$p_1(x|x_1) = N(x|x_1, \sigma^2 I)$，这是一个均值为$x_1$、标准差$\sigma &gt; 0$足够小的正态分布。对$q(x_1)$求条件概率路径的边缘分布，可得到边缘概率路径：</p>
<script type="math/tex; mode=display">p_{t}(x)=\int p_{t}\left(x | x_{1}\right) q\left(x_{1}\right) d x_{1} \tag{6}</script><p>特别地，在$t = 1$时，边缘概率$p_1$是一个混合分布，它非常接近数据分布$q$，即：</p>
<script type="math/tex; mode=display">p_{1}(x)=\int p_{1}\left(x | x_{1}\right) q\left(x_{1}\right) d x_{1} \approx q(x) \tag{7}</script><p>有趣的是，我们还可以通过以下方式“边缘化”条件向量场来定义边缘向量场（假设对于所有的$t$和$x$，$p_t(x) &gt; 0$）：</p>
<script type="math/tex; mode=display">u_{t}(x)=\int u_{t}\left(x | x_{1}\right) \frac{p_{t}\left(x | x_{1}\right) q\left(x_{1}\right)}{p_{t}(x)} d x_{1} \tag{8}</script><p>其中，$u_t(\cdot|x_1): \mathbb{R}^d \to \mathbb{R}^d$是生成$p_t(\cdot|x_1)$的条件向量场。可能不太明显，但这种聚合条件向量场的方式实际上得到了用于对边缘概率路径进行建模的正确向量场。</p>
<p><strong>我们的第一个关键发现是：边缘向量场（公式8）生成边缘概率路径（公式6）。</strong></p>
<p>这在条件向量场（生成条件概率路径的向量场）和边缘向量场（生成边缘概率路径的向量场）之间建立了一种令人惊讶的联系。这种联系使我们能够将未知且难以处理的边缘向量场分解为更简单的条件向量场，这些条件向量场只依赖于单个数据样本，定义起来要简单得多。我们在以下定理中对此进行形式化。</p>
<p><strong>定理1</strong>：给定生成条件概率路径$p_t(x|x_1)$的向量场$u_t(x|x_1)$，对于任何分布$q(x_1)$，公式8中的边缘向量场$u_t$生成公式6中的边缘概率路径$p_t$，即$u_t$和$p_t$满足连续性方程（公式26）。</p>
<p>我们所有定理的完整证明都在附录A中。定理1也可以从Peluchetti（2021）中的扩散混合表示定理推导得出，该定理为扩散随机微分方程中的边缘漂移和扩散系数提供了一个公式。</p>
<h4 id="3-2-条件流匹配"><a href="#3-2-条件流匹配" class="headerlink" title="3.2 条件流匹配"></a>3.2 条件流匹配</h4><p>遗憾的是，由于边缘概率路径和向量场的定义（公式6和公式8）中存在难以处理的积分，计算$u_t$仍然很困难，因此，直接计算原始流匹配目标的无偏估计量也很困难。相反，我们提出了一个更简单的目标，令人惊讶的是，它将得到与原始目标相同的最优解。具体来说，我们考虑条件流匹配（CFM）目标：</p>
<script type="math/tex; mode=display">\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t, q\left(x_{1}\right), p_{t}\left(x | x_{1}\right)}\left\| v_{t}(x)-u_{t}\left(x | x_{1}\right)\right\| ^{2} \tag{9}</script><p>其中，$t \sim U[0, 1]$，$x_1 \sim q(x_1)$，并且$x \sim p_t(x|x_1)$。与FM目标不同，CFM目标只要我们能够从$p_t(x|x_1)$中有效采样并计算$u_t(x|x_1)$，就可以轻松采样得到无偏估计，而这两者都很容易做到，因为它们是在每个样本的基础上定义的。</p>
<p><strong>因此，我们的第二个关键发现是：FM（公式5）和CFM（公式9）目标关于$\theta$的梯度相同。</strong></p>
<p>也就是说，优化CFM目标（在期望上）等同于优化FM目标。因此，这使我们能够训练一个CNF来生成边缘概率路径$p_t$（特别地，在$t = 1$时，$p_t$近似未知数据分布$q$），而无需访问边缘概率路径或边缘向量场。我们只需要设计合适的条件概率路径和向量场。我们在以下定理中对这一性质进行形式化。</p>
<p><strong>定理2</strong>：假设对于所有$x \in \mathbb{R}^d$和$t \in [0, 1]$，$p_t(x) &gt; 0$，那么，除了一个与$\theta$无关的常数外，$L_{CFM}$和$L_{FM}$相等。因此，$\nabla_{\theta} L_{FM}(\theta)=\nabla_{\theta} L_{CFM}(\theta)$</p>
<h3 id="4-条件概率路径和向量场"><a href="#4-条件概率路径和向量场" class="headerlink" title="4 条件概率路径和向量场"></a>4 条件概率路径和向量场</h3><p>条件流匹配目标适用于任何条件概率路径和条件向量场的选择。在本节中，我们将讨论一类通用的高斯条件概率路径的$p_t(x|x_1)$和$u_t(x|x_1)$的构建。具体而言，我们考虑形式如下的条件概率路径：</p>
<script type="math/tex; mode=display">p_t(x|x_1) = \mathcal{N}(x|\mu_t(x_1), \sigma_t(x_1)^2I) \tag{10}</script><p>其中，$\mu: [0, 1] \times \mathbb{R}^d \to \mathbb{R}^d$是高斯分布随时间变化的均值，而$\sigma: [0, 1] \times \mathbb{R} \to \mathbb{R}_{&gt;0}$描述了随时间变化的标量标准差。我们设定$\mu_0(x_1) = 0$且$\sigma_0(x_1) = 1$，这样所有条件概率路径在$t = 0$时都收敛到相同的标准高斯噪声分布$p(x) = N(x|0, I)$。然后我们设定$\mu_1(x_1) = x_1$且$\sigma_1(x_1) = \sigma_{min}$，$\sigma_{min}$被设置得足够小，使得$p_1(x|x_1)$是一个以$x_1$为中心的集中高斯分布。</p>
<p>对于任何特定的概率路径，都存在无数个向量场可以生成它（例如，通过在连续性方程中添加一个散度为零的分量，见公式26），但其中绝大多数是由于存在使基础分布保持不变的分量，例如当分布具有旋转不变性时的旋转分量，这会导致不必要的额外计算。我们决定使用与高斯分布的规范变换相对应的最简单向量场。具体来说，考虑（基于$x_1$的）变换：</p>
<script type="math/tex; mode=display">\psi_t(x) = \sigma_t(x_1)x + \mu_t(x_1) \tag{11}</script><p>当$x$服从标准高斯分布时，$\psi_t(x)$是一个仿射变换，它将$x$映射到一个均值为$\mu_t(x_1)$、标准差为$\sigma_t(x_1)$的正态分布随机变量。也就是说，根据公式4，$\psi_t$将噪声分布$p_0(x|x_1) = p(x)$推前到$p_t(x|x_1)$，即：</p>
<script type="math/tex; mode=display">[\psi_t]_*p(x) = p_t(x|x_1) \tag{12}</script><p>这个流进而提供了一个生成条件概率路径的向量场：</p>
<script type="math/tex; mode=display">\frac{d}{dt}\psi_t(x) = u_t(\psi_t(x)|x_1) \tag{13}</script><p>用$x_0$重新参数化$p_t(x|x_1)$，并将公式13代入CFM损失中，我们得到：</p>
<script type="math/tex; mode=display">\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t, q\left(x_{1}\right), p\left(x_{0}\right)}\left\| v_{t}\left(\psi_{t}\left(x_{0}\right)\right)-\frac{d}{d t} \psi_{t}\left(x_{0}\right)\right\| ^{2} \tag{14}</script><p>由于$\psi_t$是一个简单的（可逆）仿射映射，我们可以使用公式13以封闭形式求解$u_t$。对于一个随时间变化的函数$f$，令$f’$表示其对时间的导数，即$f’=\frac{d}{dt}f$。<br><strong>定理3</strong>：设$p_t(x|x_1)$是如公式10所示的高斯概率路径，$\psi_t$是其如公式11所示的相应流映射。那么，定义$\psi_t$的唯一向量场具有以下形式：</p>
<script type="math/tex; mode=display">u_{t}\left(x | x_{1}\right)=\frac{\sigma_{t}'\left(x_{1}\right)}{\sigma_{t}\left(x_{1}\right)}\left(x-\mu_{t}\left(x_{1}\right)\right)+\mu_{t}'\left(x_{1}\right) \tag{15}</script><p>因此，$u_t(x|x_1)$生成了高斯路径$p_t(x|x_1)$。</p>
<h4 id="4-1-高斯条件概率路径的特殊实例"><a href="#4-1-高斯条件概率路径的特殊实例" class="headerlink" title="4.1 高斯条件概率路径的特殊实例"></a>4.1 高斯条件概率路径的特殊实例</h4><p>我们的公式对于任意函数$\mu_t(x_1)$和$\sigma_t(x_1)$都是完全通用的，并且我们可以将它们设置为满足所需边界条件的任何可微函数。我们首先讨论那些能够恢复与先前使用的扩散过程相对应的概率路径的特殊情况。由于我们直接处理概率路径，因此可以完全抛开对扩散过程的推理。因此，在下面的第二个例子中，我们直接基于Wasserstein - 2最优传输解来构建概率路径，这是一个有趣的实例。</p>
<p><strong>示例一：扩散条件向量场</strong>。扩散模型从数据点开始，逐渐添加噪声，直到它近似于纯噪声。这些可以被表述为随机过程，为了在任意时刻$t$获得封闭形式的表示，需要满足严格的条件，这导致了具有特定均值$\mu_t(x_1)$和标准差$\sigma_t(x_1)$选择的高斯条件概率路径$p_t(x|x_1)$（Sohl - Dickstein等人，2015；Ho等人，2020；Song等人，2020b）。例如，反向（从噪声到数据）方差爆炸（VE）路径具有以下形式：</p>
<script type="math/tex; mode=display">p_{t}(x)=\mathcal{N}\left(x | x_{1}, \sigma_{1 - t}^{2}I\right)  \tag{16}</script><p>其中，$\sigma_t$是一个递增函数，$\sigma_0 = 0$，且$\sigma_1 \gg 1$。根据公式16，我们得到$\mu_t(x_1) = x_1$和$\sigma_t(x_1) = \sigma_{1 - t}$。将这些代入定理3的公式15中，我们得到：</p>
<script type="math/tex; mode=display">u_{t}\left(x | x_{1}\right)=-\frac{\sigma_{1 - t}'}{\sigma_{1 - t}}\left(x - x_{1}\right) \tag{17}</script><p>反向（从噪声到数据）方差保持（VP）扩散路径具有以下形式：</p>
<script type="math/tex; mode=display">p_{t}\left(x | x_{1}\right)=\mathcal{N}\left(x | \alpha_{1 - t}x_{1},(1 - \alpha_{1 - t}^{2})I\right) \tag{18}</script><p>其中$\alpha_{t}=e^{-\frac{1}{2}T(t)}$，$T(t)=\int_{0}^{t} \beta(s)ds$，$\beta$是噪声尺度函数。根据公式18，我们得到$\mu_t(x_1) = \alpha_{1 - t}x_1$和$\sigma_t(x_1)=\sqrt{1 - \alpha_{1 - t}^{2}}$。将这些代入定理3的公式15中，我们得到：</p>
<script type="math/tex; mode=display">u_{t}\left(x | x_{1}\right)=\frac{\alpha_{1 - t}'}{1 - \alpha_{1 - t}^{2}}\left(\alpha_{1 - t}x - x_{1}\right)=-\frac{T'(1 - t)}{2}\left[\frac{e^{-T(1 - t)}x - e^{-\frac{1}{2}T(1 - t)}x_{1}}{1 - e^{-T(1 - t)}}\right] \tag{19}</script><p>当限制在这些条件扩散过程时，我们构建的条件向量场$u_t(x|x_1)$实际上与之前在确定性概率流中使用的向量场（Song等人，2020b，公式13）一致；详见附录D。尽管如此，将扩散条件向量场与流匹配目标相结合，为现有的得分匹配方法提供了一种有吸引力的训练替代方案，在我们的实验中，我们发现这种方法更稳定、更强大。</p>
<p>另一个重要的观察结果是，由于这些概率路径以前是作为扩散过程的解推导出来的，它们实际上在有限时间内并不能达到真正的噪声分布。在实践中，$p_0(x)$只是通过一个合适的高斯分布来近似，以进行采样和似然评估。相反，我们的构建方法可以完全控制概率路径，我们可以直接设置$\mu_t$和$\sigma_t$，就像我们接下来要做的那样。</p>
<p><strong>示例二：最优传输条件向量场</strong>。一种更自然的条件概率路径选择是将均值和标准差定义为随时间线性变化，即：</p>
<script type="math/tex; mode=display">\mu_{t}(x)=tx_{1}，\sigma_{t}(x)=1 - (1 - \sigma_{min})t \tag{20}</script><p>根据定理3，这条路径由向量场生成：</p>
<script type="math/tex; mode=display">u_{t}\left(x | x_{1}\right)=\frac{x_{1}-(1 - \sigma_{min})x}{1 - (1 - \sigma_{min})t} \tag{21}</script><p>与扩散条件向量场（公式19）相比，它在所有$t \in [0, 1]$上都有定义。与$u_t(x|x_1)$对应的条件流为：</p>
<script type="math/tex; mode=display">\psi_{t}(x)=(1 - (1 - \sigma_{min})t)x + tx_{1} \tag{22}</script><p>在这种情况下，CFM损失（见公式9、14）的形式为：</p>
<script type="math/tex; mode=display">\mathcal{L}_{CFM}(\theta)=\mathbb{E}_{t, q\left(x_{1}\right), p\left(x_{0}\right)}\left\| v_{t}\left(\psi_{t}\left(x_{0}\right)\right)-\left(x_{1}-(1 - \sigma_{min})x_{0}\right)\right\| ^{2} \tag{23}</script><p>允许均值和标准差线性变化不仅会产生简单直观的路径，而且实际上在以下意义上也是最优的。条件流$\psi_t(x)$实际上是两个高斯分布$p_0(x|x_1)$和$p_1(x|x_1)$之间的最优传输（OT）位移映射。OT插值（一种概率路径）定义为（见McCann，1997中的定义1.1）：</p>
<script type="math/tex; mode=display">p_{t}=[(1 - t)\text{id}+t\psi]_*p_{0} \tag{24}</script><p>其中$\psi: \mathbb{R}^d \to \mathbb{R}^d$是将$p_0$推前到$p_1$的OT映射，$\text{id}$表示恒等映射，即$\text{id}(x) = x$，$(1 - t)\text{id}+t\psi$被称为OT位移映射。McCann（1997）中的示例1.7表明，在我们的两个高斯分布的情况下，其中第一个是标准高斯分布，OT位移映射具有公式22的形式。</p>
<p>直观地说，在OT位移映射下，粒子总是沿直线轨迹以恒定速度移动。图3描绘了扩散和OT条件向量场的采样路径。有趣的是，我们发现从扩散路径采样的轨迹可能会“超过”最终样本，导致不必要的回溯，而OT路径则保证保持直线。图2比较了扩散条件得分函数（典型扩散方法中的回归目标），即$\nabla \log p_t(x|x_1)$（其中$p_t$如公式18所定义）与OT条件向量场（公式21）。在两个示例中，起始（$p_0$）和结束（$p_1$）的高斯分布是相同的。一个有趣的观察结果是，OT向量场在时间上具有恒定的方向，这可以说导致了一个更简单的回归任务。从公式21也可以直接验证这一性质，因为该向量场可以写成$u_t(x|x_1) = g(t)h(x|x_1)$的形式。附录中的图8展示了扩散向量场的可视化。最后，我们注意到，虽然条件流是最优的，但这绝不是说边缘向量场是最优传输解。尽管如此，我们预计边缘向量场仍然相对简单。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f2.png" width="70%" height="70%"></th>
<th style="text-align:center"><img src="f3.png" width="100%" height="100%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图2：与扩散路径的条件得分函数相比，最优传输（OT）路径的条件向量场在时间上具有恒定的方向，并且可以说更容易用参数模型进行拟合。请注意，蓝色表示幅度较大，而红色表示幅度较小。</em></td>
<td style="text-align:center"><em>图3：扩散和最优传输（OT）轨迹。扩散轨迹可能会“超调”最终样本，导致不必要的回溯，而OT轨迹始终保持直线。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="5-相关工作"><a href="#5-相关工作" class="headerlink" title="5 相关工作"></a>5 相关工作</h3><p>连续归一化流（Continuous Normalizing Flows，CNFs）由Chen等人于2018年提出，是归一化流（Normalizing Flows）的连续时间版本（相关综述可参考Kobyzev等人，2020；Papamakarios等人，2021）。最初，CNFs是通过最大似然目标进行训练的，但这需要对正向和反向传播进行代价高昂的ODE模拟。由于ODE模拟的顺序性，导致时间复杂度较高。尽管一些研究展示了CNF生成模型在图像合成方面的能力（Grathwohl等人，2018），但要扩展到高维图像本质上仍然困难。许多研究试图对ODE进行正则化以使其更易于求解，例如使用增强技术（Dupont等人，2019）、添加正则化项（Yang和Karniadakis，2019；Finlay等人，2020；Onken等人，2021；Tong等人，2020；Kelly等人，2020），或者对积分区间进行随机采样（Du等人，2022）。这些研究仅仅旨在对ODE进行正则化，并没有改变基本的训练算法。</p>
<p>为了加速CNF训练，一些研究通过显式设计目标概率路径和动力学，开发了无需模拟的CNF训练框架。例如，Rozen等人（2021）考虑了先验和目标密度之间的线性插值，但涉及到在高维中难以估计的积分。Ben - Hamu等人（2022）考虑了与本研究类似的通用概率路径，但在随机小批量训练中存在梯度偏差问题。相比之下，流匹配框架允许进行无偏梯度的无模拟训练，并且可以轻松扩展到高维。</p>
<p>另一种无模拟训练方法依赖于构建扩散过程来间接定义目标概率路径（Sohl - Dickstein等人，2015；Ho等人，2020；Song和Ermon，2019）。Song等人（2020b）表明，扩散模型可以通过去噪得分匹配（Vincent，2011）进行训练，这是一种条件目标，能够为得分匹配目标提供无偏梯度。条件流匹配从该结果中获得启发，但将其推广到直接匹配向量场。由于易于扩展，扩散模型受到了越来越多的关注，并产生了多种改进方法，如损失重缩放（Song等人，2021）、添加分类器指导以及架构改进（Dhariwal和Nichol，2021），还有学习噪声调度（Nichol和Dhariwal，2021；Kingma等人，2021）。然而，Nichol和Dhariwal（2021）以及Kingma等人（2021）仅考虑了由简单扩散过程定义的具有单个参数的受限高斯条件路径设置，特别地，其中不包括我们的条件OT路径。在另一系列研究中，De Bortoli等人（2021）、Wang等人（2021）和Peluchetti（2021）通过扩散桥理论提出了有限时间扩散构建方法，解决了无限时间去噪构建所产生的近似误差问题。虽然现有研究利用了扩散过程和具有相同概率路径的连续归一化流之间的联系（Maoutsa等人，2020b；Song等人，2020b；2021），但我们的工作使我们能够超越简单扩散所建模的概率路径类别。通过我们的工作，可以完全避开扩散过程的构建，直接对概率路径进行推理，同时仍然保持高效的训练和对数似然评估。最后，与我们的工作同期，Liu等人（2022）和Albergo与Vanden - Eijnden（2022）得出了类似的用于CNFs无模拟训练的条件目标，而Neklyudov等人（2023）在假设$u_t$为梯度场的情况下推导出了一个隐式目标。</p>
<h3 id="6-实验"><a href="#6-实验" class="headerlink" title="6 实验"></a>6 实验</h3><p>我们在CIFAR10（Krizhevsky等人，2009）以及分辨率为32、64和128的ImageNet（Chrabaszcz等人，2017；Deng等人，2009）图像数据集上探究使用流匹配的实证优势。我们还对比了流匹配中不同扩散路径的选择，特别是标准方差保持扩散路径和最优传输路径。我们讨论了通过直接参数化生成向量场并使用流匹配目标，样本生成是如何得到改进的。最后，我们展示了流匹配也可用于条件生成场景。除非另有说明，我们使用dopri5（Dormand和Prince，1980）在绝对和相对容差为1e - 5的情况下评估模型的似然性和样本。生成的样本见附录，所有实现细节见附录E。</p>
<h4 id="6-1-ImageNet上的密度建模和样本质量"><a href="#6-1-ImageNet上的密度建模和样本质量" class="headerlink" title="6.1 ImageNet上的密度建模和样本质量"></a>6.1 ImageNet上的密度建模和样本质量</h4><p>我们首先比较相同的模型架构（即来自Dhariwal和Nichol，2021的U - Net架构，仅做了微小改动）在CIFAR - 10和不同分辨率（32×32、64×64）的ImageNet上，使用不同流行的基于扩散的损失函数进行训练的情况：来自Ho等人（2020）的DDPM、得分匹配（SM，Song等人，2020b）和得分流（SF，Song等人，2021）。具体细节见附录E.1。表1（左）总结了我们的结果以及这些基线方法，报告了以每维比特数（BPD）为单位的负对数似然（NLL）、通过弗雷歇初始距离（FID，Heusel等人，2017）衡量的样本质量，以及自适应求解器达到预定数值容差所需的平均函数评估次数（NFE），对50,000个样本求平均。所有模型都使用相同的架构、超参数值和训练迭代次数进行训练，为了更好地收敛，基线方法允许更多的迭代次数。请注意，这些都是无条件模型。在CIFAR - 10和ImageNet上，与竞争方法相比，基于最优传输的流匹配（FM - OT）在所有定量指标上始终获得最佳结果。我们注意到，与之前的工作（Ho等人，2020；Song等人，2020b；2021）相比，我们在CIFAR - 10上的FID性能更高，这可能是因为我们使用的架构并非针对CIFAR - 10进行优化。其次，表1（右）比较了在分辨率为128×128的ImageNet上使用基于最优传输路径的流匹配训练的模型。除了使用自监督ResNet50模型进行条件设定的IC - GAN（Casanova等人，2021）外，我们的FID达到了当前最优水平，因此IC - GAN未列入此表。附录中的图11、12、13展示了这些模型生成的未经筛选的样本。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t1.png" width="100%" height="100%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表1：使用不同方法训练的同一模型的似然性（以比特每维度，即BPD为单位）、生成样本的质量（以弗雷歇初始距离，即FID衡量）以及评估时间（以函数评估次数，即NFE表示）。</em></td>
</tr>
</tbody>
</table>
</div>
<p><strong>更快的训练速度</strong>：虽然现有工作在训练扩散模型时需要大量的迭代次数（例如，得分流和VDM分别报告了130万次和1000万次迭代），但我们发现流匹配通常收敛得更快。图5展示了在ImageNet 64×64上训练流匹配和所有基线模型时的FID曲线；FM - OT能够比其他方法更快地降低FID，且降幅更大。对于ImageNet - 128，Dhariwal和Nichol（2021）使用批量大小为256训练了436万次迭代，而FM（模型大小比前者大25%）使用批量大小为1500训练了50万次迭代，即图像吞吐量减少了33%；具体细节见表3。此外，在使用得分匹配训练时，模型采样的成本在训练过程中可能会大幅变化，而使用流匹配训练时，采样成本保持恒定（见附录图10）。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f5.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图5：ImageNet 64×64图像训练过程中的图像质量变化。图中展示了流匹配（Flow Matching）和所有基线模型在训练过程中的FID曲线。基于最优传输的流匹配（FM - OT）能够比其他方法更快地降低FID，且降幅更大。</em></td>
</tr>
</tbody>
</table>
</div>
<h4 id="6-2-采样效率"><a href="#6-2-采样效率" class="headerlink" title="6.2 采样效率"></a>6.2 采样效率</h4><p>在采样时，我们首先从标准正态分布$x_0 \sim N(0, I)$中随机抽取一个噪声样本，然后使用训练好的向量场$v_t$，在区间$t \in [0, 1]$上通过求解方程1，利用ODE求解器计算$\phi_1(x_0)$。虽然扩散模型也可以通过随机微分方程（SDE）进行采样，但这可能效率极低，许多提出快速采样器的方法（例如Song等人，2020a；Zhang和Chen，2022）直接采用ODE视角（见附录D）。部分原因是ODE求解器效率更高，在相似计算成本下误差更低（Kloeden等人，2012），并且有多种可用的ODE求解器方案。与我们的对比模型相比，我们发现使用基于最优传输路径的流匹配训练的模型，无论使用何种ODE求解器，总是能得到最高效的采样器，具体如下。<br><strong>采样路径</strong>：我们首先定性地可视化扩散路径和OT路径在采样路径上的差异。图6展示了使用相同随机种子，从ImageNet - 64模型生成的样本，我们发现基于OT路径的模型比基于扩散路径的模型更早开始生成图像，在扩散路径模型中，直到最后一个时间点图像中都主要是噪声。我们还在生成棋盘图案的2D实验中描绘了概率密度路径（图4左），也观察到了类似的趋势。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f6.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图6：使用在ImageNet 64×64上训练的模型，从相同初始噪声生成的采样路径。OT路径大致呈线性地降低噪声，而扩散路径明显仅在路径接近结束时才去除噪声。同时注意生成图像之间的差异。</em></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f4.png" width="70%" height="70%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图4：（左）在二维棋盘数据上使用不同目标训练的连续归一化流（CNF）的轨迹。最优传输（OT）路径能更早地呈现出棋盘图案，而流匹配（FM）则使训练更加稳定。（右）使用OT路径的流匹配在采用中点法求解时，采样效率更高。</em></td>
</tr>
</tbody>
</table>
</div>
<p><strong>低成本样本</strong>：接下来，我们切换到固定步长求解器，并比较表1中ImageNet - 32模型计算的低NFE（≤100）样本。在图7（左）中，我们比较了低NFE解与1000 NFE解的每像素均方误差（MSE）（我们使用256个随机噪声种子），发现基于最优传输的FM模型在计算成本方面产生的数值误差最小，达到与扩散模型相同误差阈值所需的NFE大约仅为扩散模型的60%。其次，图7（右）展示了FID随计算成本的变化，我们发现基于最优传输的FM模型即使在非常低的NFE值下也能实现不错的FID，与对比模型相比，在样本质量和成本之间实现了更好的平衡。图4（右）展示了2D棋盘实验中的低成本采样效果。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f7.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图7：流匹配，尤其是在使用最优传输（OT）路径时，能让我们在保持相似数值误差（左图）和样本质量（右图）的情况下，减少采样所需的评估次数。图中展示的是在ImageNet 32×32上训练的模型的结果，数值误差是基于中点法计算的。</em></td>
</tr>
</tbody>
</table>
</div>
<h4 id="6-3-低分辨率图像的条件采样"><a href="#6-3-低分辨率图像的条件采样" class="headerlink" title="6.3 低分辨率图像的条件采样"></a>6.3 低分辨率图像的条件采样</h4><p>最后，我们对流匹配在条件图像生成方面进行了实验，特别是将图像从64×64上采样到256×256。我们遵循Saharia等人（2022）中的评估流程，计算上采样后的验证图像的FID；基线方法包括参考值（原始验证集的FID）和回归方法。结果见表2。附录中的图14、15展示了上采样后的图像样本。基于最优传输的FM（FM - OT）在峰值信噪比（PSNR）和结构相似性指数测量（SSIM）值上与Saharia等人（2022）的方法相近，同时在FID和 inception分数（IS）上有显著提升，正如Saharia等人（2022）所指出的，FID和IS能更好地反映生成质量。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t2.png" width="70%" height="70%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表2：ImageNet验证集上的图像超分辨率结果。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="7-结论"><a href="#7-结论" class="headerlink" title="7 结论"></a>7 结论</h3><p>我们引入了流匹配（Flow Matching），这是一种全新的、无需模拟的训练连续归一化流模型的框架。该框架借助条件构建方式，可轻松扩展到极高维度。此外，流匹配框架为扩散模型提供了新的视角，建议放弃随机/扩散构建方式，转而更直接地指定概率路径。这使我们能够构建出例如可实现更快采样和（或）提升生成效果的路径。我们通过实验展示了使用流匹配框架进行训练和采样的便捷性。未来，我们期望流匹配能够开启使用多种概率路径的大门（例如非各向同性高斯分布路径，甚至是更通用的内核路径）。</p>
<h3 id="8-社会责任"><a href="#8-社会责任" class="headerlink" title="8 社会责任"></a>8 社会责任</h3><p>除了诸多积极应用外，图像生成技术也可能被用于不良目的。使用经过内容管控的训练集，以及进行图像验证和分类，有助于减少此类不良应用。此外，训练大型深度学习模型的能源需求正迅速增长（Amodei等人，2018；Thompson等人，2020）。关注那些能够通过更少的梯度更新或图像吞吐量完成训练的方法，有助于大幅节省时间和能源。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/09/Improved-Denoising-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/09/Improved-Denoising-Diffusion-Probabilistic-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Improved Denoising Diffusion Probabilistic Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-09 10:51:35" itemprop="dateCreated datePublished" datetime="2025-03-09T10:51:35+08:00">2025-03-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-11 20:48:26" itemprop="dateModified" datetime="2025-03-11T20:48:26+08:00">2025-03-11</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>去噪扩散概率模型（DDPM）是一类生成模型，最近研究表明，这类模型能够生成高质量样本。研究发现，通过一些简单的修改，DDPM在保持高样本质量的同时，还能获得具有竞争力的对数似然值。此外，研究人员还发现，对反向扩散过程的方差进行学习，可以在样本质量差异可忽略不计的情况下，将前向传递次数减少一个数量级，这对这些模型的实际应用至关重要。此外，研究人员使用精度和召回率来比较DDPM和生成对抗网络（GAN）对目标分布的覆盖程度。最后，研究表明，这些模型的样本质量和对数似然值会随着模型容量和训练计算量的增加而平稳提升，这使得它们易于扩展。研究人员已将代码发布在<a target="_blank" rel="noopener" href="https://github.com/openai/improved-diffusion">https://github.com/openai/improved-diffusion</a> 。</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h3><p>Sohl - Dickstein等人（2015年）提出了扩散概率模型，这是一类生成模型，通过学习逆转一个渐进的、多步的加噪过程来匹配数据分布。最近，Ho等人（2020年）揭示了去噪扩散概率模型（DDPM）和基于分数的生成模型（Song &amp; Ermon，2019年；2020年）之间的等价性，后者使用去噪分数匹配（Hyvärinen，2005年）来学习数据分布的对数密度梯度。最近的研究表明，这类模型能够生成高质量的图像（Ho等人，2020年；Song &amp; Ermon，2020年；Jolicoeur - Martineau等人，2020年）和音频（Chen等人，2020b；Kong等人，2020年），但DDPM能否在对数似然值上与其他基于似然的模型（如自回归模型（van den Oord等人，2016c）和变分自编码器（Kingma &amp; Welling，2013年））相媲美，尚未得到验证。这就引发了诸多问题，比如DDPM是否能够捕捉到分布的所有模式。此外，尽管Ho等人（2020年）在CIFAR - 10（Krizhevsky，2009年）和LSUN（Yu等人，2015年）数据集上取得了极为出色的成果，但DDPM在像ImageNet这样多样性更高的数据集上的扩展性如何，仍不明确。最后，虽然Chen等人（2020b）发现DDPM可以通过少量采样步骤高效地生成音频，但在图像生成方面是否同样如此，还有待证明。</p>
<p>在本文中，研究人员证明了DDPM在对数似然值上能够与其他基于似然的模型竞争，即使在像ImageNet这样多样性高的数据集上也是如此。为了更严格地优化变分下界（VLB），研究人员使用了一种简单的重参数化方法和一个混合学习目标（将VLB与Ho等人（2020年）提出的简化目标相结合）来学习反向过程的方差。</p>
<p>研究人员惊讶地发现，使用混合目标时，模型获得的对数似然值比直接优化对数似然得到的结果更好，并且发现直接优化对数似然的目标在训练过程中存在更多的梯度噪声。研究表明，一种简单的重要性采样技术可以减少这种噪声，使模型获得比使用混合目标时更好的对数似然值。</p>
<p>在将学习到的方差纳入模型后，研究人员意外地发现，可以用更少的步骤进行采样，且样本质量几乎没有变化。虽然Ho等人（2020年）的DDPM需要数百次前向传递才能生成高质量样本，但研究人员只需50次前向传递就能达到类似效果，从而加快了实际应用中的采样速度。在研究人员开展工作的同时，Song等人（2020a）开发了一种不同的快速采样方法，研究人员在实验中将其与该方法（DDIM）进行了比较。</p>
<p>虽然对数似然是与其他基于似然的模型进行比较的良好指标，但研究人员也希望将这些模型与GAN的分布覆盖范围进行对比。研究人员使用改进的精度和召回率指标（Kynkäänniemi等人，2019年），发现扩散模型在相似的FID下具有更高的召回率，这表明它们确实覆盖了目标分布的更大比例。最后，由于预计未来机器学习模型将消耗更多的计算资源，研究人员评估了随着模型规模和训练计算量增加，这些模型的性能变化。与（Henighan等人，2020年）类似，研究人员观察到，随着训练计算量的增加，模型性能呈现出可预测的提升趋势。</p>
<h3 id="2-去噪扩散概率模型"><a href="#2-去噪扩散概率模型" class="headerlink" title="2. 去噪扩散概率模型"></a>2. 去噪扩散概率模型</h3><p>研究人员简要回顾Ho等人（2020）提出的去噪扩散概率模型（DDPM）的公式。该公式做了各种简化假设，例如固定的加噪过程 $q$，它在每个时间步添加对角高斯噪声。更一般的推导过程，可参见Sohl - Dickstein等人（2015）的研究。</p>
<h4 id="2-1-定义"><a href="#2-1-定义" class="headerlink" title="2.1 定义"></a>2.1 定义</h4><p>给定数据分布 $x_{0} \sim q(x_{0})$，研究人员定义前向加噪过程 $q$，该过程通过在时间 $t$ 添加方差为 $\beta_{t} \in(0,1)$ 的高斯噪声，生成潜在变量 $x_{1}$ 到 $x_{T}$，具体如下：</p>
<script type="math/tex; mode=display">q\left(x_{1}, \ldots, x_{T} | x_{0}\right):=\prod_{t = 1}^{T} q\left(x_{t} | x_{t - 1}\right) \tag{1}</script><script type="math/tex; mode=display">q\left(x_{t} | x_{t - 1}\right):=\mathcal{N}\left(x_{t} ; \sqrt{1 - \beta_{t}} x_{t - 1}, \beta_{t} I\right) \tag{2}</script><p>在 $T$ 足够大且 $\beta_{t}$ 满足特定条件的情况下，潜在变量 $x_{T}$ 近似为各向同性高斯分布。因此，如果知道精确的反向分布 $q(x_{t - 1} | x_{t})$，就可以从 $x_{T} \sim N(0, I)$ 中采样，并反向运行该过程，从而从 $q(x_{0})$ 中获得样本。然而，由于 $q(x_{t - 1} | x_{t})$ 依赖于整个数据分布，因此研究人员使用神经网络对其进行近似：</p>
<script type="math/tex; mode=display">p_{\theta}\left(x_{t - 1} | x_{t}\right):=\mathcal{N}\left(x_{t - 1} ; \mu_{\theta}\left(x_{t}, t\right), \sum_{\theta}\left(x_{t}, t\right)\right) \tag{3}</script><p>$q$ 和 $p$ 的组合是一个变分自编码器（Kingma &amp; Welling，2013），变分下界（VLB）可以写为：</p>
<script type="math/tex; mode=display">L_{vlb}:=L_{0}+L_{1}+\cdots+L_{T - 1}+L_{T} \tag{4}</script><script type="math/tex; mode=display">L_{0}:=-\log p_{\theta}\left(x_{0} | x_{1}\right) \tag{5}</script><script type="math/tex; mode=display">L_{t - 1}:=D_{KL}\left(q\left(x_{t - 1} | x_{t}, x_{0}\right) \| p_{\theta}\left(x_{t - 1} | x_{t}\right)\right) \tag{6}</script><script type="math/tex; mode=display">L_{T}:=D_{KL}\left(q\left(x_{T} | x_{0}\right) \| p\left(x_{T}\right)\right) \tag{7}</script><p>除了 $L_{0}$ 之外，公式（4）中的每一项都是两个高斯分布之间的KL散度，因此可以通过解析形式进行计算。在评估图像的 $L_{0}$ 时，研究人员假设每个颜色分量被划分为256个区间，并计算 $p_{\theta}(x_{0} | x_{1})$ 落在正确区间的概率（利用高斯分布的累积分布函数可以计算该概率）。还需注意的是，虽然 $L_{T}$ 不依赖于 $\theta$，但如果前向加噪过程充分破坏了数据分布，使得 $q(x_{T} | x_{0}) \approx N(0, I)$，那么 $L_{T}$ 将接近0。</p>
<p>正如Ho等人（2020）所指出的，公式（2）中定义的加噪过程使得研究人员可以直接在输入 $x_{0}$ 的条件下，对加噪后的潜在变量的任意步骤进行采样。令 $\alpha_{t}:=1 - \beta_{t}$ 且 $\bar{\alpha}_{t}:=\prod_{s = 0}^{t} \alpha_{s}$，可以写出边缘分布：</p>
<script type="math/tex; mode=display">q\left(x_{t} | x_{0}\right)=\mathcal{N}\left(x_{t} ; \sqrt{\overline{\alpha}_{t}} x_{0},\left(1 - \overline{\alpha}_{t}\right) I\right) \tag{8}</script><script type="math/tex; mode=display">x_{t}=\sqrt{\overline{\alpha}_{t}} x_{0}+\sqrt{1 - \overline{\alpha}_{t}} \epsilon \tag{9}</script><p>其中 $\epsilon \sim N(0, I)$。这里，$1 - \bar{\alpha}_{t}$ 表示任意时间步的噪声方差，也可以用它来定义噪声调度，而不使用 $\beta_{t}$。</p>
<p>利用贝叶斯定理，可以根据 $\tilde{\beta}_{t}$ 和 $\tilde{\mu}_{t}(x_{t}, x_{0})$ 计算后验概率 $q(x_{t - 1} | x_{t}, x_{0})$，其定义如下：</p>
<script type="math/tex; mode=display">\tilde{\beta}_{t}:=\frac{1 - \overline{\alpha}_{t - 1}}{1 - \overline{\alpha}_{t}} \beta_{t} \tag{10}</script><script type="math/tex; mode=display">\tilde{\mu}_{t}\left(x_{t}, x_{0}\right):=\frac{\sqrt{\overline{\alpha}_{t - 1}} \beta_{t}}{1 - \overline{\alpha}_{t}} x_{0}+\frac{\sqrt{\alpha_{t}}\left(1 - \overline{\alpha}_{t - 1}\right)}{1 - \overline{\alpha}_{t}} x_{t} \tag{11}</script><script type="math/tex; mode=display">q\left(x_{t - 1} | x_{t}, x_{0}\right)=\mathcal{N}\left(x_{t - 1} ; \tilde{\mu}\left(x_{t}, x_{0}\right), \tilde{\beta}_{t} I\right) \tag{12}</script><h4 id="2-2-实际训练"><a href="#2-2-实际训练" class="headerlink" title="2.2 实际训练"></a>2.2 实际训练</h4><p>公式（4）中的目标函数是独立项 $L_{t - 1}$ 的和，公式（9）提供了一种有效的方法，可从正向加噪过程的任意步骤进行采样，并利用后验概率（公式（12））和先验概率（公式（3））来估计 $L_{t - 1}$。因此，可以随机采样 $t$，并使用期望 $E_{t, x_{0}, \epsilon}[L_{t - 1}]$ 来估计 $L_{vlb}$。Ho等人（2020）在每个小批量中为每个图像均匀采样 $t$。</p>
<p>在定义先验概率时，有多种方法对 $\mu_{\theta}(x_{t}, t)$ 进行参数化。最直接的方法是用神经网络直接预测 $\mu_{\theta}(x_{t}, t)$ 。另外，网络也可以预测 $x_{0}$，并将该输出用于公式（11）以生成 $\mu_{\theta}(x_{t}, t)$ 。网络还可以预测噪声 $\epsilon$，并利用公式（9）和（11）推导出：</p>
<script type="math/tex; mode=display">\mu_{\theta}\left(x_{t}, t\right)=\frac{1}{\sqrt{\alpha_{t}}}\left(x_{t}-\frac{\beta_{t}}{\sqrt{1 - \overline{\alpha}_{t}}} \epsilon_{\theta}\left(x_{t}, t\right)\right) \tag{13}</script><p>Ho等人（2020）发现，预测 $\epsilon$ 的效果最佳，特别是在与加权损失函数结合使用时：</p>
<script type="math/tex; mode=display">L_{simple }=E_{t, x_{0}, \epsilon}\left[\left\| \epsilon-\epsilon_{\theta}\left(x_{t}, t\right)\right\| ^{2}\right] \tag{14}</script><p>这个目标函数可以看作是 $L_{vib }$ 的加权形式（不包含影响 $\sum _{\theta}$ 的项）。作者发现，优化这个加权目标函数比直接优化 $L_{vlb}$ 能得到更好的样本质量，并通过与生成分数匹配（Song &amp; Ermon，2019；2020）建立联系来解释这一现象。</p>
<p>需要注意的是，$L_{simple }$ 没有为 $\sum _{\theta}(x_{t}, t)$ 提供学习信号。不过，这并不重要，因为Ho等人（2020）通过将方差固定为 $\sigma_{t}^{2} I$ 而非学习它，取得了最佳效果。他们发现，使用 $\sigma_{t}^{2}=\beta_{t}$ 或 $\sigma_{t}^{2}=\tilde{\beta}_{t}$（分别是 $q(x_{0})$ 为各向同性高斯噪声或狄拉克函数时方差的上下界），都能获得相似的样本质量。</p>
<h3 id="3-提高对数似然"><a href="#3-提高对数似然" class="headerlink" title="3. 提高对数似然"></a>3. 提高对数似然</h3><p>虽然Ho等人（2020年）发现，去噪扩散概率模型（DDPM）根据弗雷歇 inception 距离（FID, Frechet Inception Distance，Heusel等人，2017年）和inception分数（Salimans等人，2016年）能够生成高保真样本，但他们无法在这些模型上实现具有竞争力的对数似然。对数似然是生成式建模中广泛使用的指标，人们普遍认为，优化对数似然能促使生成式模型捕捉数据分布的所有模式（Razavi等人，2019年）。此外，最近的研究（Henighan等人，2020年）表明，对数似然的微小改进就能对样本质量和学习到的特征表示产生巨大影响。因此，探究为什么DDPM在这个指标上表现不佳很重要，因为这可能暗示了一个根本性的缺陷，比如模式覆盖不足。本节将探讨对第2节中描述的算法进行的几处修改，这些修改结合起来，能使DDPM在图像数据集上实现更好的对数似然，这表明这些模型与其他基于似然的生成式模型一样具有优势。</p>
<p>为了研究不同修改的效果，我们在ImageNet 64×64（van den Oord等人，2016b）和CIFAR-10（Krizhevsky，2009）数据集上，使用固定的超参数训练固定的模型架构。虽然CIFAR-10在这类模型中应用更为广泛，但我们也选择研究ImageNet 64×64，因为它在多样性和分辨率之间提供了良好的平衡，使我们能够快速训练模型而无需担心过拟合。此外，ImageNet 64×64在生成式建模领域已有广泛研究（van den Oord等人，2016c；Menick和Kalchbrenner，2018；Child等人，2019；Roy等人，2020），这使我们能够将DDPM直接与许多其他生成式模型进行比较。+</p>
<p>Ho等人（2020年）的设置（在将$\sigma_{t}^{2}=\beta_{t}$且$T = 1000$的情况下优化$L_{simple}$ ）在ImageNet 64×64上经过20万次训练迭代后，对数似然达到3.99（比特/维度）。我们在早期实验中发现，将$T$从1000增加到4000可以提高对数似然；经过这一调整，对数似然提高到3.77。在本节的其余部分，我们使用$T = 4000$，但我们将在第4节中探讨这一选择。</p>
<h4 id="3-1-学习-sum-theta-x-t-t"><a href="#3-1-学习-sum-theta-x-t-t" class="headerlink" title="3.1 学习$\sum_{\theta}(x_{t}, t)$"></a>3.1 学习$\sum_{\theta}(x_{t}, t)$</h4><p>在Ho等人（2020年）的研究中，作者将$\sum_{\theta}(x_{t}, t) = \sigma_{t}^{2}I$ ，其中$\sigma_{t}$ 是固定值而非学习得到的。奇怪的是，他们发现将$\sigma_{t}^{2}$固定为$\beta_{t}$与固定为<script type="math/tex">\tilde{\beta}_{t}</script>时，得到的样本质量大致相同。考虑到<script type="math/tex">\beta_{t}</script>和<script type="math/tex">\tilde{\beta}_{t}</script>代表了两个极端情况，人们有理由质疑为什么这种选择不会影响样本。图1给出了线索，该图显示，除了在$t = 0$附近，<script type="math/tex">\beta_{t}</script>和<script type="math/tex">\tilde{\beta}_{t}</script>几乎相等，即在模型处理难以察觉的细节时二者存在差异。此外，随着扩散步骤的增加，<script type="math/tex">\beta_{t}</script>和<script type="math/tex">\tilde{\beta}_{t}</script>在更多的扩散过程中似乎保持接近。这表明，在扩散步骤无限多的极限情况下，<script type="math/tex">\sigma_{t}</script>的选择对样本质量可能根本没有影响。换句话说，随着扩散步骤的增加，模型均值$\mu_{\theta}(x_{t}, t)$对分布的影响比$\sum_{\theta}(x_{t}, t)$大得多。</p>
<p>虽然上述观点表明，为了保证样本质量，固定$\sigma_{t}$是一个合理的选择，但这与对数似然无关。事实上，图2显示，扩散过程的前几个步骤对变分下界的贡献最大。因此，通过更好地选择$\sum_{\theta}(x_{t}, t)$，似乎有可能提高对数似然。为了实现这一点，我们必须在学习$\sum_{\theta}(x_{t}, t)$的过程中避免出现Ho等人（2020年）遇到的不稳定性问题。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f1.png" alt="f1"></th>
<th style="text-align:center"><img src="f2.png" alt="f2"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图1. 不同长度扩散过程中每个扩散步骤的$\tilde{\beta}</em>{t}/\beta<em>{t}$比值</em></td>
<td style="text-align:center"><em>图2. 变分下界（VLB）的各项与扩散步骤的关系。前几项对负对数似然（NLL）的贡献最大。</em></td>
</tr>
</tbody>
</table>
</div>
<p>如图1所示，$\sum_{\theta}(x_{t}, t)$的合理取值范围非常小，正如Ho等人（2020年）所观察到的，即使在对数域中，神经网络也很难直接预测$\sum_{\theta}(x_{t}, t)$。相反，我们发现在对数域中将方差参数化为$\beta_{t}$和<script type="math/tex">\tilde{\beta}_{t}</script>之间的插值会更好。具体来说，我们的模型输出一个向量$v$，每个维度都有一个分量，我们将这个输出转换为方差，如下所示：</p>
<script type="math/tex; mode=display">\sum_{\theta}(x_{t}, t) = \exp(v \log\beta_{t} + (1 - v)\log\tilde{\beta}_{t}) \tag{15}</script><p>我们没有对$v$施加任何约束，理论上允许模型预测超出插值范围的方差。然而，在实践中我们并未观察到网络这样做，这表明$\sum_{\theta}(x_{t}, t)$的取值范围确实具有足够的表达能力。</p>
<p>由于$L_{simple}$不依赖于$\sum_{\theta}(x_{t}, t)$，我们定义一个新的混合目标：</p>
<script type="math/tex; mode=display">L_{hybrid} = L_{simple} + \lambda L_{vlb} \tag{16}</script><p>在我们的实验中，我们将$\lambda$设置为0.001，以防止$L_{vlb}$主导$L_{simple}$。基于同样的思路，我们还对$L_{vlb}$项中的$\mu_{\theta}(x_{t}, t)$输出应用了停止梯度操作。这样，$L_{vlb}$可以指导$\sum_{\theta}(x_{t}, t)$的学习，而$L_{simple}$仍然是影响$\mu_{\theta}(x_{t}, t)$的主要因素。</p>
<h4 id="3-2-改进噪声调度"><a href="#3-2-改进噪声调度" class="headerlink" title="3.2 改进噪声调度"></a>3.2 改进噪声调度</h4><p>我们发现，虽然Ho等人（2020年）使用的线性噪声调度在高分辨率图像上效果良好，但对于分辨率为64×64和32×32的图像来说并非最优。特别是，前向加噪过程的后期噪声过多，对样本质量的提升贡献不大。从图3中可以直观地看出这一点。图4研究了这种影响的结果，我们可以看到，使用线性调度训练的模型在跳过高达20%的反向扩散过程时，（根据FID衡量）并没有变得更差。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f3.png" alt="f3"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图3. 分别从线性（上）和余弦（下）调度在从0到T的线性间隔t值处的潜在样本。线性调度最后四分之一的潜在样本几乎全是噪声，而余弦调度添加噪声的速度更慢。</em></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f4.png" alt="f4"></th>
<th style="text-align:center"><img src="f5.png" alt="f5"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图4. 在ImageNet 64×64上跳过反向扩散过程的前缀时的FID。</em></td>
<td style="text-align:center"><em>图5. 线性调度和我们提出的余弦调度在整个扩散过程中的$\bar{\alpha}_{t}$</em></td>
</tr>
</tbody>
</table>
</div>
<p>为了解决这个问题，我们根据$\bar{\alpha}_{t}$构建了一种不同的噪声调度：</p>
<script type="math/tex; mode=display">\bar{\alpha}_{t} = \frac{f(t)}{f(0)}, \quad f(t) = \cos\left(\frac{t/T + s}{1 + s} \cdot \frac{\pi}{2}\right)^{2} \tag{17}</script><p>为了从这个定义得到方差$\beta_{t}$，我们注意到$\beta_{t} = 1 - \frac{\bar{\alpha}_{t}}{\bar{\alpha}_{t - 1}}$。在实践中，我们将$\beta_{t}$裁剪为不大于0.999，以防止在扩散过程接近$t = T$时出现奇点。</p>
<p>我们的余弦调度旨在使$\bar{\alpha}_{t}$在过程中间呈线性下降，同时在$t = 0$和$t = T$的极端情况下变化很小，以防止噪声水平突然变化。图5展示了两种调度下$\bar{\alpha}_{t}$的变化情况。我们可以看到，Ho等人（2020年）的线性调度使$\bar{\alpha}_{t}$更快地趋近于零，比必要的情况更快地破坏了信息。</p>
<p>我们使用一个小的偏移量$s$来防止$\beta_{t}$在$t = 0$附近过小，因为我们发现，在过程开始时存在少量噪声会使网络难以准确预测$\epsilon$。具体来说，我们选择$s$使得$\sqrt{\beta_{0}}$略小于像素量化区间大小1/127.5，由此得到$s = 0.008$。我们特别选择使用$\cos^{2}$函数，是因为它是一种常见的数学函数，具有我们所需的形状。这个选择具有一定的任意性，我们预计许多其他形状相似的函数也会有类似的效果。</p>
<h4 id="3-3-减少梯度噪声"><a href="#3-3-减少梯度噪声" class="headerlink" title="3.3 减少梯度噪声"></a>3.3 减少梯度噪声</h4><p>我们原本期望通过直接优化$L_{vlb}$而不是$L_{hybrid}$来实现最佳的对数似然。然而，我们惊讶地发现，在实践中$L_{vlb}$实际上很难优化，至少在多样的ImageNet 64×64数据集上是如此。图6展示了$L_{vlb}$和$L_{hybrid}$的学习曲线。两条曲线都存在波动，但在相同的训练时间内，混合目标函数在训练集上显然实现了更好的对数似然。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="f6.png" alt="f6"></th>
<th style="text-align:center"><img src="f7.png" alt="f7"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图6. 在ImageNet 64×64上比较不同目标函数实现的对数似然的学习曲线</em></td>
<td style="text-align:center"><em>图7. 在ImageNet 64×64上$L_{vlb}$和$L_{hybrid}$目标函数的梯度噪声尺度</em></td>
</tr>
</tbody>
</table>
</div>
<p>我们假设$L_{vlb}$的梯度比$L_{hybrid}$的梯度噪声大得多。通过评估使用这两种目标函数训练的模型的梯度噪声尺度（McCandlish等人，2018年），我们证实了这一假设，如图7所示。因此，我们寻求一种减少$L_{vlb}$方差的方法，以便直接优化对数似然。</p>
<p>注意到$L_{vlb}$的不同项的量级差异很大（图2），我们假设均匀采样$t$会在$L_{vlb}$目标函数中引入不必要的噪声。为了解决这个问题，我们采用重要性采样：</p>
<script type="math/tex; mode=display">L_{vlb} = E_{t \sim p_{t}}\left[\frac{L_{t}}{p_{t}}\right], \quad \text{其中} \quad p_{t} \propto \sqrt{E[L_{t}^{2}]} \quad \text{且} \quad \sum p_{t} = 1 \tag{18}</script><p>由于$E[L_{t}^{2}]$在训练前是未知的，并且可能在训练过程中发生变化，我们为每个损失项保留之前10个值的历史记录，并在训练过程中动态更新。在训练开始时，我们均匀采样$t$，直到为每个$t \in [0, T - 1]$都抽取到10个样本。</p>
<p>通过这种重要性采样目标函数，我们能够通过优化$L_{vlb}$实现最佳的对数似然。在图6中，$L_{vlb}$（重采样）曲线展示了这一点。该图还显示，重要性采样目标函数的噪声明显低于原始的均匀采样目标函数。我们发现，在直接优化噪声较小的$L_{hybrid}$目标函数时，重要性采样技术并无帮助。</p>
<h4 id="3-4-结果与消融实验"><a href="#3-4-结果与消融实验" class="headerlink" title="3.4 结果与消融实验"></a>3.4 结果与消融实验</h4><p>在本节中，我们对为提高对数似然而进行的更改进行消融实验。表1总结了我们在ImageNet 64×64上的消融实验结果，表2展示了在CIFAR-10上的结果。我们还对最佳的ImageNet 64×64模型进行了150万次迭代训练，并报告了这些结果。$L_{vlb}$和$L_{hybrid}$使用3.1节中的参数化方法学习$\sigma$进行训练。对于$L_{vlb}$，我们使用了3.3节中的重采样方案。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src="t1.png" alt="t1"></th>
<th style="text-align:center"><img src="t2.png" alt="t2"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表1. 在ImageNet 64×64上对调度和目标函数的消融实验。</em></td>
<td style="text-align:center"><em>表2. 在CIFAR-10数据集上对噪声调度和目标函数的消融实验。</em></td>
</tr>
</tbody>
</table>
</div>
<p>基于我们的消融实验，使用$L_{hybrid}$和我们的余弦调度在提高对数似然的同时，保持与Ho等人（2020年）的基线相似的FID。优化$L_{vlb}$进一步提高了对数似然，但代价是FID更高。我们通常更倾向于使用$L_{hybrid}$而不是$L_{vlb}$，因为它在不牺牲样本质量的情况下提高了似然。</p>
<p>在表3中，我们将表现最佳的似然模型与先前研究成果进行对比，结果显示，在对数似然方面，这些模型与传统的最优方法相比颇具竞争力。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "t3.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表3. 在CIFAR-10和无条件的ImageNet 64×64数据集上，去噪扩散概率模型（DDPMs）与其他基于似然的模型的比较。负对数似然（NLL）以比特/维度为单位报告。在ImageNet 64×64数据集上，我们的模型与最好的卷积模型相比具有竞争力，但比完全基于Transformer的架构要差。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-提高采样速度"><a href="#4-提高采样速度" class="headerlink" title="4. 提高采样速度"></a>4. 提高采样速度</h3><p>我们所有的模型都经过4000步扩散训练，因此在现代GPU上生成单个样本需要花费几分钟时间。在本节中，我们探究如果减少采样时使用的步数，模型性能会如何变化，并且发现我们预训练的$L_{hybrid}$模型能够在比训练时少得多的扩散步数下生成高质量样本（无需任何微调）。以这种方式减少步数后，我们的模型能够在几秒内而非几分钟内完成采样，大大提高了图像DDPM在实际应用中的可行性。</p>
<p>对于一个经过$T$步扩散训练的模型，我们通常会使用与训练时相同的$t$值序列$(1, 2, \ldots, T)$进行采样。然而，也可以使用$t$值的任意子序列$S$进行采样。给定训练噪声调度$\bar{\alpha}_{t}$ ，对于给定的序列$S$，我们可以得到采样噪声调度$\bar{\alpha}_{S_{t}}$ ，进而得到相应的采样方差：</p>
<script type="math/tex; mode=display">\beta_{S_{t}} = 1 - \frac{\bar{\alpha}_{S_{t}}}{\bar{\alpha}_{S_{t - 1}}}, \quad \tilde{\beta}_{S_{t}} = \frac{1 - \bar{\alpha}_{S_{t - 1}}}{1 - \bar{\alpha}_{S_{t}}} \beta_{S_{t}} \tag{19}</script><p>由于$\sum_{\theta}(x_{S_{t}}, S_{t})$被参数化为$\beta_{S_{t}}$和$\tilde{\beta}_{S_{t}}$之间的一个范围，它会自动针对更短的扩散过程进行重新缩放。因此，我们可以将$p(x_{S_{t - 1}} | x_{S_{t}})$计算为$\mathcal{N}(\mu_{\theta}(x_{S_{t}}, S_{t}), \sum_{\theta}(x_{S_{t}}, S_{t}))$ 。</p>
<p>为了将采样步数从$T$减少到$K$，我们在$1$到$T$（包含两端）之间取$K$个均匀分布的实数，然后将每个结果四舍五入到最接近的整数。在图8中，我们评估了一个$L_{hybrid}$模型和一个$L_{simple}$模型的FID，这两个模型都经过4000步扩散训练，使用25、50、100、200、400、1000和4000步采样。我们对完全训练好的模型和训练过程中的中间模型进行了这样的评估。对于CIFAR-10，我们使用20万次和50万次训练迭代，对于ImageNet 64，我们使用50万次和150万次训练迭代。我们发现，固定标准差的$L_{simple}$模型（无论是较大的$\sigma_{t}^{2} = \beta_{t}$还是较小的$\sigma_{t}^{2} = \tilde{\beta}_{t}$ ）在减少采样步数时，样本质量下降得更明显，而我们学习标准差的$L_{hybrid}$模型则能保持较高的样本质量。对于这个模型，100步采样就足以使完全训练好的模型达到接近最优的FID。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f8.png" width="50%" height="50%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图8. 在ImageNet 64×64（上）和CIFAR-10（下）上训练的模型的FID与采样步数的关系。所有模型都经过4000步扩散训练。</em></td>
</tr>
</tbody>
</table>
</div>
<p>在我们进行研究的同时，Song等人（2020a）提出了一种用于DDPM的快速采样算法，通过生成一个新的隐式模型，该模型具有与原模型相同的边际噪声分布，但能将噪声确定性地映射为图像。我们将他们的算法DDIM也纳入图8中进行比较，发现DDIM在采样步数少于50步时能生成更好的样本，但在使用50步或更多步数时样本质量较差。有趣的是，DDIM在训练开始时表现较差，但随着训练的进行，它与其他采样器的差距逐渐缩小。我们发现，我们的跨步技术会显著降低DDIM的性能，因此我们的DDIM结果使用了Song等人（2020a）提出的常数跨步，即最后一步是$T - T/K + 1$而不是$T$ 。其他采样器在使用我们的跨步技术时表现略有提升。</p>
<h3 id="5-与生成对抗网络（GANs）的比较"><a href="#5-与生成对抗网络（GANs）的比较" class="headerlink" title="5. 与生成对抗网络（GANs）的比较"></a>5. 与生成对抗网络（GANs）的比较</h3><p>虽然对数似然是衡量模式覆盖程度的一个良好指标，但用这个指标来与GANs进行比较却很困难。因此，我们转而使用精度和召回率（Kynkänniemi等人，2019）进行对比。由于在GAN的研究文献中，训练类条件模型是很常见的做法，所以在本次实验中我们也采用了同样的方式。为了使我们的模型成为类条件模型，我们通过与时间步t相同的路径注入类别信息。具体来说，我们将类别嵌入向量$v_{i}$添加到时间步嵌入向量$e_{t}$中，并将这个嵌入向量传递给模型中的各个残差块。我们使用$L_{hybrid}$目标函数进行训练，并采用250步采样。我们训练了两个模型：一个是参数为1亿的“小”模型，训练了170万步；另一个是参数为2.7亿的较大模型，训练了25万步。我们还训练了一个BigGAN-deep模型，其生成器和判别器的参数总量为1亿。</p>
<p>在计算这个任务的指标时，我们生成了50,000个样本（而不是通常的10,000个），以便能直接与其他研究成果进行比较。这是我们在报告ImageNet 64×64的FID时，唯一一次使用50,000个样本进行计算的情况。对于FID，参考分布的特征是在整个训练集上计算得到的，这遵循了（Brock等人，2018）的方法。</p>
<p>图9展示了我们较大模型生成的样本，表4总结了实验结果。我们发现，BigGAN-deep在FID方面优于我们的小模型，但在召回率方面表现不佳。这表明，扩散模型在覆盖分布模式方面比类似的GANs表现更优。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "t4.png" width="80%" height="80%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>表4. 在类条件ImageNet 64×64上的样本质量比较。精度和召回率（Kynkänniemi等人，2019年）使用Inception-V3特征和$K = 5$进行测量。我们对BigGAN-deep模型进行了12.5万次迭代训练，并且在采样时不使用截断以最大化GAN的召回率。</em></td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f9.png" width="60%" height="60%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图9. 使用$L_{hybrid}$模型（FID为2.92）经过250步采样生成的类条件ImageNet 64×64样本。这些类分别是9：鸵鸟、11：金翅雀、130：火烈鸟、141：红脚鹬、154：哈巴狗、157：蝴蝶犬、97：公鸭和28：斑点蝾螈。我们可以看到每个类别的样本都具有很高的多样性，这表明模型对目标分布有很好的覆盖。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="6-扩展模型规模"><a href="#6-扩展模型规模" class="headerlink" title="6. 扩展模型规模"></a>6. 扩展模型规模</h3><p>在前面的章节中，我们展示了在不改变训练计算量的情况下，通过算法改进提升对数似然和FID的方法。然而，现代机器学习的一个趋势是，更大的模型和更长的训练时间往往能提升模型性能（Kaplan等人，2020；Chen等人，2020a；Brown等人，2020）。基于这一观察，我们研究FID和负对数似然（NLL）如何随着训练计算量的变化而变化。我们的结果虽然是初步的，但表明随着训练计算量的增加，DDPMs的性能有可预测的提升。</p>
<p>为了衡量性能如何随训练计算量变化，我们使用第3.1节中描述的$L_{hybrid}$目标函数，在ImageNet 64×64上训练了四个不同的模型。为了改变模型容量，我们在所有层应用深度乘数，使得第一层分别有64、96、128或192个通道。注意，我们之前的实验中第一层使用128个通道。由于每层的深度会影响初始权重的尺度，我们针对每个模型将Adam（Kingma和Ba，2014）学习率除以通道乘数的平方根进行调整，使得128通道的模型学习率为0.0001（与我们其他实验一致）。</p>
<p>图10展示了FID和NLL相对于理论训练计算量的提升情况。FID曲线在对数坐标图上大致呈线性，这表明FID遵循幂律变化（用黑色虚线表示）。NLL曲线与幂律的拟合度没有那么高，这表明验证集上的NLL变化方式不如FID理想。这可能是由多种因素导致的，比如1）这类扩散模型存在出乎意料的高不可约损失（Henighan等人，2020）；2）模型对训练分布过拟合。我们还注意到，这些模型一般无法达到最优的对数似然，因为它们是使用$L_{hybrid}$目标函数训练的，而不是直接使用$L_{vlb}$，目的是同时兼顾良好的对数似然和样本质量。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><img src = "f10.png" width="60%" height="60%"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><em>图10. 在ImageNet 64×64上不同模型规模在训练过程中的FID和验证集NLL。FID趋势线的常数是通过分布内数据的FID近似得到的。对于NLL趋势线，常数是通过向下取整该数据集当前最先进的NLL（Roy等人，2020）近似得到的。</em></td>
</tr>
</tbody>
</table>
</div>
<h3 id="7-相关工作"><a href="#7-相关工作" class="headerlink" title="7. 相关工作"></a>7. 相关工作</h3><p>Chen等人（2020b）和Kong等人（2020）是近期两项利用去噪扩散概率模型（DDPMs）在基于梅尔频谱图的条件下生成高保真音频的研究。与我们的工作同期，Chen等人（2020b）结合改进的调度和$L_{1}$损失，使得在采样步数减少的情况下，样本质量仅有轻微下降。然而，与我们的无条件图像生成任务相比，他们的生成任务有梅尔频谱图提供的强输入条件信号，我们推测这使得在较少的扩散步数下进行采样变得更容易。</p>
<p>Jolicoeur-Martineau等人（2020）探索了图像领域的分数匹配，并构建了一个对抗训练目标，以产生更好的$x_{0}$预测。然而，他们发现选择更好的网络架构消除了对这种对抗目标的需求，这表明对抗目标对于强大的生成式建模并非必要。</p>
<p>与我们的工作并行，Song等人（2020a）和Song等人（2020b）通过利用不同的采样过程，为使用DDPM目标训练的模型提出了快速采样算法。Song等人（2020a）通过推导一个隐式生成模型来实现这一点，该模型与DDPMs具有相同的边际噪声分布，同时能将噪声确定性地映射到图像。Song等人（2020b）将扩散过程建模为连续随机微分方程（SDE）的离散化，并观察到存在一个与反向SDE采样相对应的常微分方程（ODE）。通过改变ODE求解器的数值精度，他们可以在较少的函数评估次数下进行采样。然而，他们指出，这种技术在直接使用时，生成的样本比祖传采样更差，只有在结合朗之万校正步骤时才能实现更好的FID。这反过来又需要手动调整朗之万步骤的信噪比。我们的方法允许直接从祖传过程中快速采样，从而无需额外的超参数。</p>
<p>同样与我们的工作同期，Gao等人（2020）开发了一种扩散模型，其中反向扩散步骤由基于能量的模型建模。这种方法的一个潜在意义是，可能需要更少的扩散步骤就能获得高质量的样本。</p>
<h3 id="8-结论"><a href="#8-结论" class="headerlink" title="8. 结论"></a>8. 结论</h3><p>我们已经证明，通过一些修改，去噪扩散概率模型（DDPMs）可以在对样本质量影响极小的情况下，实现更快的采样速度和更高的对数似然。通过我们的参数化方法和$L_{hybrid}$目标函数来学习$\sum_{\theta}$，提高了模型的对数似然，使得这些模型的对数似然更接近其他基于似然的模型。我们还意外地发现，这一改变还使得从这些模型采样所需的步数大幅减少。</p>
<p>我们还发现，DDPMs在样本质量上可以与生成对抗网络（GANs）相媲美，同时在通过召回率衡量的模式覆盖方面表现更优。此外，我们研究了DDPMs的性能如何随着可用训练计算量的变化而变化，发现更多的训练计算量能显著提升样本质量和对数似然。</p>
<p>这些结果综合起来，使得DDPMs成为生成式建模中一个极具吸引力的选择。因为它们结合了良好的对数似然、高质量的样本、相当快的采样速度，以及一个坚实可靠、稳定的训练目标，并且该目标能随着训练计算量的增加而轻松扩展。这些结果表明，DDPMs是未来研究的一个很有前景的方向。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/08/GLIDE-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/08/GLIDE-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">GLIDE Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-08 11:08:14" itemprop="dateCreated datePublished" datetime="2025-03-08T11:08:14+08:00">2025-03-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-09 10:50:25" itemprop="dateModified" datetime="2025-03-09T10:50:25+08:00">2025-03-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>扩散模型最近已被证明能够生成高质量的合成图像，尤其是在与引导技术相结合，以在多样性和逼真度之间进行权衡时。我们探索了用于文本条件图像合成问题的扩散模型，并比较了两种不同的引导策略：CLIP引导和无分类器引导。我们发现，在逼真度和字幕相似度方面，人类评估者更倾向于后者，并且它通常能生成逼真的样本。使用无分类器引导的35亿参数文本条件扩散模型生成的样本，即使在DALL-E使用昂贵的CLIP重排序的情况下，也更受人类评估者的青睐。此外，我们发现我们的模型可以进行微调以执行图像修复，从而实现强大的文本驱动图像编辑。我们在经过筛选的数据集上训练了一个较小的模型，并在<a target="_blank" rel="noopener" href="https://github.com/openai/glide-text2im上发布了代码和权重。">https://github.com/openai/glide-text2im上发布了代码和权重。</a><br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/08/GLIDE-Towards-Photorealistic-Image-Generation-and-Editing-with-Text-Guided-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/08/Palette-Image-to-Image-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/08/Palette-Image-to-Image-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">Palette Image-to-Image Diffusion Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-08 09:58:48 / 修改时间：11:08:13" itemprop="dateCreated datePublished" datetime="2025-03-08T09:58:48+08:00">2025-03-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>本文基于条件扩散模型开发了一个统一的图像到图像转换框架，并在四项具有挑战性的图像到图像转换任务上对该框架进行了评估，这些任务分别是彩色化、图像修复、图像扩展和JPEG图像恢复。我们对图像到图像扩散模型的简单实现，在所有任务上均优于强大的生成对抗网络（GAN）和回归基线方法，且无需针对特定任务进行超参数调整、架构定制，也无需使用任何辅助损失函数或复杂的新技术。我们揭示了去噪扩散目标中L2和L1损失对样本多样性的影响，并通过实证研究证明了自注意力机制在神经架构中的重要性。重要的是，我们倡导基于ImageNet建立统一的评估协议，采用人工评估和样本质量评分（如FID、Inception Score、预训练ResNet50的分类准确率，以及与原始图像的感知距离）。我们期望这个标准化的评估协议能够推动图像到图像转换研究的发展。最后，我们展示了一个通用的多任务扩散模型，其性能与特定任务的专业模型相当，甚至更优。有关结果和代码的概述，请查看<a target="_blank" rel="noopener" href="https://diffusionpalette.github.io/。">https://diffusionpalette.github.io/。</a><br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/08/Palette-Image-to-Image-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/08/%E5%B8%B8%E7%94%A8%E7%A7%91%E7%A0%94%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/08/%E5%B8%B8%E7%94%A8%E7%A7%91%E7%A0%94%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86/" class="post-title-link" itemprop="url">常用科研网站合集</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-03-08 09:24:48 / 修改时间：09:45:41" itemprop="dateCreated datePublished" datetime="2025-03-08T09:24:48+08:00">2025-03-08</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Ps：本文转载于<a target="_blank" rel="noopener" href="https://hwcoder.top/Awesome-Sites">科研常用网站合集</a><br>记录科研常用网站，包括：论文检索、代码检索、学者信息、论文写作、科研论坛、截稿日期、电子书。本文持续更新。</p>
<h2 id="Paper"><a href="#Paper" class="headerlink" title="Paper"></a><a href="#paper"></a>Paper</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Site</th>
<th>Describe</th>
<th>推荐指数</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener" href="http://www.arxivdaily.com/">ArXiv Daily</a></td>
<td><strong>每日爬取 ArXiv</strong> 各个领域论文，适合速刷</td>
<td>※※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://papers.labml.ai/papers/daily">Daliy Papers</a></td>
<td>近期<strong>热点论文</strong>追踪，每天必刷！</td>
<td>※※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.semanticscholar.org/">Semantic Scholar</a></td>
<td>查看一篇论文的<strong>被引</strong>，按次数排序，<strong>更新速度很快</strong></td>
<td>※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.connectedpapers.com/">Connected Papers</a></td>
<td>用<strong>连通图</strong>展示同领域论文，大小论文都适用</td>
<td>※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://openreview.net/">OpenReview</a></td>
<td>检索<strong>最新在投论文</strong>，追踪顶会动向，可以看到<strong>审稿意见</strong></td>
<td>※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.scholar-inbox.com/">Shcolar Inbox</a></td>
<td>将最新论文按照<strong>研究兴趣匹配程度</strong>进行排序并推送</td>
<td>※※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://arxiv.org/">ArXiv</a></td>
<td>预印版论文下载，适合占坑</td>
<td>※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://github.com/">GitHub</a></td>
<td>偶尔会有好心人放出领域论文集</td>
<td>※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://www.paperdigest.org/">Paper Digest</a></td>
<td>快速搜索<strong>领域论文</strong>、最新会议论文索引 + <strong>highlight</strong></td>
<td>※※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/menu">CVF Open Access</a></td>
<td>CV 会议论文下载</td>
<td>※※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://ai-paper-collector.vercel.app/">AI-Paper-Search</a></td>
<td>国人开发的插件，支持关键词匹配 AI 顶会</td>
<td>※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://ac.scmor.com/">思谋学术导航</a></td>
<td>谷歌学术镜像与 Sci-Hub 导航</td>
<td>※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://xueshu.dailyheadlines.cc/">深度学术搜索</a></td>
<td>谷歌学术镜像</td>
<td>※</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener" href="https://readpaper.com/">ReadPaper</a></td>
<td>国内论文社区，可以看到别人对热点论文的<strong>笔记</strong></td>
<td>※</td>
</tr>
<tr>
<td>其他途径</td>
<td>公众号、组会分享、学术主页、顶会 Accept List</td>
<td>※※※※</td>
</tr>
</tbody>
</table>
</div>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/08/%E5%B8%B8%E7%94%A8%E7%A7%91%E7%A0%94%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://hqulzq.github.io/2025/03/07/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
      <meta itemprop="name" content="Zongqing Li">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lzq's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/03/07/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" class="post-title-link" itemprop="url">High-Resolution Image Synthesis with Latent Diffusion Models论文精读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-07 18:05:33" itemprop="dateCreated datePublished" datetime="2025-03-07T18:05:33+08:00">2025-03-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-03-12 15:27:54" itemprop="dateModified" datetime="2025-03-12T15:27:54+08:00">2025-03-12</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="全文翻译"><a href="#全文翻译" class="headerlink" title="全文翻译"></a>全文翻译</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>通过将图像生成过程分解为去噪自编码器的顺序应用，扩散模型（DMs）在图像数据及其他领域取得了最先进的合成结果。此外，其公式允许在无需重新训练的情况下，通过一种引导机制来控制图像生成过程。然而，由于这些模型通常直接在像素空间中运行，训练强大的扩散模型往往需要消耗数百个GPU日的计算资源，并且由于顺序评估，推理成本也很高。为了在有限的计算资源上训练扩散模型，同时保持其质量和灵活性，我们将其应用于强大的预训练自编码器的潜在空间中。与以往的工作不同，在这种表示上训练扩散模型首次在降低复杂度和保留细节之间达到了接近最优的平衡，极大地提高了视觉保真度。通过在模型架构中引入交叉注意力层，我们将扩散模型转变为强大且灵活的生成器，适用于文本或边界框等一般条件输入，并且以卷积方式实现高分辨率合成也成为可能。我们的潜在扩散模型（LDMs）在图像修复和类别条件图像合成方面取得了新的最先进分数，在包括文本到图像合成、无条件图像生成和超分辨率在内的各种任务中表现出极具竞争力的性能，同时与基于像素的扩散模型相比，显著降低了计算需求。<br>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2025/03/07/High-Resolution-Image-Synthesis-with-Latent-Diffusion-Models%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zongqing Li"
      src="https://github.com/hqulzq/hqulzq.github.io/blob/main/images/userimg.jpg?raw=true">
  <p class="site-author-name" itemprop="name">Zongqing Li</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">51</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/hqulzq" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hqulzq" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:hqulzq@163.com" title="E-Mail → mailto:hqulzq@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

      
<script type="text/javascript" charset="utf-8" src="/js/tagcloud.js"></script>
<script type="text/javascript" charset="utf-8" src="/js/tagcanvas.js"></script>
<div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div id="myCanvasContainer" class="widget tagcloud">
        <canvas width="250" height="250" id="resCanvas" style="width=100%">
            <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/2019/" rel="tag">2019</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2020/" rel="tag">2020</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2021/" rel="tag">2021</a><span class="tag-list-count">7</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2022/" rel="tag">2022</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2023/" rel="tag">2023</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/2025/" rel="tag">2025</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Bug%E6%80%BB%E7%BB%93/" rel="tag">Bug总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR/" rel="tag">CVPR</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CVPR-Workshop/" rel="tag">CVPR Workshop</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Git/" rel="tag">Git</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICLR/" rel="tag">ICLR</a><span class="tag-list-count">5</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ICML/" rel="tag">ICML</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Kafka/" rel="tag">Kafka</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Knife4j/" rel="tag">Knife4j</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/" rel="tag">Linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MinIO/" rel="tag">MinIO</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mybatis-Plus/" rel="tag">Mybatis-Plus</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NeurIPS/" rel="tag">NeurIPS</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nginx/" rel="tag">Nginx</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RabbitMQ/" rel="tag">RabbitMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/RocketMQ/" rel="tag">RocketMQ</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/diffusion/" rel="tag">diffusion</a><span class="tag-list-count">19</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/" rel="tag">docker</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/" rel="tag">k8s</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/latex/" rel="tag">latex</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode/" rel="tag">leetcode</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mongodb/" rel="tag">mongodb</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mysql/" rel="tag">mysql</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95/" rel="tag">代码随想录</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%A4%B4%E5%87%BD%E6%95%B0/" rel="tag">头函数</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%B0%9A%E5%BA%AD%E5%85%AC%E5%AF%93/" rel="tag">尚庭公寓</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/" rel="tag">异常处理</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" rel="tag">快速入门</a><span class="tag-list-count">13</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/" rel="tag">技术总结</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E7%BB%84/" rel="tag">数组</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B3%A8%E8%A7%A3/" rel="tag">注解</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BD%91%E7%AB%99/" rel="tag">网站</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%8B%A5%E4%BE%9D/" rel="tag">若依</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" rel="tag">设计模式</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%93%BE%E8%A1%A8i/" rel="tag">链表i</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/" rel="tag">项目实战</a><span class="tag-list-count">6</span></li></ul>
        </canvas>
    </div>
</div>



    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zongqing Li</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>









<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>




  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #4D4D4C;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #F7F7F7;
      background-image: linear-gradient(#F7F7F7, #F7F7F7);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>

  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('post.copy_button').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
          if(result)$(this).text('post.copy_success')
          else $(this).text('post.copy_failure')
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('post.copy_button')
        }, 300)
      }).append(e)
    })
  </script>


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":-15,"vOffset":-15},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>
